[
  {
    "objectID": "index.html#antes-de-comenzar",
    "href": "index.html#antes-de-comenzar",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de comenzar",
    "text": "Antes de comenzar\n\n\nUno de los objetivos de este curso es el evitar en la medida de lo posible el adentrarnos en teor√≠a estad√≠stica. Entre los temas que dejaremos de lado est√°n:\n\nTeor√≠a de la probabilidad b√°sica\nDescripci√≥n a detalle de la distribuci√≥n normal\nDescripci√≥n a detalle de otras distribuciones\n\nSin embargo, es preciso el comenzar por algunas definiciones que inevitablemente ser√°n necesarias para entender de mejor manera el resto del mismo.\n\n\n\nPara qui√©n est√© interesado en un recurso para ver estos temas a profundidad, recomiendo el libro de Danielle Navarro: Learning Statistics with R"
  },
  {
    "objectID": "index.html#muestras-poblaciones-y-muestreos",
    "href": "index.html#muestras-poblaciones-y-muestreos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestras, poblaciones y muestreos",
    "text": "Muestras, poblaciones y muestreos\n\n\nMuestra: Es un conjunto de observaciones que provienen de una poblaci√≥n de inter√©s. Idealmente, esta deber√≠a ser lo suficientemente grande para hacer inferencias de esa poblaci√≥n.\nPoblaci√≥n: Es el conjunto de todas las posibles observaciones de las que tengamos inter√©s en realizar inferencias. Es vital el definir adecuadamente sus caracter√≠sticas.\nMuestreo: Es el proceso por el cual obtendremos nuestra muestra para un estudio. En estudios experimentales, el muestreo se entiende tambi√©n como el proceso de aleatorizaci√≥n/randomizaci√≥n de unidades experimentales."
  },
  {
    "objectID": "index.html#muestreo-simple-sin-reemplazo",
    "href": "index.html#muestreo-simple-sin-reemplazo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestreo simple sin reemplazo",
    "text": "Muestreo simple sin reemplazo\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#muestreo-simple-con-reemplazo",
    "href": "index.html#muestreo-simple-con-reemplazo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestreo simple con reemplazo",
    "text": "Muestreo simple con reemplazo\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#otros-tipos-de-muestreo",
    "href": "index.html#otros-tipos-de-muestreo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Otros tipos de muestreo",
    "text": "Otros tipos de muestreo\n\n\nMuestreo sistem√°tico: consiste en tomar un determinado elemento de la poblaci√≥n siguiendo un patr√≥n. Por ejemplo, escoger los m√∫ltiplos de cuatro enumerados en una lista de posibles individuos de estudio (sol√≠a ser una pr√°ctica com√∫n en ensayos cl√≠nicos).\nMuestreo a conveniencia: consiste en incluir en el estudio a todos los elementos disponibles de la poblaci√≥n de inter√©s. Esto sucede sobre todo con poblaciones escasas o de dificil acceso (ejemplo, realizar estudios en comunidades LGBTIQ+).\nMuestreo estratificado: es una combinaci√≥n del muestreo simple con los sujetos agrupados por alguna caracter√≠stica en com√∫n, por ejemplo sexo, edad, h√°bitat (suele ser usado en exit polls y conteos r√°pidos)."
  },
  {
    "objectID": "index.html#par√°metros-poblacionales-y-estad√≠sticos-muestrales",
    "href": "index.html#par√°metros-poblacionales-y-estad√≠sticos-muestrales",
    "title": "Estad√≠stica aplicada con R",
    "section": "Par√°metros poblacionales y estad√≠sticos muestrales",
    "text": "Par√°metros poblacionales y estad√≠sticos muestrales\n\n\nLos par√°metros poblacionales son caracter√≠sticas de toda una poblaci√≥n (ejemplo, supongamos que el IQ de toda una poblaci√≥n puede estar caracterizado por una media aritm√©tica, \\(\\mu\\), igual a 100, con una desviaci√≥n est√°ndar, \\(\\sigma\\), igual a 15).\nSi tomo una muestra de 100 individuos de dicha poblaci√≥n, podr√≠a tener una media aritm√©tica de esta muestra, \\(\\overline{X}\\), igual a 101.4 y una desviaci√≥n est√°ndar de la muestra, \\(s\\), igual a 13.7.\nEn otras palabras, la \\(\\overline{X}\\) y \\(s\\) son aproximaciones a los valores verdareros de \\(\\mu\\) y \\(\\sigma\\) de esa poblaci√≥n."
  },
  {
    "objectID": "index.html#ley-de-los-n√∫meros-grandes",
    "href": "index.html#ley-de-los-n√∫meros-grandes",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ley de los n√∫meros grandes",
    "text": "Ley de los n√∫meros grandes\n\n\nLa ley de los n√∫meros grandes establece que a medida que aumenta el tama√±o de una muestra, \\(\\overline{X}\\) y \\(s\\) estar√°n m√°s y m√°s cerca de los valores verdaderos \\(\\mu\\) y \\(\\sigma\\).\nEsta es una de las razones por las cuales en la conducci√≥n de experimentos siempre se aconseja el intentar recabar tantas observaciones sea posible.\n\n\n\n\n\nset.seed(123)\nIQ1 <- rnorm(100, mean = 100, sd = 15)\nmean(IQ1)\n\n[1] 101.3561\n\nsd(IQ1)\n\n[1] 13.69224\n\n\n\n\nset.seed(123)\nIQ2 <- rnorm(100000, mean = 100, sd = 15)\nmean(IQ2)\n\n[1] 100.0147\n\nsd(IQ2)\n\n[1] 14.996"
  },
  {
    "objectID": "index.html#distribuci√≥n-de-muestreo",
    "href": "index.html#distribuci√≥n-de-muestreo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Distribuci√≥n de muestreo",
    "text": "Distribuci√≥n de muestreo\n\n\nLa idea de poder medir enormes n√∫meros de individuos es irreal.\nSin embargo, consideremos el siguiente escenario: si en lugar de medir el IQ de 100000 personas, repito el experimento una y otra vez pero en grupos de 5, puedo observar que la distribuci√≥n de las medias aritm√©ticas de todos estos experimentos adopta la forma de una distribuci√≥n normal"
  },
  {
    "objectID": "index.html#distribuci√≥n-de-muestreo-1",
    "href": "index.html#distribuci√≥n-de-muestreo-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Distribuci√≥n de muestreo",
    "text": "Distribuci√≥n de muestreo\n\n\nEsta distribuci√≥n toma el nombre distribuci√≥n de muestreo de la media aritm√©tica.\nLo que nos demuestra es que, incluso ante reducidos n√∫meros de observaciones en una muestra, la media aritm√©tica de esta muestra (\\(\\overline{X}\\)) estar√° pr√≥xima a la media aritm√©tica verdadera de la poblaci√≥n (\\(\\mu\\)).\n\n\n\n\n\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central",
    "href": "index.html#teorema-del-l√≠mite-central",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central\n\n\nEl teorema del l√≠mite central establece que siempre que el n√∫mero de observaciones sea lo suficientemente grande, la distribuci√≥n de muestreo de la media aritm√©tica tender√° a ser normal independientemente de si la distribuci√≥n de las observaciones es normal o no.\nEjemplo: supongamos que el ancho del caparaz√≥n de una especie de tortugas est√° comprendido entre 4 y 10 cent√≠metros. En otras palabras, si observamos al azar una tortuga de esta poblaci√≥n, sabemos que el ancho del caparaz√≥n estar√° en este rango. En t√©rminos de una distribuci√≥n, podemos decir que el ancho del caparaz√≥n en una poblaci√≥n de 1000 tortugas podr√≠a verse de esta manera:"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central-1",
    "href": "index.html#teorema-del-l√≠mite-central-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central-2",
    "href": "index.html#teorema-del-l√≠mite-central-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central\n\n\nEs gracias al teorema del l√≠mite central que la mayor parte de m√©todos estad√≠sticos giran alrededor de la normalidad.\nSin embargo, c√≥mo ya hemos mencionado, requiere a veces de un considerable n√∫mero de observaciones para que se cumpla y no todas las veces esto es posible en la pr√°ctica.\nPor ello, en el desarrollo del curso iremos mostrando ejemplos de cuando esto no ocurre y que medidas podemos tomar en tales casos."
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nMedia aritm√©tica\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(\\overline{X}\\)\nMedia aritm√©tica de la muestra\nCalculada de los datos\n\n\n\\(\\mu\\)\nVerdadera media aritm√©tica de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\mu}\\)\nEstimado de la media aritm√©tica de la poblaci√≥n\nS√≠, identica a \\(\\overline{X}\\)\n\n\n\n\\[\n\\overline{X} = \\frac{1}{n}\\sum^{n}_{i=1}\\left(X_i\\right)\n\\]"
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-1",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nDesviaci√≥n est√°ndar\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(s\\)\nDesviaci√≥n est√°ndar de la muestra\nCalculada de los datos\n\n\n\\(\\sigma\\)\nVerdadera desviaci√≥n est√°ndar de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\sigma}\\)\nEstimado de la deviaci√≥n est√°ndar de la poblaci√≥n\nS√≠, pero no es igual a \\(s\\)\n\n\n\n\n\n\\[\ns = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X})^2}\n\\]\n\n\\[\n\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2}\n\\]"
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-2",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nVarianza\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(s^2\\)\nVarianza de la muestra\nCalculada de los datos\n\n\n\\(\\sigma^2\\)\nVerdadera varianza de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\sigma}^2\\)\nEstimado de la varianza de la poblaci√≥n\nS√≠, pero no es igual a \\(s^2\\)\n\n\n\n\n\n\\[\ns^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X})^2\n\\]\n\n\\[\n\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2\n\\]"
  },
  {
    "objectID": "index.html#intervalos-de-confianza",
    "href": "index.html#intervalos-de-confianza",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nC√≥mo hemos visto, los estimados de las verdaderas \\(\\mu\\) y \\(\\sigma\\) (\\(\\hat{\\mu}\\) y \\(\\hat{\\sigma}\\)) provienen de distribuciones de muestreo, y como tales, inherentemente poseen cierto grado de incertidumbre.\nLos intervalos de confianza son medidas que nos permiten tener una idea de esa incertidumbre.\nEn el estudio de la distribuci√≥n normal est√°ndar tenemos el conocimiento que existe un 95% de chances que una cantidad normalmente distribuida colectada al azar, estar√° distante de la media aritm√©tica entre \\(\\pm\\) 1.96 desviaciones est√°ndar.\n\n\n\n\\[\n\\overline{X} - \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\overline{X} + \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\n\n\nY se interpreta como: con un 95% de confianza, podemos esperar que la media aritm√©tica verdadera de la poblaci√≥n de inter√©s se encuentra contenida entre‚Ä¶\n\n\n\n\n\\[\n\\text{IC}_{95}=\\overline{X} \\pm \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-1",
    "href": "index.html#intervalos-de-confianza-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nSin embargo, como mencionamos \\(\\sigma\\) es casi nunca conocido, y es necesario hacer una correcci√≥n a la f√≥rmula anterior. La distribuci√≥n normal trabaja bien baja la presunci√≥n de un numero grande de observaciones.\nEn su lugar, en 1908 el estad√≠stico Gosset parametriz√≥ una distribuci√≥n para muestras peque√±as que asemeja a la normal. Con el tiempo, esta distribuci√≥n adopt√≥ el nombre de Student.\nY es precisamente que la f√≥rmula anterior es corregida con la distribuci√≥n de Student y as√≠ poder calcular intervalos de confianza para muestras peque√±as usando \\(s\\) en lugar de \\(\\sigma\\):\n\n\n\n\\[\n\\text{IC}_{95}=\\overline{X} \\pm \\left(t_{n-1,\\alpha/2}\\times\\frac{s}{\\sqrt{n}}\\right)\n\\]\n\n\nDonde el valor \\(t_{n-1,\\alpha/2}\\) refiere a:\n\n\\(n-1\\): los grados de libertad, igual al n√∫mero de observaciones \\(n\\) de la muestra, menos 1\n\\(\\alpha\\): es el nivel de significancia (probabilidad de obtener un resultado err√≥neo por azar).\nEstos valores en el pasado se encontraban tabulados en libros de texto, hoy contamos con R!"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-2",
    "href": "index.html#intervalos-de-confianza-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nRegresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el \\(\\text{IC}_{95}\\)\n\n\n\n\nIQ_muestra <- c(101, 98, 116, 96, 129)   # muestra\nn <- 5                                   # n√∫mero de observaciones\nt95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%\nx <- mean(IQ_muestra)                    # media aritm√©tica de la muestra\ns <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra\nls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95\nli <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-3",
    "href": "index.html#intervalos-de-confianza-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\nRegresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el \\(\\text{IC}_{95}\\)\n\n\nIQ_muestra <- c(101, 98, 116, 96, 129)   # muestra\nn <- 5                                   # n√∫mero de observaciones\nt95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%\nx <- mean(IQ_muestra)                    # media aritm√©tica de la muestra\ns <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra\nls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95\nli <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95\nprint(paste0(\"Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [\",round(li,0),\", \",round(ls,0),\"]\"))\n\n[1] \"Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [98, 118]\""
  },
  {
    "objectID": "index.html#ejercicios-4.1",
    "href": "index.html#ejercicios-4.1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.1",
    "text": "Ejercicios 4.1\nLa concentraci√≥n media de glucosa en ratones sanos se ha estimado en un rango entre 80 y 100 mg/dL. En un experimento, se han medido las siguientes concentraciones de glucosa en 10 ratones de una l√≠nea gen√©tica se presume tendr√≠a potencial de ser modelo de hiperglucemia despu√©s de unas cuantas m√°s generaciones de cruce selectivo:\n\n\nglc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\n\n\n\n\nCalcula la media aritm√©tica \\(\\overline{X}\\), la desviaci√≥n de est√°ndar \\(s\\) y el intervalo de confianza al 95% de la concentraci√≥n de glucosa en estos ratones. Sin recurrir a pruebas estad√≠sticas formales, ¬ødir√≠as que sus niveles de glucosa est√°n dentro de lo normal o hay raz√≥n para desconfiar que son hipergluc√©micos?\nCalcula el \\(\\text{IC}_{95}\\) sin usar la distribuci√≥n de Student y nota la diferencia."
  },
  {
    "objectID": "index.html#hip√≥tesis-de-investigaci√≥n-vs.-hip√≥tesis-estad√≠sticas",
    "href": "index.html#hip√≥tesis-de-investigaci√≥n-vs.-hip√≥tesis-estad√≠sticas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Hip√≥tesis de investigaci√≥n vs.¬†hip√≥tesis estad√≠sticas",
    "text": "Hip√≥tesis de investigaci√≥n vs.¬†hip√≥tesis estad√≠sticas\n\n\nUna hip√≥tesis de investigaci√≥n gira alrededor del desarrollar una conclusi√≥n cient√≠fica acerca de un tema de inter√©s del investigador. Ejemplos: el fumar causa c√°ncer, las vacunas causan/previenen enfermedades.\n\nEs decir, pueden tener una naturaleza subjetiva, que expresan la pregunta del investigador de una manera general sin mayor descripci√≥n del ¬øc√≥mo? voy a probar o descartarla, ni ¬øen qu√© extensi√≥n?.\n\nHip√≥tesis estad√≠sticas, por el contrario, deben ser matem√°ticamente precisas y basadas en las caracter√≠sticas de los datos que recolectemos con el fin de probar o descartar la hip√≥tesis de investigaci√≥n.\n\nC√≥mo es de esperar, el probar o descartar una hip√≥tesis estad√≠stica ser√° √∫nicamente v√°lida para la poblaci√≥n sobre la cual una muestra fue tomada.\nEs ah√≠ donde radica la importancia en definir la poblaci√≥n sujeto de estudio de manera planificada con el objetivo de que cumpla tantos detalles sean necesarios de la hip√≥tesis de investigaci√≥n. Ejemplo, el modelo animal m√°s usado es el rat√≥n. Si bien es cierto constituye uno de los primeros pasos en el desarrollo de muchas investigaciones, los hallazgos en ratones NO pueden ser inmediatamente atribuibles a suceder en seres humanos."
  },
  {
    "objectID": "index.html#hip√≥tesis-nula-y-alternativa",
    "href": "index.html#hip√≥tesis-nula-y-alternativa",
    "title": "Estad√≠stica aplicada con R",
    "section": "Hip√≥tesis nula y alternativa",
    "text": "Hip√≥tesis nula y alternativa\n\n\nLa formulaci√≥n de hip√≥tesis estad√≠sticas puede reducirse a establer preguntas de investigaci√≥n en forma de las hip√≥tesis nula y alternativa.\nLa m√°s sencilla manera de formular esta dupla, es la siguiente. Supongamos que tenemos dos grupos experimentales para probar la eficiencia de un nuevo procedimiento quir√∫rgico. Un grupo de pacientes ser√° sometido a la intervenci√≥n tradicional (control), y el otro grupo al nuevo procedimiento (experimental).\n\nLa hip√≥tesis nula (\\(H_0\\)) establece que: no existe diferencia entre el grupo control y el grupo experimental,\nMientras que la hip√≥tesis alternativa (\\(H_a\\)) establece que: s√≠ existe differencia entre ambos.\n\n\n\n\n\\[\\begin{align}\nH_0& : \\mu_c = \\mu_e& H_0& : \\mu_c- \\mu_e =0 \\\\\nH_a& : \\mu_c \\neq \\mu_e& H_a& : \\mu_c- \\mu_e \\neq 0\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#tipos-de-errores",
    "href": "index.html#tipos-de-errores",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tipos de errores",
    "text": "Tipos de errores\n\n\nAl llevar a cabo pruebas de hip√≥tesis pueden ocurrir errores\n\n\n\n\\[\\begin{array}{|c||c||c|}\n  \\hline\n  & \\text{Acepta }H_{0} & \\text{Rechaza }H_{0} \\\\\n  \\hline\nH_{0}\\text{ es verdadera} & \\text{Desici√≥n correcta} & \\text{Error tipo I} \\\\\n  H_{0}\\text{ es falsa} & \\text{Error tipo II} & \\text{Desici√≥n correcta} \\\\\n   \\hline\n\\end{array}\\]\n\n\n\n¬øDe qu√© depende que aceptemos correctamente o no la hip√≥tesis nula?\n\n\n\nLas pruebas estad√≠sticas dependen de la cantidad de variaci√≥n y la diferencia entre tratamientos a detectar (tama√±o del efecto). La soluci√≥n: aumentar el n√∫mero de observaciones"
  },
  {
    "objectID": "index.html#poder-de-una-prueba-estad√≠stica",
    "href": "index.html#poder-de-una-prueba-estad√≠stica",
    "title": "Estad√≠stica aplicada con R",
    "section": "Poder de una prueba estad√≠stica",
    "text": "Poder de una prueba estad√≠stica\n\n\nEl poder de una prueba estad√≠stica es la probabilidad de rechazar la hip√≥tesis nula cuando esta es de hecho falsa.\nSe puede derivar de la tabla anterior\n\n\n\n\\[\\begin{array}{|c||c||c|}\n  \\hline\n  & \\text{Acepta }H_{0} & \\text{Rechaza }H_{0} \\\\\n  \\hline\nH_{0}\\text{ es verdadera} & 1-\\alpha\\text{ (Prob. decisi√≥n correcta)} & \\alpha\\text{ (Taza Error tipo I)} \\\\\n  H_{0}\\text{ es falsa} & \\beta\\text{ (Taza Error tipo II)} & 1-\\beta\\text{ (Poder)} \\\\\n   \\hline\n\\end{array}\\]\n\n\n\nEn la pr√°ctica, existen f√≥rmulas cerradas para la determinaci√≥n del n√∫mero m√≠nimo de observaciones para alcanzar un poder adecuado (\\(\\ge\\) 80%)."
  },
  {
    "objectID": "index.html#tama√±o-del-efecto",
    "href": "index.html#tama√±o-del-efecto",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tama√±o del efecto",
    "text": "Tama√±o del efecto\n\n\nEl tama√±o del efecto (\\(\\theta\\)) es un valor que por lo general es determinado por el investigador y que puede ser la diferencia de inter√©s a detectar en una prueba estad√≠stica.\nPor simplicidad, vamos a enfocarnos en el ejercicio de los ratones. Supongamos que el investigador est√° interesado en saber cual ser√≠a el n√∫mero de ratones que necesitar√≠a para con un 80% de poder, encontrar una diferencia entre la media aritm√©tica de su muestra y un valor que considera razonable chequear igual a 100 mg/dL. Este √∫ltimo valor viene a ser el \\(\\theta\\).\nLas hip√≥tesis de esta prueba se ver√≠an as√≠\n\n\n\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r = \\theta \\\\\nH_a& : \\mu_c- \\mu_r \\neq \\theta\n\\end{align}\\]\n\n\nSin embargo, la pregunta del investigador a√∫n est√° incompleta. A tu criterio, ¬øqu√© falta?\nAl formular hip√≥tesis, hemos considerado el caso m√°s simple hasta el momento. Pero recordando la idea inicial del experimento de los ratones, la opci√≥n l√≥gica ser√≠a preguntarnos ¬øcu√°ntos ratones necesitamos para estar seguros que la poblaci√≥n sea hipergluc√©mica? (cuyo valor de glucosa en sangre est√© por encima del de un rat√≥n sano)"
  },
  {
    "objectID": "index.html#pruebas-de-dos-colas",
    "href": "index.html#pruebas-de-dos-colas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de dos colas",
    "text": "Pruebas de dos colas\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r = \\theta \\\\\nH_a& : \\mu_c- \\mu_r \\neq \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#pruebas-de-una-cola",
    "href": "index.html#pruebas-de-una-cola",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de una cola",
    "text": "Pruebas de una cola\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r \\le \\theta \\\\\nH_a& : \\mu_c- \\mu_r > \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#pruebas-de-una-cola-1",
    "href": "index.html#pruebas-de-una-cola-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de una cola",
    "text": "Pruebas de una cola\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r \\ge \\theta \\\\\nH_a& : \\mu_c- \\mu_r < \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\n\nRetomando el poder de una prueba estad√≠stica (aunque no es un objetivo de este curso), culminaremos esta secci√≥n ejemplificando un an√°lisis de poder con nuestro ejemplo del IQ de una muestra de participantes de una determinada poblaci√≥n.\nSin entrar en mayor detalle, esto puede lograrse mediante el uso de la librer√≠a pwr\nEl tama√±o del efecto para an√°lisis de poder tiene que ser estandarizado\n\n\n\n\\[\n\\theta = \\frac{\\hat{\\mu}_r-\\hat{\\mu}_c}{s}\n\\]\n\nPara mayor detalle del uso de pwr en an√°lisis de poder, puedes acceder a este recurso"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder-1",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\n\nAcerca del IQ de la muestra de una poblaci√≥n, supongamos que el investigador est√° interesado en saber el n√∫mero de participantes necesarios para conducir un estudio donde se pueda demostrar que un valor de 100 en IQ esta dentro de la media aritm√©tica del IQ de la poblaci√≥n de donde se tom√≥ la muestra.\n\n\n\n\nlibrary(pwr)\n\nIQ_muestra <- c(101, 98, 116, 96, 129)\ns <- sd(IQ_muestra)\nuc <- mean(IQ_muestra)\nur <- 100\n\ntheta <- (ur-uc)/s\n\npwr.t.test(d = theta, \n           sig.level = 0.05,\n           power = 0.80,\n           type = \"one.sample\",\n           alternative = \"two.sided\")"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder-2",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\nlibrary(pwr)\n\nIQ_muestra <- c(101, 98, 116, 96, 129)\ns <- sd(IQ_muestra)\nuc <- mean(IQ_muestra)\nur <- 100\n\ntheta <- (ur-uc)/s\n\npwr.t.test(d = theta, \n           sig.level = 0.05,\n           power = 0.80,\n           type = \"one.sample\",\n           alternative = \"two.sided\")\n\n\n     One-sample t test power calculation \n\n              n = 26.45135\n              d = 0.5663939\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided"
  },
  {
    "objectID": "index.html#ejercicio-4.2",
    "href": "index.html#ejercicio-4.2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.2",
    "text": "Ejercicio 4.2\nA partir de los estad√≠sticos de muestreo de la muestra de ratones del ejemplo anterior, ¬øcu√°l ser√≠a el n√∫mero de los mismos para en un futuro experimento llevar a cabo una prueba estad√≠stica con al menos 80% de poder si el objetivo es demostrar que de hecho la media aritm√©tica de esta l√≠nea de ratones est√° por encima del l√≠mite superior de 100 mg/dL de glucosa en sangre que se sabe poseen ratones saludables?\n\nglc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)"
  },
  {
    "objectID": "index.html#valores-cr√≠ticos-y-el-valor-p",
    "href": "index.html#valores-cr√≠ticos-y-el-valor-p",
    "title": "Estad√≠stica aplicada con R",
    "section": "Valores cr√≠ticos y el valor p",
    "text": "Valores cr√≠ticos y el valor p\n\n\nPero ¬øc√≥mo sabemos si una hip√≥tesis es aceptada o rechazada?\nRegresando al concepto de los intervalos de confianza, los cuartiles de la distribuci√≥n de Student calculados a un nivel de significancia \\(\\alpha\\) son valores cr√≠ticos sobre los cuales se determina el rechazo o aceptaci√≥n de la hip√≥tesis nula.\nEl valor p, describe que tan probable ser√≠a observar resultados de la prueba asumiendo que la hip√≥tesis nula no hubiese sido rechazada. Por ello, a menores valores p, mayor la diferencia estad√≠stica con respecto a la hip√≥tesis alternativa."
  },
  {
    "objectID": "index.html#antes-de-continuar",
    "href": "index.html#antes-de-continuar",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nPara esta secci√≥n del curso usaremos algunas de las tablas de datos del libro Using R for Introductory Statistics, como tambi√©n de la librer√≠a datarium.\nPara ello, instalaremos las librer√≠as de R: UsingR y datarium.\n\n\n\n\nlibrary(UsingR)\nlibrary(datarium)\n\n\n\nEn esta secci√≥n iniciaremos directamente con la conducci√≥n de las pruebas sin una formal evaluaci√≥n de la normalidad de los datos. M√°s tarde veremos que algunas de las tablas de datos no est√°n normalmente distribuidas üòâ"
  },
  {
    "objectID": "index.html#pruebas-t",
    "href": "index.html#pruebas-t",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas t",
    "text": "Pruebas t\n\n\nLas pruebas t son usadas para encontrar la diferencia entre dos medias aritm√©ticas.\nLa \\(H_0\\) en estas pruebas es que las medias aritm√©ticas son las mismas.\nSe rechaza la \\(H_0\\) cuando el valor p resultante es \\(<\\) 0.05\nExisten tres tipos de pruebas t\n\nPruebas t de una muestra\nPruebas t de muestras independientes\nPruebas t de muestras emparejadas\n\nEstas pruebas fueron desarrolladas bajo la suposici√≥n de la normalidad y de homogeneidad de las varianzas.\nDe acuerdo a lo que hemos visto acerca del teorema del l√≠mite central, muestras grandes casi aseguran la normalidad.\nCuando el n√∫mero de observaciones en una muestra es peque√±o, es recomendable llevar a cabo un test de normalidad para decidir si es posible llevar a cabo una prueba t o una de sus alternativas."
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra",
    "href": "index.html#prueba-t-de-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\n\nEs usada para comparar la media aritm√©tica de una muestra con un valor conocido (un est√°ndar por ejemplo).\nPor lo general la el valor al que se va a comparar proviene de referencias bibliogr√°ficas, pre-experimentos o supociones fundamentadas.\nRegresando a nuestro ejemplo de los ratones, determinemos si la media de la muestra es mayor al l√≠mite superior de glucosa de ratones saludables."
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra-1",
    "href": "index.html#prueba-t-de-una-muestra-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\nglc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\nt.test(glc_rat,\n       mu = 100,\n       alternative = \"greater\")"
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra-2",
    "href": "index.html#prueba-t-de-una-muestra-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\nglc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\nt.test(glc_rat,\n       mu = 100,\n       alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  glc_rat\nt = -1.4485, df = 9, p-value = 0.9093\nalternative hypothesis: true mean is greater than 100\n95 percent confidence interval:\n 76.16687      Inf\nsample estimates:\nmean of x \n    89.48"
  },
  {
    "objectID": "index.html#ejercicio-4.3",
    "href": "index.html#ejercicio-4.3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.3",
    "text": "Ejercicio 4.3\nLa tabla de datos blood de la librer√≠a UsingR tiene las medidas de presi√≥n sist√≥lica de sangre correspondientes a 15 pacientes (columna ‚Äúmachine‚Äù). De acuerdo al Centro de Prevenci√≥n y Control de Enfermedades de los Estados Unidos (CDC), una presi√≥n sist√≥lica saludable est√° por debajo de 120 mm Hg. Determina si la media de la muestra contenida en esta tabla de datos est√° por debajo de este valor sugerido por el CDC.\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre blood aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(blood)\nblood\n\nTip: para acceder a la columna con las presiones sist√≥licas, usa la siguiente sintaxis: blood$machine"
  },
  {
    "objectID": "index.html#prueba-t-de-muestras-independientes",
    "href": "index.html#prueba-t-de-muestras-independientes",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de muestras independientes",
    "text": "Prueba t de muestras independientes\n\n\nEs usado para comparar las medias aritm√©ticas de dos grupos independientes.\nPor ejemplo, si deseas comparar las medias aritm√©ticas de individuos agrupados por sexo.\nPara ilustrar esta prueba, vamos a hacer uso de la tabla de datos de genderweight de la librer√≠a datarium.\n\nVeamos si existe una diferencia significativa en la media del peso entre hombres y mujeres\n\n\n\n\n\ndata(genderweight)"
  },
  {
    "objectID": "index.html#prueba-t-de-muestras-independientes-1",
    "href": "index.html#prueba-t-de-muestras-independientes-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de muestras independientes",
    "text": "Prueba t de muestras independientes\n\nt.test(genderweight$weight ~ genderweight$group)\n\n\n    Welch Two Sample t-test\n\ndata:  genderweight$weight by genderweight$group\nt = -20.791, df = 26.872, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -24.53135 -20.12353\nsample estimates:\nmean in group F mean in group M \n       63.49867        85.82612"
  },
  {
    "objectID": "index.html#ejercicio-4.4",
    "href": "index.html#ejercicio-4.4",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.4",
    "text": "Ejercicio 4.4\nLa tabla de datos normtemp de la librer√≠a UsingR tiene las medidas en grados Fahrenheit de temperatura corporal (columna ‚Äútemperature‚Äù ) correspodientes a 65 mujeres y 65 hombres (columna ‚Äúgender‚Äù). Determina si existe una diferencia entre las temperaturas corporales de hombres y mujeres.\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre normtemp aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(normtemp)\nnormtemp\n\nTip: para acceder a las columnas con las temperaturas corporales y sexo, usa la siguiente sintaxis: normtemp$temperature y normtemp$gender respectivamente"
  },
  {
    "objectID": "index.html#prueba-t-para-muestras-emparejadas",
    "href": "index.html#prueba-t-para-muestras-emparejadas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t para muestras emparejadas",
    "text": "Prueba t para muestras emparejadas\n\n\nEs usado para comparar las medias de dos grupos que guardan una relaci√≥n.\nEsto solo ocurre cuando las medidas se han realizado a partir de los mismos grupos. Por ejemplo, al inicio y al final de un experimento.\nPara esta prueba, vamos a usar la tabla de datos crime de la librer√≠a UsingR\n\nVeamos si existe una diferencia en las tasas de crimen (# de reportes/100000 habitantes) en 50 estados de los Estados unidos entre 1983 y 1993\n\n\n\n\n\ndata(crime)"
  },
  {
    "objectID": "index.html#prueba-t-para-muestras-emparejadas-1",
    "href": "index.html#prueba-t-para-muestras-emparejadas-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t para muestras emparejadas",
    "text": "Prueba t para muestras emparejadas\n\nt.test(x = crime$y1983, y = crime$y1993, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  crime$y1983 and crime$y1993\nt = -7.6839, df = 50, p-value = 5.141e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -213.5671 -125.0525\nsample estimates:\nmean difference \n      -169.3098 \n\nmean(crime$y1983)\n\n[1] 437.5196\n\nmean(crime$y1993)\n\n[1] 606.8294"
  },
  {
    "objectID": "index.html#ejercicio-4.5",
    "href": "index.html#ejercicio-4.5",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.5",
    "text": "Ejercicio 4.5\nLa tabla de datos mice2 de la librer√≠a datarium tiene las medidas del peso de 10 ratones antes y despu√©s de haber sido sometidos a una determinada dieta. Encuentra si existe una diferencia significativa en el peso de estos ratones antes y despu√©s del r√©gimen de dieta al que fueron expuestos. ¬øGanaron o perdieron peso?\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre normtemp aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(mice2)\nmice2\n\nTip: usa el mismo tips de los ejemplos anteriores"
  },
  {
    "objectID": "index.html#normalidad-de-una-muestra",
    "href": "index.html#normalidad-de-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Normalidad de una muestra",
    "text": "Normalidad de una muestra\n\n\nHasta este momento, hemos asumido que todos los datos analizados son normalmente distribuidos.\nPor esta raz√≥n, no he introducido las pruebas que en la pr√°ctica deber√≠as realizar en orden de determinar que prueba estad√≠stica es la m√°s adecuada para realizar inferencias estad√≠sticas.\nExisten dos tipos de pruebas para establecer si una muestra es normalmente distribuida o no\n\nIndirectamente: gr√°fico Q-Q\nPrueba formal de normalidad Shapiro-Wilk"
  },
  {
    "objectID": "index.html#gr√°fico-q-q",
    "href": "index.html#gr√°fico-q-q",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°fico Q-Q",
    "text": "Gr√°fico Q-Q\n\n\nEl gr√°fico Q-Q es una prueba visual indirecta de la normalidad.\nConsiste en crear un gr√°fico de dispersi√≥n entre los valores observados de una muestra vs.¬†los valores que deber√≠an estos tener si siguieran una distribuci√≥n normal.\nMientras el gr√°fico de dispersi√≥n m√°s concentra sus puntos a lo largo de una diagonal, m√°s cercanos est√°n los datos de la muestra a seguir un distribuci√≥n normal.\nEs muy subjetivo."
  },
  {
    "objectID": "index.html#gr√°fico-q-q-1",
    "href": "index.html#gr√°fico-q-q-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°fico Q-Q",
    "text": "Gr√°fico Q-Q\n\ny <- rnorm(n = 100, mean = 0, sd = 1) # simulamos 100 observaciones de una normal estandar\nqqnorm(y)                             # producimos el gr√°fico Q-Q"
  },
  {
    "objectID": "index.html#prueba-de-normalidad-shapiro-wilk",
    "href": "index.html#prueba-de-normalidad-shapiro-wilk",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de normalidad Shapiro-Wilk",
    "text": "Prueba de normalidad Shapiro-Wilk\n\n\nLa \\(H_0\\) de esta prueba es que un set de \\(n\\) observaciones es normalmente distribuido.\nOtro conocido m√©todo es Kolmogorov-Smirnov. Sin embargo, Shapiro-Wilk es m√°s apropiado para cuando el n√∫mero de muestras es menor a 50.\nProbemos entonces si los datos de crimen en los Estados Unidos son normalmente distribuidos:\n\nComo en este caso tenemos dos muestras, debemos chequear la normalidad de cada grupo sujeto de comparaci√≥n por separado."
  },
  {
    "objectID": "index.html#prueba-de-normalidad-shapiro-wilk-1",
    "href": "index.html#prueba-de-normalidad-shapiro-wilk-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de normalidad Shapiro-Wilk",
    "text": "Prueba de normalidad Shapiro-Wilk\n\n\n\nshapiro.test(crime$y1983)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1983\nW = 0.77333, p-value = 1.827e-07\n\n\n\n\nshapiro.test(crime$y1993)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1993\nW = 0.77348, p-value = 1.841e-07\n\n\n\n\n\n\n¬°Los datos no son normalmente distribuidos! üò±\nAntes de recurrir a pruebas para datos no normales, podemos recurrir a probar transformaciones de los datos. Las transformaciones m√°s usadas son:\n\nLa ra√≠z cuadrada (si los datos no contienen n√∫meros negativos)\nElevar al cuadrado\nLogaritmo (si los datos solo incluyen n√∫meros reales positivos, cero excluido)"
  },
  {
    "objectID": "index.html#prueba-de-normalidad-shapiro-wilk-2",
    "href": "index.html#prueba-de-normalidad-shapiro-wilk-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de normalidad Shapiro-Wilk",
    "text": "Prueba de normalidad Shapiro-Wilk\n\n\nRa√≠z cuadrada\n\nshapiro.test(sqrt(crime$y1983))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  sqrt(crime$y1983)\nW = 0.9411, p-value = 0.01359\n\n\n\nElevar al cuadrado\n\nshapiro.test(crime$y1983^2)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1983^2\nW = 0.38921, p-value = 2.954e-13\n\n\n\n\n\n\nLogaritmo\n\nshapiro.test(log(crime$y1983))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  log(crime$y1983)\nW = 0.98076, p-value = 0.5713\n\n\n\nChequeemos con el otro grupo\n\nshapiro.test(log(crime$y1993))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  log(crime$y1993)\nW = 0.96191, p-value = 0.1006"
  },
  {
    "objectID": "index.html#prueba-de-normalidad-shapiro-wilk-3",
    "href": "index.html#prueba-de-normalidad-shapiro-wilk-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de normalidad Shapiro-Wilk",
    "text": "Prueba de normalidad Shapiro-Wilk\n\nOjo con las transformaciones\n\n\nExiste un m√©todo m√°s sofisticado para ‚Äúnormalizar‚Äù una muestra. La transformaci√≥n de Box-Cox.\nCuando se trabaja con muestras transformadas, el objetivo es poder revertir la transformaci√≥n a las unidades reales para as√≠ poder hacer conclusiones sobre las inferencias estad√≠sticas.\nEn otras palabras, una misma transformaci√≥n debe aplicarse a todos los grupos a ser comparados. NO tiene ning√∫n sentido tratar de realizar inferencias entre grupos donde se hayan usado distintas transformaciones para normalizarlos.\nSi el n√∫mero de observaciones es muy reducido, no hay transformaci√≥n que funcione y se recomienda usar directamente pruebas no param√©tricas."
  },
  {
    "objectID": "index.html#ejercicios-4.6",
    "href": "index.html#ejercicios-4.6",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.6",
    "text": "Ejercicios 4.6\n\nChequea si los datos que usamos en el ejercicio 4.5 de la tabla de datos mice2 son normalmente distribuidos.\nEn la librer√≠a UsingR tenemos disponible una lista con 5 objetos bajo el nombre cancer. Esta contiene el tiempo de sobreviviencia en d√≠as de pacientes con distintos tipos de c√°ncer desde el momento de su diagn√≥stico hasta su deceso. Chequea si los datos correspondientes a cancer de colon son normalmente distribuidos. Si no lo son, prueba si puedes normalizarlos usando alguna de las tres transformaciones que vimos. En el caso que m√°s de una transformaci√≥n funcione, ¬øcu√°l escoger√≠as para continuar con alguna prueba estad√≠stica, y por qu√©?\n\nTip: usa el siguiente c√≥digo para extraer en un vector los datos de pacientes con c√°ncer de colon:\n\ndata(cancer)\ncolon <- cancer$colon"
  },
  {
    "objectID": "index.html#pruebas-de-wilcoxon-para-datos-no-normales",
    "href": "index.html#pruebas-de-wilcoxon-para-datos-no-normales",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de Wilcoxon para datos no normales",
    "text": "Pruebas de Wilcoxon para datos no normales\n\n\nLas pruebas de Wilcoxon usan la mediana como criterio para evaluar la \\(H_0\\).\nLastimosamente, estas pruebas son usualmente menos poderosas (mayor tasa de errores tipo II).\nTiene dos formas:\n\nPruebas para una muestra (an√°loga a la prueba t para una muestra)\nPruebas para dos muestras (an√°loga a las pruebas t para dos muestras independientes y emparejadas)"
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-una-muestra",
    "href": "index.html#prueba-de-wilcoxon-para-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para una muestra",
    "text": "Prueba de Wilcoxon para una muestra\n\n\nProf.¬†Danielle Navarro midi√≥ el nivel de felicidad de sus estudiantes antes y despu√©s de su clase de Estad√≠stica. Ella estaba interesada en saber si el tomar una clase de Estad√≠stica tiene alg√∫n efecto en la felicidad de sus estudiantes. Los datos que obtuvo no est√°n normalmente distribuidos. Por ello, se vio en la necesidad de llevar a cabo una prueba de Wilcoxon.\nEn este caso, la \\(H_0\\), es que la diferencia de la mediana de la felicidad de sus estudiantes antes y despu√©s de la clase deber√≠a ser igual a cero para clamar que no existe tal efecto."
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-una-muestra-1",
    "href": "index.html#prueba-de-wilcoxon-para-una-muestra-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para una muestra",
    "text": "Prueba de Wilcoxon para una muestra\n\n# Primero recreo la tabla de Prof. Navarro\nfelicidad <- data.frame(before = c(30,43,21,24,23,40,29,56,38,16),\n                        after = c(6,29,11,31,17,2,31,21,8,21))\nfelicidad$change <- felicidad$after - felicidad$before\n\nwilcox.test(felicidad$change, mu = 0)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  felicidad$change\nV = 7, p-value = 0.03711\nalternative hypothesis: true location is not equal to 0"
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-dos-muestras",
    "href": "index.html#prueba-de-wilcoxon-para-dos-muestras",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para dos muestras",
    "text": "Prueba de Wilcoxon para dos muestras\n\n\nRegresando al ejemplo de la tabla de datos genderweight, sus datos no est√°n normalmente distribuidos üòÆ\nSuponiendo que no encontramos una transformaci√≥n adecuada para normalizarlos, usaremos la prueba de Wilcoxon para muestras independientes.\n\n\n\n\nwilcox.test(genderweight$weight ~ genderweight$group, paired = F)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  genderweight$weight by genderweight$group\nW = 0, p-value = 1.451e-11\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "index.html#ejercicios-4.7",
    "href": "index.html#ejercicios-4.7",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.7",
    "text": "Ejercicios 4.7\n\nCon el vector de nombre colon que creaste en el ejercicio 4.6, aplica una prueba de Wilcoxon para una muestra bajo la hip√≥tesis de que la mediana de los d√≠as de superviviencia de un paciente con c√°ncer de colon es de 370 d√≠as.\nA partir de la tabla de datos de felicidad de la Prof.¬†Navarro, lleva a cabo una prueba de Wilcoxon para dos muestras emparejadas de la felicidad de los estudiantes antes y despu√©s de recibir una clase de Estad√≠stica. Compara el resultado con la prueba que de una muestra que us√© de ejemplo. ¬øPor qu√© no hay diferencia?."
  },
  {
    "objectID": "index.html#tablas-de-contingencia",
    "href": "index.html#tablas-de-contingencia",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tablas de contingencia",
    "text": "Tablas de contingencia\n\n\nUna tabla de contigencia nos sirve para ver si los valores de una variable categ√≥rica dependen de los valores de otra variable categ√≥rica.\nEl an√°lisis de contingencia nos permite probar formalmente la asociaci√≥n entre dos o m√°s variables categ√≥ricas.\n\n¬øQu√© tan probable es que beban m√°s alcohol personas que fuman con respecto a aquellas que no?\n¬øLas personas que toman una aspirina diaria tienen menos probabilidad de sufrir un ataque card√≠aco con respecto a las que no?"
  },
  {
    "objectID": "index.html#tabla-de-contingencia-n-times-n",
    "href": "index.html#tabla-de-contingencia-n-times-n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tabla de contingencia \\(n \\times n\\)",
    "text": "Tabla de contingencia \\(n \\times n\\)\n\n\n\n\n\n\nModificado de Milo≈° Gejdo≈°, et al. (2019) Int. J. Environ. Res. Public Health 16(1)"
  },
  {
    "objectID": "index.html#tabla-de-contingencia-n-times-n-1",
    "href": "index.html#tabla-de-contingencia-n-times-n-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tabla de contingencia \\(n \\times n\\)",
    "text": "Tabla de contingencia \\(n \\times n\\)\n\n\n\n\n\n\n\nLa variable B (o respuesta) contendr√° como posibles resultados ‚Äú√©xito‚Äù o ‚Äúfracaso‚Äù.\nLa variable A (o explanatoria) posee las clases que identifican los grupos cuya probabilidad es sujeto de comparaci√≥n.\n\n\n\nModificado de Milo≈° Gejdo≈°, et al. (2019) Int. J. Environ. Res. Public Health 16(1)"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2",
    "href": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)",
    "text": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)\n\n\nEl cociente de probabilidad mide la magnitud de asociaci√≥n entre dos variables categ√≥ricas cuando estas tienen dos clases.\nEn una tabla de contingencia \\(2 \\times 2\\), el cociente de probabilidad (OR) se define como:\n\n\n\n\\[ OR=\\frac{n_{11}/n_{12}}{n_{21}/n_{22}} \\]"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2-1",
    "href": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)",
    "text": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)\n\n\nLa interpretaci√≥n del OR depende de la magnitud del mismo:\n\nIgual a 1, los eventos (clase de la variable explanatoria) son independientes de la variable de respuesta.\nMayor o menor a 1, existe una relaci√≥n positiva o negativa de la variable explanatoria con la variable de respuesta.\nLa magnitud de OR depende de la clase tomada como base en el an√°lisis."
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-en-r",
    "href": "index.html#cociente-de-probabilidad-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad en R",
    "text": "Cociente de probabilidad en R\n\nUsaremos para este ejemplo los datos del Titanic. La pregunta de investigaci√≥n es: ¬øtuvieron las mujeres mayores probabilidades de salvarse durante el hundimiento del Titanic?\n\n\n\nCargamos en nuestro ambiente la tabla de datos (librer√≠a datarium)\n\n\ndata(titanic.raw)\n\n\n\n\nDefinimos las clases de referencia\n\n\n\n\n\ntitanic.raw$Survived <- relevel(titanic.raw$Survived, ref = \"Yes\")\ntitanic.raw$Sex <- relevel(titanic.raw$Sex, ref = \"Female\")"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-en-r-1",
    "href": "index.html#cociente-de-probabilidad-en-r-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad en R",
    "text": "Cociente de probabilidad en R\n\n\n\nCreamos la tabla de contingencia\n\n\ntabla_cont <- table(titanic.raw$Sex, titanic.raw$Survived)\n\n\n\n\ntabla_cont\n\n        \n          Yes   No\n  Female  344  126\n  Male    367 1364\n\n\n\n\n\n\n\n\nCalculamos el OR\n\n\noddratio <- fisher.test(tabla_cont)\n\n\n\n\noddratio \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tabla_cont\np-value < 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  7.97665 12.92916\nsample estimates:\nodds ratio \n   10.1319"
  },
  {
    "objectID": "index.html#c√≥mo-interpretamos-estos-resultados",
    "href": "index.html#c√≥mo-interpretamos-estos-resultados",
    "title": "Estad√≠stica aplicada con R",
    "section": "¬øC√≥mo interpretamos estos resultados?",
    "text": "¬øC√≥mo interpretamos estos resultados?\n\n\n\n\noddratio\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tabla_cont\np-value < 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  7.97665 12.92916\nsample estimates:\nodds ratio \n   10.1319 \n\n\n\n\n\nVemos que el cociente de probabilidad (OR) es 10. La interpretaci√≥n es: durante el hundimiento del Titanic fue 10 veces m√°s probable que un pasajero se salve si este era mujer.\nAdicionalmente, del valor p de la prueba estad√≠stica exacta de Fisher menor al 0.05, se puede concluir que este cociente de probabilidad es significativo. En otras palabras, existe evidencia estad√≠stica significativa para afirmar que las probabilidades de sobrevivir durante el hundimiento del Titanic fueron 10 veces m√°s para pasajeras mujeres en comparaci√≥n a los hombres."
  },
  {
    "objectID": "index.html#introducci√≥n",
    "href": "index.html#introducci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\n\n\nHasta el momento nos hemos enfocado a los casos donde comparamos las medias entre dos grupos.\nEl An√°lisis de Varianza, desarrollado por Fisher a inicios del siglo 20"
  }
]