[
  {
    "objectID": "index.html#antes-de-comenzar",
    "href": "index.html#antes-de-comenzar",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de comenzar",
    "text": "Antes de comenzar\n\n\nUno de los objetivos de este curso es el evitar en la medida de lo posible el adentrarnos en teor√≠a estad√≠stica. Entre los temas que dejaremos de lado est√°n:\n\nTeor√≠a de la probabilidad b√°sica\nDescripci√≥n a detalle de la distribuci√≥n normal\nDescripci√≥n a detalle de otras distribuciones\n\nSin embargo, es preciso el comenzar por algunas definiciones que inevitablemente ser√°n necesarias para entender de mejor manera el resto del mismo.\n\n\n\nPara qui√©n est√© interesado en un recurso para ver estos temas a profundidad, recomiendo el libro de Danielle Navarro: Learning Statistics with R"
  },
  {
    "objectID": "index.html#muestras-poblaciones-y-muestreos",
    "href": "index.html#muestras-poblaciones-y-muestreos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestras, poblaciones y muestreos",
    "text": "Muestras, poblaciones y muestreos\n\n\nMuestra: Es un conjunto de observaciones que provienen de una poblaci√≥n de inter√©s. Idealmente, esta deber√≠a ser lo suficientemente grande para hacer inferencias de esa poblaci√≥n.\nPoblaci√≥n: Es el conjunto de todas las posibles observaciones de las que tengamos inter√©s en realizar inferencias. Es vital el definir adecuadamente sus caracter√≠sticas.\nMuestreo: Es el proceso por el cual obtendremos nuestra muestra para un estudio. En estudios experimentales, el muestreo se entiende tambi√©n como el proceso de aleatorizaci√≥n/randomizaci√≥n de unidades experimentales."
  },
  {
    "objectID": "index.html#muestreo-simple-sin-reemplazo",
    "href": "index.html#muestreo-simple-sin-reemplazo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestreo simple sin reemplazo",
    "text": "Muestreo simple sin reemplazo\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#muestreo-simple-con-reemplazo",
    "href": "index.html#muestreo-simple-con-reemplazo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Muestreo simple con reemplazo",
    "text": "Muestreo simple con reemplazo\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#otros-tipos-de-muestreo",
    "href": "index.html#otros-tipos-de-muestreo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Otros tipos de muestreo",
    "text": "Otros tipos de muestreo\n\n\nMuestreo sistem√°tico: consiste en tomar un determinado elemento de la poblaci√≥n siguiendo un patr√≥n. Por ejemplo, escoger los m√∫ltiplos de cuatro enumerados en una lista de posibles individuos de estudio (sol√≠a ser una pr√°ctica com√∫n en ensayos cl√≠nicos).\nMuestreo a conveniencia: consiste en incluir en el estudio a todos los elementos disponibles de la poblaci√≥n de inter√©s. Esto sucede sobre todo con poblaciones escasas o de dificil acceso (ejemplo, realizar estudios en comunidades LGBTIQ+).\nMuestreo estratificado: es una combinaci√≥n del muestreo simple con los sujetos agrupados por alguna caracter√≠stica en com√∫n, por ejemplo sexo, edad, h√°bitat (suele ser usado en exit polls y conteos r√°pidos)."
  },
  {
    "objectID": "index.html#par√°metros-poblacionales-y-estad√≠sticos-muestrales",
    "href": "index.html#par√°metros-poblacionales-y-estad√≠sticos-muestrales",
    "title": "Estad√≠stica aplicada con R",
    "section": "Par√°metros poblacionales y estad√≠sticos muestrales",
    "text": "Par√°metros poblacionales y estad√≠sticos muestrales\n\n\nLos par√°metros poblacionales son caracter√≠sticas de toda una poblaci√≥n (ejemplo, supongamos que el IQ de toda una poblaci√≥n puede estar caracterizado por una media aritm√©tica, \\(\\mu\\), igual a 100, con una desviaci√≥n est√°ndar, \\(\\sigma\\), igual a 15).\nSi tomo una muestra de 100 individuos de dicha poblaci√≥n, podr√≠a tener una media aritm√©tica de esta muestra, \\(\\overline{X}\\), igual a 101.4 y una desviaci√≥n est√°ndar de la muestra, \\(s\\), igual a 13.7.\nEn otras palabras, la \\(\\overline{X}\\) y \\(s\\) son aproximaciones a los valores verdareros de \\(\\mu\\) y \\(\\sigma\\) de esa poblaci√≥n."
  },
  {
    "objectID": "index.html#ley-de-los-n√∫meros-grandes",
    "href": "index.html#ley-de-los-n√∫meros-grandes",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ley de los n√∫meros grandes",
    "text": "Ley de los n√∫meros grandes\n\n\nLa ley de los n√∫meros grandes establece que a medida que aumenta el tama√±o de una muestra, \\(\\overline{X}\\) y \\(s\\) estar√°n m√°s y m√°s cerca de los valores verdaderos \\(\\mu\\) y \\(\\sigma\\).\nEsta es una de las razones por las cuales en la conducci√≥n de experimentos siempre se aconseja el intentar recabar tantas observaciones sea posible.\n\n\n\n\n\nset.seed(123)\nIQ1 &lt;- rnorm(100, mean = 100, sd = 15)\nmean(IQ1)\n\n[1] 101.3561\n\nsd(IQ1)\n\n[1] 13.69224\n\n\n\n\nset.seed(123)\nIQ2 &lt;- rnorm(100000, mean = 100, sd = 15)\nmean(IQ2)\n\n[1] 100.0147\n\nsd(IQ2)\n\n[1] 14.996"
  },
  {
    "objectID": "index.html#distribuci√≥n-de-muestreo",
    "href": "index.html#distribuci√≥n-de-muestreo",
    "title": "Estad√≠stica aplicada con R",
    "section": "Distribuci√≥n de muestreo",
    "text": "Distribuci√≥n de muestreo\n\n\nLa idea de poder medir enormes n√∫meros de individuos es irreal.\nSin embargo, consideremos el siguiente escenario: si en lugar de medir el IQ de 100000 personas, repito el experimento una y otra vez pero en grupos de 5, puedo observar que la distribuci√≥n de las medias aritm√©ticas de todos estos experimentos adopta la forma de una distribuci√≥n normal"
  },
  {
    "objectID": "index.html#distribuci√≥n-de-muestreo-1",
    "href": "index.html#distribuci√≥n-de-muestreo-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Distribuci√≥n de muestreo",
    "text": "Distribuci√≥n de muestreo\n\n\nEsta distribuci√≥n toma el nombre distribuci√≥n de muestreo de la media aritm√©tica.\nLo que nos demuestra es que, incluso ante reducidos n√∫meros de observaciones en una muestra, la media aritm√©tica de esta muestra (\\(\\overline{X}\\)) estar√° pr√≥xima a la media aritm√©tica verdadera de la poblaci√≥n (\\(\\mu\\)).\n\n\n\n\n\n\nTomado de Learning Statistics with R"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central",
    "href": "index.html#teorema-del-l√≠mite-central",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central\n\n\nEl teorema del l√≠mite central establece que siempre que el n√∫mero de observaciones sea lo suficientemente grande, la distribuci√≥n de muestreo de la media aritm√©tica tender√° a ser normal independientemente de si la distribuci√≥n de las observaciones es normal o no.\nEjemplo: supongamos que el ancho del caparaz√≥n de una especie de tortugas est√° comprendido entre 4 y 10 cent√≠metros. En otras palabras, si observamos al azar una tortuga de esta poblaci√≥n, sabemos que el ancho del caparaz√≥n estar√° en este rango. En t√©rminos de una distribuci√≥n, podemos decir que el ancho del caparaz√≥n en una poblaci√≥n de 1000 tortugas podr√≠a verse de esta manera:"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central-1",
    "href": "index.html#teorema-del-l√≠mite-central-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central"
  },
  {
    "objectID": "index.html#teorema-del-l√≠mite-central-2",
    "href": "index.html#teorema-del-l√≠mite-central-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Teorema del l√≠mite central",
    "text": "Teorema del l√≠mite central\n\n\nEs gracias al teorema del l√≠mite central que la mayor parte de m√©todos estad√≠sticos giran alrededor de la normalidad.\nSin embargo, c√≥mo ya hemos mencionado, requiere a veces de un considerable n√∫mero de observaciones para que se cumpla y no todas las veces esto es posible en la pr√°ctica.\nPor ello, en el desarrollo del curso iremos mostrando ejemplos de cuando esto no ocurre y que medidas podemos tomar en tales casos."
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nMedia aritm√©tica\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(\\overline{X}\\)\nMedia aritm√©tica de la muestra\nCalculada de los datos\n\n\n\\(\\mu\\)\nVerdadera media aritm√©tica de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\mu}\\)\nEstimado de la media aritm√©tica de la poblaci√≥n\nS√≠, identica a \\(\\overline{X}\\)\n\n\n\n\\[\n\\overline{X} = \\frac{1}{n}\\sum^{n}_{i=1}\\left(X_i\\right)\n\\]"
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-1",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nDesviaci√≥n est√°ndar\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(s\\)\nDesviaci√≥n est√°ndar de la muestra\nCalculada de los datos\n\n\n\\(\\sigma\\)\nVerdadera desviaci√≥n est√°ndar de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\sigma}\\)\nEstimado de la deviaci√≥n est√°ndar de la poblaci√≥n\nS√≠, pero no es igual a \\(s\\)\n\n\n\n\n\n\\[\ns = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X})^2}\n\\]\n\n\\[\n\\sigma = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2}\n\\]"
  },
  {
    "objectID": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-2",
    "href": "index.html#estimaci√≥n-de-par√°metros-de-poblaci√≥n-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Estimaci√≥n de par√°metros de poblaci√≥n",
    "text": "Estimaci√≥n de par√°metros de poblaci√≥n\nVarianza\n\n\n\n\n\n\n\n\nS√≠mbolo\n¬øQu√© es?\n¬øSabemos qu√© es?\n\n\n\n\n\\(s^2\\)\nVarianza de la muestra\nCalculada de los datos\n\n\n\\(\\sigma^2\\)\nVerdadera varianza de la poblaci√≥n\nCasi nunca es conocida\n\n\n\\(\\hat{\\sigma}^2\\)\nEstimado de la varianza de la poblaci√≥n\nS√≠, pero no es igual a \\(s^2\\)\n\n\n\n\n\n\\[\ns^2 = \\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X})^2\n\\]\n\n\\[\n\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2\n\\]"
  },
  {
    "objectID": "index.html#intervalos-de-confianza",
    "href": "index.html#intervalos-de-confianza",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nC√≥mo hemos visto, los estimados de las verdaderas \\(\\mu\\) y \\(\\sigma\\) (\\(\\hat{\\mu}\\) y \\(\\hat{\\sigma}\\)) provienen de distribuciones de muestreo, y como tales, inherentemente poseen cierto grado de incertidumbre.\nLos intervalos de confianza son medidas que nos permiten tener una idea de esa incertidumbre.\nEn el estudio de la distribuci√≥n normal est√°ndar tenemos el conocimiento que existe un 95% de chances que una cantidad normalmente distribuida colectada al azar, estar√° distante de la media aritm√©tica entre \\(\\pm\\) 1.96 desviaciones est√°ndar.\n\n\n\n\\[\n\\overline{X} - \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\overline{X} + \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]\n\n\nY se interpreta como: con un 95% de confianza, podemos esperar que la media aritm√©tica verdadera de la poblaci√≥n de inter√©s se encuentra contenida entre‚Ä¶\n\n\n\n\n\\[\n\\text{IC}_{95}=\\overline{X} \\pm \\left(1.96\\times\\frac{\\sigma}{\\sqrt{n}}\\right)\n\\]"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-1",
    "href": "index.html#intervalos-de-confianza-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nSin embargo, como mencionamos \\(\\sigma\\) es casi nunca conocido, y es necesario hacer una correcci√≥n a la f√≥rmula anterior. La distribuci√≥n normal trabaja bien baja la presunci√≥n de un numero grande de observaciones.\nEn su lugar, en 1908 el estad√≠stico Gosset parametriz√≥ una distribuci√≥n para muestras peque√±as que asemeja a la normal. Con el tiempo, esta distribuci√≥n adopt√≥ el nombre de Student.\nY es precisamente que la f√≥rmula anterior es corregida con la distribuci√≥n de Student y as√≠ poder calcular intervalos de confianza para muestras peque√±as usando \\(s\\) en lugar de \\(\\sigma\\):\n\n\n\n\\[\n\\text{IC}_{95}=\\overline{X} \\pm \\left(t_{n-1,\\alpha/2}\\times\\frac{s}{\\sqrt{n}}\\right)\n\\]\n\n\nDonde el valor \\(t_{n-1,\\alpha/2}\\) refiere a:\n\n\\(n-1\\): los grados de libertad, igual al n√∫mero de observaciones \\(n\\) de la muestra, menos 1\n\\(\\alpha\\): es el nivel de significancia (probabilidad de obtener un resultado err√≥neo por azar).\nEstos valores en el pasado se encontraban tabulados en libros de texto, hoy contamos con R!"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-2",
    "href": "index.html#intervalos-de-confianza-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\n\nRegresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el \\(\\text{IC}_{95}\\)\n\n\n\n\nIQ_muestra &lt;- c(101, 98, 116, 96, 129)   # muestra\nn &lt;- 5                                   # n√∫mero de observaciones\nt95 &lt;- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%\nx &lt;- mean(IQ_muestra)                    # media aritm√©tica de la muestra\ns &lt;- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra\nls &lt;- x + (t95*s/(n-1))                  # l√≠mite superior del IC95\nli &lt;- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95"
  },
  {
    "objectID": "index.html#intervalos-de-confianza-3",
    "href": "index.html#intervalos-de-confianza-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Intervalos de confianza",
    "text": "Intervalos de confianza\n\nRegresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el \\(\\text{IC}_{95}\\)\n\n\nIQ_muestra &lt;- c(101, 98, 116, 96, 129)   # muestra\nn &lt;- 5                                   # n√∫mero de observaciones\nt95 &lt;- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%\nx &lt;- mean(IQ_muestra)                    # media aritm√©tica de la muestra\ns &lt;- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra\nls &lt;- x + (t95*s/(n-1))                  # l√≠mite superior del IC95\nli &lt;- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95\nprint(paste0(\"Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [\",round(li,0),\", \",round(ls,0),\"]\"))\n\n[1] \"Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [98, 118]\""
  },
  {
    "objectID": "index.html#ejercicios-4.1",
    "href": "index.html#ejercicios-4.1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.1",
    "text": "Ejercicios 4.1\nLa concentraci√≥n media de glucosa en ratones sanos se ha estimado en un rango entre 80 y 100 mg/dL. En un experimento, se han medido las siguientes concentraciones de glucosa en 10 ratones de una l√≠nea gen√©tica se presume tendr√≠a potencial de ser modelo de hiperglucemia despu√©s de unas cuantas m√°s generaciones de cruce selectivo:\n\n\nglc_rat &lt;- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\n\n\n\n\nCalcula la media aritm√©tica \\(\\overline{X}\\), la desviaci√≥n de est√°ndar \\(s\\) y el intervalo de confianza al 95% de la concentraci√≥n de glucosa en estos ratones. Sin recurrir a pruebas estad√≠sticas formales, ¬ødir√≠as que sus niveles de glucosa est√°n dentro de lo normal o hay raz√≥n para desconfiar que son hipergluc√©micos?\nCalcula el \\(\\text{IC}_{95}\\) sin usar la distribuci√≥n de Student y nota la diferencia."
  },
  {
    "objectID": "index.html#hip√≥tesis-de-investigaci√≥n-vs.-hip√≥tesis-estad√≠sticas",
    "href": "index.html#hip√≥tesis-de-investigaci√≥n-vs.-hip√≥tesis-estad√≠sticas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Hip√≥tesis de investigaci√≥n vs.¬†hip√≥tesis estad√≠sticas",
    "text": "Hip√≥tesis de investigaci√≥n vs.¬†hip√≥tesis estad√≠sticas\n\n\nUna hip√≥tesis de investigaci√≥n gira alrededor del desarrollar una conclusi√≥n cient√≠fica acerca de un tema de inter√©s del investigador. Ejemplos: el fumar causa c√°ncer, las vacunas causan/previenen enfermedades.\n\nEs decir, pueden tener una naturaleza subjetiva, que expresan la pregunta del investigador de una manera general sin mayor descripci√≥n del ¬øc√≥mo? voy a probar o descartarla, ni ¬øen qu√© extensi√≥n?.\n\nHip√≥tesis estad√≠sticas, por el contrario, deben ser matem√°ticamente precisas y basadas en las caracter√≠sticas de los datos que recolectemos con el fin de probar o descartar la hip√≥tesis de investigaci√≥n.\n\nC√≥mo es de esperar, el probar o descartar una hip√≥tesis estad√≠stica ser√° √∫nicamente v√°lida para la poblaci√≥n sobre la cual una muestra fue tomada.\nEs ah√≠ donde radica la importancia en definir la poblaci√≥n sujeto de estudio de manera planificada con el objetivo de que cumpla tantos detalles sean necesarios de la hip√≥tesis de investigaci√≥n. Ejemplo, el modelo animal m√°s usado es el rat√≥n. Si bien es cierto constituye uno de los primeros pasos en el desarrollo de muchas investigaciones, los hallazgos en ratones NO pueden ser inmediatamente atribuibles a suceder en seres humanos."
  },
  {
    "objectID": "index.html#hip√≥tesis-nula-y-alternativa",
    "href": "index.html#hip√≥tesis-nula-y-alternativa",
    "title": "Estad√≠stica aplicada con R",
    "section": "Hip√≥tesis nula y alternativa",
    "text": "Hip√≥tesis nula y alternativa\n\n\nLa formulaci√≥n de hip√≥tesis estad√≠sticas puede reducirse a establer preguntas de investigaci√≥n en forma de las hip√≥tesis nula y alternativa.\nLa m√°s sencilla manera de formular esta dupla, es la siguiente. Supongamos que tenemos dos grupos experimentales para probar la eficiencia de un nuevo procedimiento quir√∫rgico. Un grupo de pacientes ser√° sometido a la intervenci√≥n tradicional (control), y el otro grupo al nuevo procedimiento (experimental).\n\nLa hip√≥tesis nula (\\(H_0\\)) establece que: no existe diferencia entre el grupo control y el grupo experimental,\nMientras que la hip√≥tesis alternativa (\\(H_a\\)) establece que: s√≠ existe differencia entre ambos.\n\n\n\n\n\\[\\begin{align}\nH_0& : \\mu_c = \\mu_e& H_0& : \\mu_c- \\mu_e =0 \\\\\nH_a& : \\mu_c \\neq \\mu_e& H_a& : \\mu_c- \\mu_e \\neq 0\n\\end{align}\\]"
  },
  {
    "objectID": "index.html#tipos-de-errores",
    "href": "index.html#tipos-de-errores",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tipos de errores",
    "text": "Tipos de errores\n\n\nAl llevar a cabo pruebas de hip√≥tesis pueden ocurrir errores\n\n\n\n\\[\\begin{array}{|c||c||c|}\n  \\hline\n  & \\text{Acepta }H_{0} & \\text{Rechaza }H_{0} \\\\\n  \\hline\nH_{0}\\text{ es verdadera} & \\text{Desici√≥n correcta} & \\text{Error tipo I} \\\\\n  H_{0}\\text{ es falsa} & \\text{Error tipo II} & \\text{Desici√≥n correcta} \\\\\n   \\hline\n\\end{array}\\]\n\n\n\n¬øDe qu√© depende que aceptemos correctamente o no la hip√≥tesis nula?\n\n\n\nLas pruebas estad√≠sticas dependen de la cantidad de variaci√≥n y la diferencia entre tratamientos a detectar (tama√±o del efecto). La soluci√≥n: aumentar el n√∫mero de observaciones"
  },
  {
    "objectID": "index.html#poder-de-una-prueba-estad√≠stica",
    "href": "index.html#poder-de-una-prueba-estad√≠stica",
    "title": "Estad√≠stica aplicada con R",
    "section": "Poder de una prueba estad√≠stica",
    "text": "Poder de una prueba estad√≠stica\n\n\nEl poder de una prueba estad√≠stica es la probabilidad de rechazar la hip√≥tesis nula cuando esta es de hecho falsa.\nSe puede derivar de la tabla anterior\n\n\n\n\\[\\begin{array}{|c||c||c|}\n  \\hline\n  & \\text{Acepta }H_{0} & \\text{Rechaza }H_{0} \\\\\n  \\hline\nH_{0}\\text{ es verdadera} & 1-\\alpha\\text{ (Prob. decisi√≥n correcta)} & \\alpha\\text{ (Taza Error tipo I)} \\\\\n  H_{0}\\text{ es falsa} & \\beta\\text{ (Taza Error tipo II)} & 1-\\beta\\text{ (Poder)} \\\\\n   \\hline\n\\end{array}\\]\n\n\n\nEn la pr√°ctica, existen f√≥rmulas cerradas para la determinaci√≥n del n√∫mero m√≠nimo de observaciones para alcanzar un poder adecuado (\\(\\ge\\) 80%)."
  },
  {
    "objectID": "index.html#tama√±o-del-efecto",
    "href": "index.html#tama√±o-del-efecto",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tama√±o del efecto",
    "text": "Tama√±o del efecto\n\n\nEl tama√±o del efecto (\\(\\theta\\)) es un valor que por lo general es determinado por el investigador y que puede ser la diferencia de inter√©s a detectar en una prueba estad√≠stica.\nPor simplicidad, vamos a enfocarnos en el ejercicio de los ratones. Supongamos que el investigador est√° interesado en saber cual ser√≠a el n√∫mero de ratones que necesitar√≠a para con un 80% de poder, encontrar una diferencia entre la media aritm√©tica de su muestra y un valor que considera razonable chequear igual a 100 mg/dL. Este √∫ltimo valor viene a ser el \\(\\theta\\).\nLas hip√≥tesis de esta prueba se ver√≠an as√≠\n\n\n\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r = \\theta \\\\\nH_a& : \\mu_c- \\mu_r \\neq \\theta\n\\end{align}\\]\n\n\nSin embargo, la pregunta del investigador a√∫n est√° incompleta. A tu criterio, ¬øqu√© falta?\nAl formular hip√≥tesis, hemos considerado el caso m√°s simple hasta el momento. Pero recordando la idea inicial del experimento de los ratones, la opci√≥n l√≥gica ser√≠a preguntarnos ¬øcu√°ntos ratones necesitamos para estar seguros que la poblaci√≥n sea hipergluc√©mica? (cuyo valor de glucosa en sangre est√© por encima del de un rat√≥n sano)"
  },
  {
    "objectID": "index.html#pruebas-de-dos-colas",
    "href": "index.html#pruebas-de-dos-colas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de dos colas",
    "text": "Pruebas de dos colas\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r = \\theta \\\\\nH_a& : \\mu_c- \\mu_r \\neq \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#pruebas-de-una-cola",
    "href": "index.html#pruebas-de-una-cola",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de una cola",
    "text": "Pruebas de una cola\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r \\ge \\theta \\\\\nH_a& : \\mu_c- \\mu_r &lt; \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#pruebas-de-una-cola-1",
    "href": "index.html#pruebas-de-una-cola-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de una cola",
    "text": "Pruebas de una cola\n\\[\\begin{align}\nH_0& : \\mu_c- \\mu_r \\le \\theta \\\\\nH_a& : \\mu_c- \\mu_r &gt; \\theta\n\\end{align}\\]\n\nImagen tomada de UCLA: Advanced Research Computing"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\n\nRetomando el poder de una prueba estad√≠stica (aunque no es un objetivo de este curso), culminaremos esta secci√≥n ejemplificando un an√°lisis de poder con nuestro ejemplo del IQ de una muestra de participantes de una determinada poblaci√≥n.\nSin entrar en mayor detalle, esto puede lograrse mediante el uso de la librer√≠a pwr\nEl tama√±o del efecto para an√°lisis de poder tiene que ser estandarizado\n\n\n\n\\[\n\\theta = \\frac{\\hat{\\mu}_r-\\hat{\\mu}_c}{s}\n\\]\n\nPara mayor detalle del uso de pwr en an√°lisis de poder, puedes acceder a este recurso"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder-1",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\n\nAcerca del IQ de la muestra de una poblaci√≥n, supongamos que el investigador est√° interesado en saber el n√∫mero de participantes necesarios para conducir un estudio donde se pueda demostrar que un valor de 100 en IQ esta dentro de la media aritm√©tica del IQ de la poblaci√≥n de donde se tom√≥ la muestra.\n\n\n\n\nlibrary(pwr)\n\nIQ_muestra &lt;- c(101, 98, 116, 96, 129)\ns &lt;- sd(IQ_muestra)\nuc &lt;- mean(IQ_muestra)\nur &lt;- 100\n\ntheta &lt;- (ur-uc)/s\n\npwr.t.test(d = theta, \n           sig.level = 0.05,\n           power = 0.80,\n           type = \"one.sample\",\n           alternative = \"two.sided\")"
  },
  {
    "objectID": "index.html#un-ejemplo-de-an√°lisis-de-poder-2",
    "href": "index.html#un-ejemplo-de-an√°lisis-de-poder-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Un ejemplo de an√°lisis de poder",
    "text": "Un ejemplo de an√°lisis de poder\n\nlibrary(pwr)\n\nIQ_muestra &lt;- c(101, 98, 116, 96, 129)\ns &lt;- sd(IQ_muestra)\nuc &lt;- mean(IQ_muestra)\nur &lt;- 100\n\ntheta &lt;- (ur-uc)/s\n\npwr.t.test(d = theta, \n           sig.level = 0.05,\n           power = 0.80,\n           type = \"one.sample\",\n           alternative = \"two.sided\")\n\n\n     One-sample t test power calculation \n\n              n = 26.45135\n              d = 0.5663939\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided"
  },
  {
    "objectID": "index.html#ejercicio-4.2",
    "href": "index.html#ejercicio-4.2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.2",
    "text": "Ejercicio 4.2\nA partir de los estad√≠sticos de muestreo de la muestra de ratones del ejemplo anterior, ¬øcu√°l ser√≠a el n√∫mero de los mismos para en un futuro experimento llevar a cabo una prueba estad√≠stica con al menos 80% de poder si el objetivo es demostrar que de hecho la media aritm√©tica de esta l√≠nea de ratones est√° por encima del l√≠mite superior de 100 mg/dL de glucosa en sangre que se sabe poseen ratones saludables?\n\nglc_rat &lt;- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)"
  },
  {
    "objectID": "index.html#valores-cr√≠ticos-y-el-valor-p",
    "href": "index.html#valores-cr√≠ticos-y-el-valor-p",
    "title": "Estad√≠stica aplicada con R",
    "section": "Valores cr√≠ticos y el valor p",
    "text": "Valores cr√≠ticos y el valor p\n\n\nPero ¬øc√≥mo sabemos si una hip√≥tesis es aceptada o rechazada?\nRegresando al concepto de los intervalos de confianza, los cuartiles de la distribuci√≥n de Student calculados a un nivel de significancia \\(\\alpha\\) son valores cr√≠ticos sobre los cuales se determina el rechazo o aceptaci√≥n de la hip√≥tesis nula.\nEl valor p, describe que tan probable ser√≠a observar resultados de la prueba asumiendo que la hip√≥tesis nula no hubiese sido rechazada. Por ello, a menores valores p, mayor la diferencia estad√≠stica con respecto a la hip√≥tesis alternativa."
  },
  {
    "objectID": "index.html#antes-de-continuar",
    "href": "index.html#antes-de-continuar",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nImagen tomada de aqu√≠"
  },
  {
    "objectID": "index.html#antes-de-continuar-1",
    "href": "index.html#antes-de-continuar-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nEl umbral de 0.05 es una convenci√≥n arbitraria creada por Fischer en los inicios de la estad√≠stica moderna.\nLastimosamente, se ha generalizado la idea de que por m√°s m√≠nima sea la diferencia con respecto a 0.05, esta representa la diferencia entre publicar o no (en el campo acad√©mico), entre lanzar o no un nuevo f√°rmaco/producto al mercado (en la industria).\nEn 2014, debido a un fallo de la corte suprema de justicia de los Estados Unidos que le dio la potestad a los inversionistas de farmace√∫ticas a demandarlas por fallar en reportar efectos secundarios de sus productos a pesar de haber sido hallados estad√≠sticamente no significativos, la Asociaci√≥n Americana de Estad√≠stica (ASA) se vio en la necesidad de definir m√°s exhaustivamente el concepto del valor p.\nEntre las recomendaciones de la ASA, se enfatiz√≥ el dar mayor prioridad a la estimaci√≥n de otros estad√≠sticos complementarios al valor p, tales como intervalos de confianza u otros provenientes de la estad√≠stica Bayesiana (intervalos de credibilidad, factores de Bayes).\nEsta √∫ltima (estad√≠stica Bayesiana), ofrece una interpretaci√≥n m√°s natural de la estad√≠stica al poder interpretar todos sus resultados en t√©rminos de probabilidades y no en n√∫meros arbirtrarios como el valor p.\nEn resumen, una investigaci√≥n no es in√∫til si el valor p sobrepasa o est√° por debajo de 0.05 por cantidades peque√±as."
  },
  {
    "objectID": "index.html#antes-de-continuar-2",
    "href": "index.html#antes-de-continuar-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nEn su lugar, en escenarios en que el valor p est√° alejado por una d√©cima o varias cent√©simas de 0.05, los resultados deber√≠an interpretarse como indeterminados para generalizar sobre la poblaci√≥n objeto de estudio y espec√≠ficos a las condiciones experimentales (an√°lisis estad√≠sticos, instrumentos de medici√≥n, etc) bajo las cuales fueron tomadas y modeladas las mediciones.\nEn el contexto de los modelos estad√≠sticos que veremos m√°s adelante, esto ha derivado en un ‚Äútemor‚Äù del investigador cuando los resultados no pasan los chequeos de los supuestos sobre los que estos modelos se cimentan. Sobre todo cuando el valor p dista de 0.05 por √≠nfimas cantidades.\nEsto puede llevar a malas pr√°cticas cient√≠ficas tales como: no reportar el resultado de los chequeos, blindar los datos, escoger ‚Äúoutliers‚Äù y removerlos y en el peor de los casos, manipular los datos para tratar de acomodar nuestros datos a estos chequeos.\nTodo lo que he mencionado, no solamente constituyen casos de mala conducta cient√≠fica, sino lo que hoy en d√≠a se le conoce como p hacking (que se puede resumir a torturar los datos hasta que nos confiesen una verdad agradable a nuestros prop√≥sitos)."
  },
  {
    "objectID": "index.html#datos-para-esta-secci√≥n",
    "href": "index.html#datos-para-esta-secci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Datos para esta secci√≥n",
    "text": "Datos para esta secci√≥n\n\n\nPara esta secci√≥n del curso usaremos algunas de las tablas de datos del libro Using R for Introductory Statistics, como tambi√©n de la librer√≠a datarium.\nPara ello, instalaremos las librer√≠as de R: UsingR y datarium.\n\n\n\n\nlibrary(UsingR)\nlibrary(datarium)"
  },
  {
    "objectID": "index.html#pruebas-t",
    "href": "index.html#pruebas-t",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas t",
    "text": "Pruebas t\n\n\nLas pruebas t son usadas para encontrar la diferencia entre dos medias aritm√©ticas.\nLa \\(H_0\\) en estas pruebas es que las medias aritm√©ticas son las mismas.\nSe rechaza la \\(H_0\\) cuando el valor p resultante es \\(&lt;\\) 0.05\nExisten tres tipos de pruebas t\n\nPruebas t de una muestra\nPruebas t de muestras independientes\nPruebas t de muestras emparejadas\n\nEstas pruebas fueron desarrolladas bajo la suposici√≥n de la normalidad y de homogeneidad de las varianzas.\nDe acuerdo a lo que hemos visto acerca del teorema del l√≠mite central, muestras grandes casi aseguran la normalidad.\nCuando el n√∫mero de observaciones en una muestra es peque√±o, es recomendable llevar a cabo un test de normalidad para decidir si es posible una prueba t o una de sus alternativas."
  },
  {
    "objectID": "index.html#normalidad-de-una-muestra",
    "href": "index.html#normalidad-de-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Normalidad de una muestra",
    "text": "Normalidad de una muestra\n\n\nAntes de llevar a cabo las pruebas t, hemos mencionado sus supuestos. Por ello, es aconsejable el siempre realizar estas pruebas antes de usarlas.\nExisten dos tipos de pruebas para establecer si una muestra es normalmente distribuida o no\n\nIndirectamente: gr√°fico Q-Q\nPrueba formal de normalidad (ejemplo: Shapiro-Wilk)\n\nEn el caso del ANOVA, es importante enfatizar que estas pruebas no necesariamente tienen que hacerse antes de la prueba, como ya veremos m√°s adelante."
  },
  {
    "objectID": "index.html#gr√°fico-q-q",
    "href": "index.html#gr√°fico-q-q",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°fico Q-Q",
    "text": "Gr√°fico Q-Q\n\n\nEl gr√°fico Q-Q es una prueba visual indirecta de la normalidad.\nConsiste en crear un gr√°fico de dispersi√≥n entre los valores observados de una muestra vs.¬†los valores que deber√≠an estos tener si siguieran una distribuci√≥n normal.\nMientras en el gr√°fico de dispersi√≥n los puntos m√°s se distribuyan a lo largo de una diagonal, m√°s cercanos est√°n los datos de la muestra a seguir un distribuci√≥n normal.\nSu desventaja es que es muy subjetivo, y a menudo requiere una prueba formal para poder confirmarlo."
  },
  {
    "objectID": "index.html#gr√°fico-q-q-1",
    "href": "index.html#gr√°fico-q-q-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°fico Q-Q",
    "text": "Gr√°fico Q-Q\n\nset.seed(123)\ny &lt;- rnorm(n = 30, mean = 0, sd = 1)  # simulamos 30 observaciones de una normal estandar\nqqnorm(y)                             # producimos el gr√°fico Q-Q"
  },
  {
    "objectID": "index.html#gr√°fico-q-q-2",
    "href": "index.html#gr√°fico-q-q-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°fico Q-Q",
    "text": "Gr√°fico Q-Q\n\nset.seed(123)\ny &lt;- rnorm(n = 30, mean = 0, sd = 1)  # simulamos 30 observaciones de una normal estandar\nqqnorm(y)                             # producimos el gr√°fico Q-Q"
  },
  {
    "objectID": "index.html#prueba-de-normalidad-shapiro-wilk",
    "href": "index.html#prueba-de-normalidad-shapiro-wilk",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de normalidad Shapiro-Wilk",
    "text": "Prueba de normalidad Shapiro-Wilk\n\n\nLa \\(H_0\\) de esta prueba (y del resto de pruebas formales de normalidad) es que un set de \\(n\\) observaciones es normalmente distribuido.\nOtro conocido m√©todo es Kolmogorov-Smirnov. Sin embargo, Shapiro-Wilk es m√°s apropiado para cuando el n√∫mero de muestras es menor a 50.\nPara ilustrar su uso, chequeemos la normalidad de los datos que simulamos anteriormente\n\n\n\n\nshapiro.test(y)\n\n\n    Shapiro-Wilk normality test\n\ndata:  y\nW = 0.97894, p-value = 0.7966"
  },
  {
    "objectID": "index.html#prueba-de-homogeneidad-de-las-varianzas",
    "href": "index.html#prueba-de-homogeneidad-de-las-varianzas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de homogeneidad de las varianzas",
    "text": "Prueba de homogeneidad de las varianzas\n\n\nEn el caso de comparaciones entre las medias de dos grupos, la homogeneidad de varianzas puede chequearse usando la prueba F.\nLa prueba t de una muestra no requiere chequear este supuesto.\nPara ilustrar su uso, creemos otro vector con datos simulados. En este caso, un igual n√∫mero de observaciones con la misma desviaci√≥n est√°ndar pero diferente media:\n\n\n\n\nset.seed(123)\nx &lt;- rnorm(n = 30, mean = 4, sd = 1)\nvar.test(x, y)\n\n\n    F test to compare two variances\n\ndata:  x and y\nF = 1, num df = 29, denom df = 29, p-value = 1\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.4759648 2.1009958\nsample estimates:\nratio of variances \n                 1"
  },
  {
    "objectID": "index.html#supuestos-en-la-pr√°ctica",
    "href": "index.html#supuestos-en-la-pr√°ctica",
    "title": "Estad√≠stica aplicada con R",
    "section": "Supuestos en la pr√°ctica",
    "text": "Supuestos en la pr√°ctica\n\n\nUsemos las pruebas con datos reales, esta vez con la tabla de datos crime de la librer√≠a Using R.\nEsta tabla de datos contiene registros de las tasas de crimen (# de reportes/100000 habitantes) en 50 estados en los Estados Unidos correspondiente a los a√±os 1983 y 1993.\nSin enfocarnos por el momento en que prueba t espec√≠fica usaremos, limit√©monos a chequear la normalidad y la homogeneidad de varianzas entre las tasas de crimen registradas en 1983 y 1993.\n\n\n\n\ndata(crime)\n\n\n\nNormalidad 1983\n\nshapiro.test(crime$y1983)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1983\nW = 0.77333, p-value = 1.827e-07\n\n\n\nNormalidad 1993\n\nshapiro.test(crime$y1993)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1993\nW = 0.77348, p-value = 1.841e-07\n\n\n\n\n\n\nHomogeneidad de las varianzas\n\nvar.test(crime$y1983, crime$y1993)\n\n\n    F test to compare two variances\n\ndata:  crime$y1983 and crime$y1993\nF = 0.49163, num df = 50, denom df = 50, p-value = 0.01342\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.2806163 0.8613069\nsample estimates:\nratio of variances \n         0.4916266"
  },
  {
    "objectID": "index.html#transformaci√≥n-de-variables",
    "href": "index.html#transformaci√≥n-de-variables",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaci√≥n de variables",
    "text": "Transformaci√≥n de variables\n\n\nA menudo nos encontraremos con conjuntos de observaciones que no cumplen uno o ninguno de los supuestos.\nAntes de considerar pruebas no param√©tricas, podemos intentar transformaciones de variables para regresar al mundo de las pruebas param√©tricas. Las transformaciones m√°s usadas son:\n\nLa ra√≠z cuadrada (si los datos no contienen n√∫meros negativos)\nElevar al cuadrado\nLogaritmo (si los datos solo incluyen n√∫meros reales positivos, cero excluido)"
  },
  {
    "objectID": "index.html#transformaci√≥n-de-variables-1",
    "href": "index.html#transformaci√≥n-de-variables-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaci√≥n de variables",
    "text": "Transformaci√≥n de variables\n\n\nExiste un m√©todo m√°s sofisticado para ‚Äúnormalizar‚Äù una muestra. La transformaci√≥n de Box-Cox.\nCuando se trabaja con muestras transformadas, el objetivo es poder revertir la transformaci√≥n a las unidades reales para as√≠ poder hacer conclusiones sobre las inferencias estad√≠sticas.\nEn otras palabras, una misma transformaci√≥n debe aplicarse a todos los grupos a ser comparados. NO tiene ning√∫n sentido tratar de realizar inferencias entre grupos donde se hayan usado distintas transformaciones para normalizarlos.\nSi el n√∫mero de observaciones es muy reducido, usualmente no hay transformaci√≥n que funcione y se recomienda usar directamente pruebas no param√©tricas."
  },
  {
    "objectID": "index.html#transformaci√≥n-de-variables-2",
    "href": "index.html#transformaci√≥n-de-variables-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaci√≥n de variables",
    "text": "Transformaci√≥n de variables\n\n\nRa√≠z cuadrada\n\nshapiro.test(sqrt(crime$y1983))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  sqrt(crime$y1983)\nW = 0.9411, p-value = 0.01359\n\n\n\nElevar al cuadrado\n\nshapiro.test(crime$y1983^2)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  crime$y1983^2\nW = 0.38921, p-value = 2.954e-13\n\n\n\n\n\n\nLogaritmo\n\nshapiro.test(log(crime$y1983))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  log(crime$y1983)\nW = 0.98076, p-value = 0.5713\n\n\n\nChequeemos con el otro grupo\n\nshapiro.test(log(crime$y1993))     \n\n\n    Shapiro-Wilk normality test\n\ndata:  log(crime$y1993)\nW = 0.96191, p-value = 0.1006\n\n\n\n\n\nHomogeneidad de las varianzas con transformaci√≥n logar√≠tmica\n\nvar.test(log(crime$y1983), log(crime$y1993))\n\n\n    F test to compare two variances\n\ndata:  log(crime$y1983) and log(crime$y1993)\nF = 0.84048, num df = 50, denom df = 50, p-value = 0.5412\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.4797393 1.4724831\nsample estimates:\nratio of variances \n         0.8404808"
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra",
    "href": "index.html#prueba-t-de-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\n\nEs usada para comparar la media aritm√©tica de una muestra con un valor conocido (un est√°ndar por ejemplo).\nPor lo general el valor al que se va a comparar proviene de referencias bibliogr√°ficas, pre-experimentos o supociones fundamentadas.\nEn este caso, el supuesto que debe cumplirse es el de la normalidad de los datos\nRegresando a nuestro ejemplo de los ratones, determinemos si la media de la muestra es mayor al l√≠mite superior de glucosa de ratones saludables."
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra-1",
    "href": "index.html#prueba-t-de-una-muestra-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\nglc_rat &lt;- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\nt.test(glc_rat,\n       mu = 100,\n       alternative = \"greater\")"
  },
  {
    "objectID": "index.html#prueba-t-de-una-muestra-2",
    "href": "index.html#prueba-t-de-una-muestra-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de una muestra",
    "text": "Prueba t de una muestra\n\nglc_rat &lt;- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)\nt.test(glc_rat,\n       mu = 100,\n       alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  glc_rat\nt = -1.4485, df = 9, p-value = 0.9093\nalternative hypothesis: true mean is greater than 100\n95 percent confidence interval:\n 76.16687      Inf\nsample estimates:\nmean of x \n    89.48"
  },
  {
    "objectID": "index.html#ejercicio-4.3",
    "href": "index.html#ejercicio-4.3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.3",
    "text": "Ejercicio 4.3\nLa tabla de datos blood de la librer√≠a UsingR tiene las medidas de presi√≥n sist√≥lica de sangre correspondientes a 15 pacientes (columna ‚Äúmachine‚Äù). De acuerdo al Centro de Prevenci√≥n y Control de Enfermedades de los Estados Unidos (CDC), una presi√≥n sist√≥lica saludable est√° por debajo de 120 mm Hg. Determina si la media de la muestra contenida en esta tabla de datos est√° por debajo de este valor sugerido por el CDC.\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre blood aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(blood)\nblood\n\nTip: para acceder a la columna con las presiones sist√≥licas, usa la siguiente sintaxis: blood$machine"
  },
  {
    "objectID": "index.html#prueba-t-de-muestras-independientes",
    "href": "index.html#prueba-t-de-muestras-independientes",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de muestras independientes",
    "text": "Prueba t de muestras independientes\n\n\nEs usado para comparar las medias aritm√©ticas de dos grupos independientes.\nPor ejemplo, si deseas comparar las medias aritm√©ticas de individuos agrupados por sexo.\nPara ilustrar esta prueba, vamos a hacer uso de la tabla de datos de genderweight de la librer√≠a datarium.\n\nVeamos si existe una diferencia significativa en la media del peso entre hombres y mujeres\n\n\n\n\n\ndata(genderweight)"
  },
  {
    "objectID": "index.html#prueba-t-de-muestras-independientes-1",
    "href": "index.html#prueba-t-de-muestras-independientes-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de muestras independientes",
    "text": "Prueba t de muestras independientes\n\n\nChequeamos normalidad: Group M\n\nshapiro.test(subset(genderweight, group == \"M\")$weight)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  subset(genderweight, group == \"M\")$weight\nW = 0.98634, p-value = 0.9886\n\n\n\nChequeamos normalidad: Group F\n\nshapiro.test(subset(genderweight, group == \"F\")$weight)     \n\n\n    Shapiro-Wilk normality test\n\ndata:  subset(genderweight, group == \"F\")$weight\nW = 0.93847, p-value = 0.2243\n\n\n\n\n\nChequeamos la homogeneidad de las varianzas\n\nvar.test(genderweight$weight ~ genderweight$group)\n\n\n    F test to compare two variances\n\ndata:  genderweight$weight by genderweight$group\nF = 0.21692, num df = 19, denom df = 19, p-value = 0.001648\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.08585766 0.54802553\nsample estimates:\nratio of variances \n         0.2169152 \n\n\n\n\n¬°La homogeneidad de las varianzas no se cumple! üò±\n¬øDebemos transformar? No necesariamente\nEl no cumplir con el supuesto de la homogeneidad de varianzas no es un gran problema gracias a varias correcciones.\nLa funci√≥n base de R t.test cuenta con el argumento var.equal = F como default.\nBajo este argumento, no se asumen varianzas iguales entre los grupos y en su lugar R lleva a cabo la aproximaci√≥n de Welch para lidiar con este problema."
  },
  {
    "objectID": "index.html#prueba-t-de-muestras-independientes-2",
    "href": "index.html#prueba-t-de-muestras-independientes-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t de muestras independientes",
    "text": "Prueba t de muestras independientes\n\nt.test(genderweight$weight ~ genderweight$group)\n\n\n    Welch Two Sample t-test\n\ndata:  genderweight$weight by genderweight$group\nt = -20.791, df = 26.872, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -24.53135 -20.12353\nsample estimates:\nmean in group F mean in group M \n       63.49867        85.82612"
  },
  {
    "objectID": "index.html#ejercicio-4.4",
    "href": "index.html#ejercicio-4.4",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.4",
    "text": "Ejercicio 4.4\nLa tabla de datos normtemp de la librer√≠a UsingR tiene las medidas en grados Fahrenheit de temperatura corporal (columna ‚Äútemperature‚Äù ) correspodientes a 65 mujeres y 65 hombres (columna ‚Äúgender‚Äù). Determina si existe una diferencia entre las temperaturas corporales de hombres y mujeres.\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre normtemp aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(normtemp)\nnormtemp\n\nTip: para acceder a las columnas con las temperaturas corporales y sexo, usa la siguiente sintaxis: normtemp$temperature y normtemp$gender respectivamente"
  },
  {
    "objectID": "index.html#prueba-t-para-muestras-emparejadas",
    "href": "index.html#prueba-t-para-muestras-emparejadas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t para muestras emparejadas",
    "text": "Prueba t para muestras emparejadas\n\n\nEs usado para comparar las medias de dos grupos que guardan una relaci√≥n.\nEsto solo ocurre cuando las medidas se han realizado a partir de los mismos grupos. Por ejemplo, al inicio y al final de un experimento.\nPara esta prueba, vamos a usar la tabla de datos crime de la librer√≠a UsingR\n\nVeamos si existe una diferencia en las tasas de crimen (# de reportes/100000 habitantes) en 50 estados de los Estados unidos entre 1983 y 1993\n\n\n\n\n\ndata(crime)"
  },
  {
    "objectID": "index.html#prueba-t-para-muestras-emparejadas-1",
    "href": "index.html#prueba-t-para-muestras-emparejadas-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t para muestras emparejadas",
    "text": "Prueba t para muestras emparejadas\n\nt.test(x = log(crime$y1983), y = log(crime$y1993), paired = TRUE)\nexp(mean(log(crime$y1983)))\nexp(mean(log(crime$y1993)))"
  },
  {
    "objectID": "index.html#prueba-t-para-muestras-emparejadas-2",
    "href": "index.html#prueba-t-para-muestras-emparejadas-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba t para muestras emparejadas",
    "text": "Prueba t para muestras emparejadas\n\nt.test(x = log(crime$y1983), y = log(crime$y1993), paired = TRUE)\n\n\n    Paired t-test\n\ndata:  log(crime$y1983) and log(crime$y1993)\nt = -10.027, df = 50, p-value = 1.469e-13\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.3628437 -0.2417349\nsample estimates:\nmean difference \n     -0.3022893 \n\nexp(mean(log(crime$y1983)))\n\n[1] 362.8298\n\nexp(mean(log(crime$y1993)))\n\n[1] 490.8915"
  },
  {
    "objectID": "index.html#ejercicio-4.5",
    "href": "index.html#ejercicio-4.5",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.5",
    "text": "Ejercicio 4.5\nLa tabla de datos mice2 de la librer√≠a datarium tiene las medidas del peso de 10 ratones antes y despu√©s de haber sido sometidos a una determinada dieta. Encuentra si existe una diferencia significativa en el peso de estos ratones antes y despu√©s del r√©gimen de dieta al que fueron expuestos. ¬øGanaron o perdieron peso?\nCopia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre mice2 aparecer√° disponible en la ventana del ambiente de RStudio\n\ndata(mice2)\nmice2\n\nTip: usa el mismo tips de los ejemplos anteriores"
  },
  {
    "objectID": "index.html#ejercicios-4.6",
    "href": "index.html#ejercicios-4.6",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.6",
    "text": "Ejercicios 4.6\n\nEn la librer√≠a UsingR tenemos disponible una lista con 5 objetos bajo el nombre cancer. Esta contiene el tiempo de sobreviviencia en d√≠as de pacientes con distintos tipos de c√°ncer desde el momento de su diagn√≥stico hasta su deceso. Chequea si los datos correspondientes a c√°ncer de colon son normalmente distribuidos. Si no lo son, prueba si puedes normalizarlos usando alguna de las tres transformaciones que vimos. En el caso que m√°s de una transformaci√≥n funcione, ¬øcu√°l escoger√≠as para continuar con alguna prueba estad√≠stica, y por qu√©?\n\nTip: usa el siguiente c√≥digo para extraer en un vector los datos de pacientes con c√°ncer de colon:\n\ndata(cancer)\ncolon &lt;- cancer$colon"
  },
  {
    "objectID": "index.html#pruebas-de-wilcoxon-para-datos-no-normales",
    "href": "index.html#pruebas-de-wilcoxon-para-datos-no-normales",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas de Wilcoxon para datos no normales",
    "text": "Pruebas de Wilcoxon para datos no normales\n\n\nLas pruebas de Wilcoxon usan la mediana como criterio para evaluar la \\(H_0\\).\nLastimosamente, estas pruebas son usualmente menos poderosas (mayor tasa de errores tipo II).\nTiene dos formas:\n\nPruebas para una muestra (an√°loga a la prueba t para una muestra)\nPruebas para dos muestras (an√°loga a las pruebas t para dos muestras independientes y emparejadas)"
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-una-muestra",
    "href": "index.html#prueba-de-wilcoxon-para-una-muestra",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para una muestra",
    "text": "Prueba de Wilcoxon para una muestra\n\n\nProf.¬†Danielle Navarro midi√≥ el nivel de felicidad de sus estudiantes antes y despu√©s de su clase de Estad√≠stica. Ella estaba interesada en saber si el tomar una clase de Estad√≠stica tiene alg√∫n efecto en la felicidad de sus estudiantes. Los datos que obtuvo no est√°n normalmente distribuidos. Por ello, se vio en la necesidad de llevar a cabo una prueba de Wilcoxon.\nEn este caso, la \\(H_0\\), es que la diferencia de la mediana de la felicidad de sus estudiantes antes y despu√©s de la clase deber√≠a ser igual a cero para clamar que no existe tal efecto."
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-una-muestra-1",
    "href": "index.html#prueba-de-wilcoxon-para-una-muestra-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para una muestra",
    "text": "Prueba de Wilcoxon para una muestra\n\n# Primero recreo la tabla de Prof. Navarro\nfelicidad &lt;- data.frame(before = c(30,43,21,24,23,40,29,56,38,16),\n                        after = c(6,29,11,31,17,2,31,21,8,21))\nfelicidad$change &lt;- felicidad$after - felicidad$before\n\nwilcox.test(felicidad$change, mu = 0)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  felicidad$change\nV = 7, p-value = 0.03711\nalternative hypothesis: true location is not equal to 0"
  },
  {
    "objectID": "index.html#prueba-de-wilcoxon-para-dos-muestras",
    "href": "index.html#prueba-de-wilcoxon-para-dos-muestras",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Wilcoxon para dos muestras",
    "text": "Prueba de Wilcoxon para dos muestras\n\n\nRegresando al ejemplo de la tabla de datos genderweight, supongamos que estos no est√°n normalmente distribuidos.\nUsaremos la prueba de Wilcoxon para muestras independientes para ver si existe diferencia entre los pesos de hombres y mujeres.\n\n\n\n\nwilcox.test(genderweight$weight ~ genderweight$group, paired = F)\n\n\n    Wilcoxon rank sum exact test\n\ndata:  genderweight$weight by genderweight$group\nW = 0, p-value = 1.451e-11\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "index.html#ejercicios-4.7",
    "href": "index.html#ejercicios-4.7",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.7",
    "text": "Ejercicios 4.7\n\nCon el vector de nombre colon que creaste en el ejercicio 4.6, aplica una prueba de Wilcoxon para una muestra bajo la hip√≥tesis de que la mediana de los d√≠as de superviviencia de un paciente con c√°ncer de colon es de 370 d√≠as.\nA partir de la tabla de datos de felicidad de la Prof.¬†Navarro, lleva a cabo una prueba de Wilcoxon para dos muestras emparejadas de la felicidad de los estudiantes antes y despu√©s de recibir una clase de Estad√≠stica. Compara el resultado con la prueba de una muestra que us√© de ejemplo. ¬øPor qu√© no hay diferencia?."
  },
  {
    "objectID": "index.html#introducci√≥n",
    "href": "index.html#introducci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\n\n\nPara valores discretos univariados tenemos:\n\nEstad√≠sticos descriptivos\nPrueba de bondad de ajuste de \\(\\chi^2\\)\n\nPara datos discretos bivariados arreglados en Tablas de contingencia tenemos:\n\nPrueba de independencia de \\(\\chi^2\\)\nPrueba exacta de Fisher"
  },
  {
    "objectID": "index.html#revisitando-los-estad√≠sticos-descriptivos",
    "href": "index.html#revisitando-los-estad√≠sticos-descriptivos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Revisitando los estad√≠sticos descriptivos",
    "text": "Revisitando los estad√≠sticos descriptivos\n\n\nRecordar√°n que en m√≥dulo de an√°lisis exploratorio de datos vimos los estad√≠sticos descriptivos usando la funci√≥n base summary.\nSin embargo, para los fines del AED, summary es suficiente para tener una idea de estos estad√≠sticos pero su exportaci√≥n a tablas de Word es un proceso tedioso.\nAprovechando esta oportunidad, vamos a ver una forma de ver a los estad√≠sticos descriptivos con la posibilidad de exportarlos a Word de una manera sencilla.\nPara ello usaremos la librer√≠a tidycomm, flextable y palmerpenguins.\n\n\n\n\nlibrary(tidycomm)\nlibrary(palmerpenguins)\nlibrary(flextable)\n\ndata(\"penguins\")\npenguins_cat &lt;- describe_cat(penguins)\npenguins_cat\n\n# A tibble: 3 √ó 6\n  Variable     N Missing Unique Mode   Mode_N\n  &lt;chr&gt;    &lt;int&gt;   &lt;int&gt;  &lt;int&gt; &lt;chr&gt;   &lt;int&gt;\n1 species    344       0      3 Adelie    152\n2 island     344       0      3 Biscoe    168\n3 sex        333      11      3 male      168"
  },
  {
    "objectID": "index.html#tablas-de-estad√≠sticos-descriptivos",
    "href": "index.html#tablas-de-estad√≠sticos-descriptivos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tablas de estad√≠sticos descriptivos",
    "text": "Tablas de estad√≠sticos descriptivos\nTablas de estad√≠sticos descriptivos de variables continuas\n\npenguins_con &lt;- describe(penguins)\npenguins_con\n\n# A tibble: 5 √ó 15\n  Varia‚Ä¶¬π     N Missing      M      SD    Min    Q25    Mdn    Q75    Max  Range\n  &lt;chr&gt;   &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 bill_l‚Ä¶   342       2   43.9   5.46    32.1   39.2   44.4   48.5   59.6   27.5\n2 bill_d‚Ä¶   342       2   17.2   1.97    13.1   15.6   17.3   18.7   21.5    8.4\n3 flippe‚Ä¶   342       2  201.   14.1    172    190    197    213    231     59  \n4 body_m‚Ä¶   342       2 4202.  802.    2700   3550   4050   4750   6300   3600  \n5 year      344       0 2008.    0.818 2007   2007   2008   2009   2009      2  \n# ‚Ä¶ with 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;,\n#   Kurtosis &lt;dbl&gt;, and abbreviated variable name ¬π‚ÄãVariable\n\n\n\n\ntabla1 &lt;- flextable(penguins_cat)\ntabla2 &lt;- flextable(penguins_con)\ntabla2\n\n\nVariableNMissingMSDMinQ25MdnQ75MaxRangeCI_95_LLCI_95_ULSkewnessKurtosisbill_length_mm342243.921935.459583732.139.22544.4548.559.627.543.3412544.502610.052884812.119235bill_depth_mm342217.151171.974793213.115.60017.3018.721.58.416.9411317.36121-0.142834632.088845flipper_length_mm3422200.9152014.0617137172.0190.000197.00213.0231.059.0199.41960202.410810.344163832.012566body_mass_g34224,201.75439801.95453572,700.03,550.0004,050.004,750.06,300.03,600.04,116.458334,287.050440.468263962.273757year34402,008.029070.81835592,007.02,007.0002,008.002,009.02,009.02.02,007.942282,008.11586-0.053493211.499457\n\n\n\n\n\ntabla1 &lt;- flextable(penguins_cat)\ntabla2 &lt;- flextable(penguins_con)\ntabla2 &lt;- colformat_double(tabla2, j = c(3:15), digits = 2)\ntabla2\n\n\nVariableNMissingMSDMinQ25MdnQ75MaxRangeCI_95_LLCI_95_ULSkewnessKurtosisbill_length_mm342243.925.4632.1039.2344.4548.5059.6027.5043.3444.500.052.12bill_depth_mm342217.151.9713.1015.6017.3018.7021.508.4016.9417.36-0.142.09flipper_length_mm3422200.9214.06172.00190.00197.00213.00231.0059.00199.42202.410.342.01body_mass_g34224,201.75801.952,700.003,550.004,050.004,750.006,300.003,600.004,116.464,287.050.472.27year34402,008.030.822,007.002,007.002,008.002,009.002,009.002.002,007.942,008.12-0.051.50\n\nsave_as_docx(\"Tabla1\" = tabla1, \"Tabla2\" = tabla2,\n             path = \"C:/Users/mmore/Documents/cursos_uce_2023/modulos/uce2023-modulo4/descriptivos.docx\")"
  },
  {
    "objectID": "index.html#prueba-de-bondad-de-ajuste-chi2",
    "href": "index.html#prueba-de-bondad-de-ajuste-chi2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de bondad de ajuste \\(\\chi^2\\)",
    "text": "Prueba de bondad de ajuste \\(\\chi^2\\)\n\n\nPermite el comparar que tan bien se ajustan las proporciones (probabilidades) observadas en las categor√≠as de una variable discreta con respecto de una probabilidad hipot√©tica de estas.\nVolviendo con los ping√ºinos de Palmer, supongamos que quisieramos probar que la distribuci√≥n observada de estos a lo largo de las tres islas donde fueron encontrados es igual 1/3 por isla.\nLa \\(H_0\\) ser√≠a: encontramos la misma proporci√≥n de ping√ºinos en cada isla (1/3 = 1/3 = 1/3)\n\n\n\n\nChecamos cu√°ntos ping√ºinos fueron observados por isla\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\n\n\nLlevamos a cabo la prueba de bondad de ajuste de \\(\\chi^2\\)\n\n\npenguins_isla &lt;- c(168, 124, 52)\nchisq.test(penguins_isla, p = c(1/3, 1/3, 1/3))\n\n\n    Chi-squared test for given probabilities\n\ndata:  penguins_isla\nX-squared = 59.814, df = 2, p-value = 1.027e-13"
  },
  {
    "objectID": "index.html#tablas-de-contingencia",
    "href": "index.html#tablas-de-contingencia",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tablas de contingencia",
    "text": "Tablas de contingencia\n\n\nUna tabla de contigencia nos sirve para ver si los valores de una variable categ√≥rica dependen de los valores de otra variable categ√≥rica.\n\n¬øQu√© tan probable es que beban m√°s alcohol personas que fuman con respecto a aquellas que no?\n¬øLas personas que toman una aspirina diaria tienen menos probabilidad de sufrir un ataque card√≠aco con respecto a las que no?\n¬øDurante la tragedia del Titanic, tuvieron tanto hombres como mujeres los mismos chances de salvarse?"
  },
  {
    "objectID": "index.html#tabla-de-contingencia-n-times-n",
    "href": "index.html#tabla-de-contingencia-n-times-n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tabla de contingencia \\(n \\times n\\)",
    "text": "Tabla de contingencia \\(n \\times n\\)\n\n\n\n\n\n\nModificado de Milo≈° Gejdo≈°, et al. (2019) Int. J. Environ. Res. Public Health 16(1)"
  },
  {
    "objectID": "index.html#prueba-de-independencia-de-chi2",
    "href": "index.html#prueba-de-independencia-de-chi2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de independencia de \\(\\chi^2\\)",
    "text": "Prueba de independencia de \\(\\chi^2\\)\n\n\nPuede usarse con 2 variables discretas con m√°s de dos categor√≠as.\nLa \\(H_0\\) en esta prueba es que las filas y columnas de la tabla de contingencia son independientes.\n\n\n\n\nConstruimos la tabla de contingencia\n\n\ncont_tabla &lt;- xtabs(~ island + species, data = penguins)\ncont_tabla\n\n           species\nisland      Adelie Chinstrap Gentoo\n  Biscoe        44         0    124\n  Dream         56        68      0\n  Torgersen     52         0      0\n\n\n\n\n\nLlevamos a cabo la prueba de independencia de \\(\\chi^2\\)\n\n\nchisq &lt;- chisq.test(cont_tabla)\nchisq\n\n\n    Pearson's Chi-squared test\n\ndata:  cont_tabla\nX-squared = 299.55, df = 4, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "index.html#dependencia-entre-las-filas-y-las-columnas",
    "href": "index.html#dependencia-entre-las-filas-y-las-columnas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Dependencia entre las filas y las columnas",
    "text": "Dependencia entre las filas y las columnas\n\n\nExtraemos los residuos (residuos) de la prueba \\(\\chi^2\\)\n\n\nresiduos &lt;- chisq$residuals\n\n\n\n\nCon ayuda de la librer√≠a corrplot podemos ver a las dependencias una por una\n\n\nlibrary(corrplot)\ncorrplot(residuos, is.corr = F)"
  },
  {
    "objectID": "index.html#ejercicio-4.8",
    "href": "index.html#ejercicio-4.8",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.8",
    "text": "Ejercicio 4.8\nLa tabla de datos housetasks tiene una tabla de contingencia con dos variables discretas, en las filas: tareas del hogar, y en las columnas: responsable (de llevarlas a cabo). Las celdas de esta tabla cuentan el n√∫mero de veces que estas preguntas fueron contestadas en una encuesta. Para acceder a esta tabla, copia, pega y ejecuta las siguientes l√≠neas de c√≥digo:\n\nfile_path &lt;- \"http://www.sthda.com/sthda/RDoc/data/housetasks.txt\"\nhousetasks &lt;- read.delim(file_path, row.names = 1)\n\nRealiza una prueba de independencia de \\(\\chi^2\\) en esta tabla de contigencia."
  },
  {
    "objectID": "index.html#prueba-exacta-de-fisher",
    "href": "index.html#prueba-exacta-de-fisher",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba exacta de Fisher",
    "text": "Prueba exacta de Fisher\n\n\nEs usada cuando el conteo de las combinaciones de las clases de dos variables discretas es peque√±o. Cuando este n√∫mero es muy grande, la funci√≥n de R fisher.test devuelve un mensaje sugiriendo usar otra prueba estad√≠stica en su lugar.\nTambi√©n se puede usar cuando las variables discretas tienen varias categor√≠as. Sin embargo, su uso m√°s com√∫n es en tablas de contingencia 2 .\nEsto √∫ltimo por cu√°nto introduce un estad√≠stico conocido como cociente de probabilidades (en ingl√©s: odds ratio) que sirve para hacer conclusiones interesantes."
  },
  {
    "objectID": "index.html#tabla-de-contingencia-2-times-2",
    "href": "index.html#tabla-de-contingencia-2-times-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Tabla de contingencia \\(2 \\times 2\\)",
    "text": "Tabla de contingencia \\(2 \\times 2\\)\n\n\n\n\n\n\n\nLa variable B (o respuesta) contendr√° como posibles resultados ‚Äú√©xito‚Äù o ‚Äúfracaso‚Äù.\nLa variable A (o explanatoria) posee las clases que identifican los grupos cuya probabilidad es sujeto de comparaci√≥n.\n\n\n\nModificado de Milo≈° Gejdo≈°, et al. (2019) Int. J. Environ. Res. Public Health 16(1)"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2",
    "href": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)",
    "text": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)\n\n\nEl cociente de probabilidad mide la magnitud de asociaci√≥n entre dos variables categ√≥ricas cuando estas tienen dos clases (categor√≠as).\nEn una tabla de contingencia \\(2 \\times 2\\), el cociente de probabilidad (OR) se define como:\n\n\n\n\\[ OR=\\frac{n_{11}/n_{12}}{n_{21}/n_{22}} \\]"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2-1",
    "href": "index.html#cociente-de-probabilidad-para-tablas-de-contingencia-2-times-2-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)",
    "text": "Cociente de probabilidad para tablas de contingencia \\(2 \\times 2\\)\n\n\nLa interpretaci√≥n del OR depende de la magnitud del mismo:\n\nIgual a 1, los eventos (clase de la variable explanatoria) son independientes de la variable de respuesta.\nMayor o menor a 1, existe una relaci√≥n positiva o negativa de la variable explanatoria con la variable de respuesta.\nLa magnitud de OR depende de la clase tomada como referencia en el an√°lisis.\nLos coecientes de probabilidad son m√°s f√°ciles de interpretar cuando son \\(\\ge\\) 1"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-en-r",
    "href": "index.html#cociente-de-probabilidad-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad en R",
    "text": "Cociente de probabilidad en R\n\nUsaremos para este ejemplo los datos del Titanic. La pregunta de investigaci√≥n es: ¬øtuvieron las mujeres mayores chances de salvarse durante el hundimiento del Titanic?\n\n\n\nCargamos en nuestro ambiente la tabla de datos (librer√≠a datarium)\n\n\ndata(titanic.raw)\n\n\n\n\nDefinimos las clases de referencia\n\n\ntitanic.raw$Survived &lt;- relevel(titanic.raw$Survived, ref = \"Yes\")\ntitanic.raw$Sex &lt;- relevel(titanic.raw$Sex, ref = \"Female\")"
  },
  {
    "objectID": "index.html#cociente-de-probabilidad-en-r-1",
    "href": "index.html#cociente-de-probabilidad-en-r-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Cociente de probabilidad en R",
    "text": "Cociente de probabilidad en R\n\n\n\nCreamos la tabla de contingencia\n\n\ntabla_cont &lt;- table(titanic.raw$Sex, titanic.raw$Survived)\n\n\n\n\ntabla_cont\n\n        \n          Yes   No\n  Female  344  126\n  Male    367 1364\n\n\n\n\n\n\n\n\nCalculamos el OR\n\n\noddratio &lt;- fisher.test(tabla_cont)\n\n\n\n\noddratio \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tabla_cont\np-value &lt; 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  7.97665 12.92916\nsample estimates:\nodds ratio \n   10.1319"
  },
  {
    "objectID": "index.html#c√≥mo-interpretamos-estos-resultados",
    "href": "index.html#c√≥mo-interpretamos-estos-resultados",
    "title": "Estad√≠stica aplicada con R",
    "section": "¬øC√≥mo interpretamos estos resultados?",
    "text": "¬øC√≥mo interpretamos estos resultados?\n\n\n\n\noddratio\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  tabla_cont\np-value &lt; 2.2e-16\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  7.97665 12.92916\nsample estimates:\nodds ratio \n   10.1319 \n\n\n\n\n\nVemos que el cociente de probabilidad (OR) es 10. La interpretaci√≥n es: durante el hundimiento del Titanic fue 10 veces m√°s probable que un pasajero se salve si este era mujer.\nAdicionalmente, del valor p de la prueba estad√≠stica exacta de Fisher menor al 0.05, se puede concluir que este cociente de probabilidad es significativo. En otras palabras, existe evidencia estad√≠stica significativa para afirmar que las probabilidades de sobrevivir durante el hundimiento del Titanic fueron 10 veces m√°s para pasajeras mujeres en comparaci√≥n a los hombres."
  },
  {
    "objectID": "index.html#introducci√≥n-1",
    "href": "index.html#introducci√≥n-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\n\n\nHasta el momento nos hemos enfocado a los casos donde comparamos las medias entre dos grupos.\nPero es m√°s com√∫n el evaluar distintos tratamientos al mismo tiempo, como ya vimos en el m√≥dulo 2 del curso.\nPara ello, contamos con el ANOVA, desarrollado por el estad√≠stico Ronald Fisher a inicios del siglo 20, y que sin duda es el m√©todo estad√≠stico m√°s usado hoy en d√≠a.\nSu nombre puede ser confuso. El objetivo de un ANOVA es el de determinar la existencia de diferencias entre las medias aritm√©ticas de las muestras representativas de \\(n\\) poblaciones (o en t√©rminos m√°s precisos, tratamientos)."
  },
  {
    "objectID": "index.html#supuestos-del-anova",
    "href": "index.html#supuestos-del-anova",
    "title": "Estad√≠stica aplicada con R",
    "section": "Supuestos del ANOVA",
    "text": "Supuestos del ANOVA\n\n\nIndependencia de los datos: conseguida mediante una correcta randomizaci√≥n y definici√≥n del experimento.\nHomogeneidad de las varianzas: la varianza entre los tratamientos es la misma.\nNormalidad: pero, ¬øde qu√© exactamente?\n\n\nSiempre ha existido una confusi√≥n de este supuesto. C√≥mo vimos antes, la normalidad es un requisito para conducir pruebas t, y lo es tambi√©n para el ANOVA.\nMuchos libros de texto y otros recursos, mencionan que los datos de cada tratamiento deben ser normalmente distribuidos para llevar a cabo un ANOVA. Esto es cierto e impr√°ctico a la vez.\nMencionamos que como m√≠nimo deber√≠amos contar con 3 repeticiones por tratamiento. Pero, ¬øson 3 repeticiones suficientes para alcanzar la normalidad?\nEs com√∫n el sugerir el llevar a cabo una prueba de normalidad antes de un ANOVA, pero esto tiene varios problemas que supongo no te han dicho antes:\n\nCada tratamiento tiene su propia media, en caso de medias muy distantes entre s√≠, la prueba puede fallar.\nEn su lugar, podr√≠as correr una prueba por cada tratamiento. Esto solo funciona con un considerable n√∫mero de observaciones/tratamiento (3 no son suficientes)."
  },
  {
    "objectID": "index.html#supuestos-del-anova-1",
    "href": "index.html#supuestos-del-anova-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Supuestos del ANOVA",
    "text": "Supuestos del ANOVA\n\n\nEsta confusi√≥n nos puede llevar a soluciones err√≥neas como transformar datos, borrar outliers o utilizar pruebas no param√©tricas innecesariamente.\nEntonces, ¬ønormalidad de qu√©?\nDe los residuos estandarizados!‚Ä¶ ¬øQu√© es un residual?\n\nUn residual es la diferencia entre una observaci√≥n y su predicci√≥n\nUn residual estandarizado resulta de la divisi√≥n del residual para la ra√≠z cuadrada de la predicci√≥n\nLa distribuci√≥n muestral de los residuos estandarizados tiene media 0 y desviaci√≥n est√°ndar 1\n\nY es sobre esta distribuci√≥n que los valores cr√≠ticos del ANOVA (valores F) son calculados. Es decir, estos no dependen enteramente de los datos originales, por lo tanto los datos originales no tienen que ser necesariamente normalmente distribuidos.\nPero, ¬øpor qu√© la confusi√≥n? Solo cuando el n√∫mero de observaciones es lo suficientemente grande (y ya sabemos que distribuci√≥n tiene la media muestral cuando el n√∫mero incrementa), se tiene la certeza que los residuos ser√°n normalmente distribuidos.\nEn resumen, es mejor chequear la normalidad despu√©s que realizamos el ANOVA."
  },
  {
    "objectID": "index.html#el-dataset-de-recursos-por-depredaci√≥n",
    "href": "index.html#el-dataset-de-recursos-por-depredaci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "El dataset de recursos por depredaci√≥n",
    "text": "El dataset de recursos por depredaci√≥n\n\n\nImagen tomada por David Mark de Pixabay"
  },
  {
    "objectID": "index.html#el-dataset-de-recursos-por-depredaci√≥n-1",
    "href": "index.html#el-dataset-de-recursos-por-depredaci√≥n-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "El dataset de recursos por depredaci√≥n",
    "text": "El dataset de recursos por depredaci√≥n\n\n\nLos datos que usaremos en esta y otras secciones corresponden a un experimento del Prof.¬†Justin C. Touchon acerca de la interacci√≥n entre predadores y recursos.\nEl experimento consisti√≥ de m√∫ltiples tanques (mesocosmos) dispuestos al aire libre en Gamboa, Panam√°. Los investigadores ten√≠an por objetivo el saber como la variaci√≥n en la incubaci√≥n de huevos de la rana arb√≥rea de ojos rojos podr√≠a afectar su desarrollo hasta la metamorfosis bajo varias combinaciones de recursos y predadores.\nLos tratamientos fueron los siguientes:\n\nEdad de incubaci√≥n: Temprana (E: 4 d√≠as despu√©s de la oviposici√≥n) o tard√≠a (L: 6 d√≠as despu√©s de la oviposici√≥n).\nPredadores: control (C), no letal (NL: larvas de lib√©lula enjauladas) y letal (L: larvas de lib√©lula libres)\nRecursos: bajo (Lo: 0.75 g) o alto (Hi: 1.5 g) de comida suministrados cada 5 d√≠as.\n\nLos mesocosmos fueron colocados en 8 bloques de 12 tanques cada uno.\nEl experimento inici√≥ con 50 renacuajos por tanque y termin√≥ cuando todos los renacuajos alcanzaron la metamorfosis, o murieron."
  },
  {
    "objectID": "index.html#el-dataset-de-recursos-por-depredaci√≥n-2",
    "href": "index.html#el-dataset-de-recursos-por-depredaci√≥n-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "El dataset de recursos por depredaci√≥n",
    "text": "El dataset de recursos por depredaci√≥n\n\n\nVariables de respuesta:\n\nEdad de metaformosis contada desde el d√≠a de oviposici√≥n (Age.DPO).\nEdad de salida del agua (Age.FromEmergence)\nLongitud nariz-cloaca al emerger (SVL.initial)\nLongitud de la cola al emerger (Tail.initial)\nLongitud nariz-cloaca al t√©rmino de la reabsorci√≥n de la cola (SVL.final)\nPeso al t√©rmino de la reabsorci√≥n de la cola (Mass.final)\nN√∫mero de d√≠as requeridos por cada metamorfo para reabsorber completamente la cola (Resorb.days)\n\n18 tanques conteniendo predadores no letales fueron descartados debido al brote de una enfermedad\nNOTA: el dataset original de Touchon contiene alrededor de 2500 observaciones. Sin embargo, para poder usar los datos bajo los supuestos del ANOVA es necesario reducirlos a las medias aritm√©ticas de cada tratamiento por cuanto se tratan de pseudo repeticiones. Esta reducci√≥n ya est√° hecha en el archivo ‚Äútouchon.csv‚Äù disponible con el resto de materiales extras del curso."
  },
  {
    "objectID": "index.html#explorando-este-dataset",
    "href": "index.html#explorando-este-dataset",
    "title": "Estad√≠stica aplicada con R",
    "section": "Explorando este dataset",
    "text": "Explorando este dataset\n\n\nHaremos una exploraci√≥n b√°sica del dataset anteriormente descrito: gr√°ficos de caja y bigote, de barras, de densidad y matrices de dispersi√≥n.\nComo estos datos han sido pre-procesados, omitiremos el mapa de observaciones perdidas.\nPara esto, aprovecho la oportunidad para introducir otro par de librer√≠as √∫tiles\nComo vimos anteriormente, ggplot2 es una poderosa librer√≠a de visualizaci√≥n de datos cuyo uso es relativamente sencillo. Sin embargo, su dominio requiere un poco de tiempo y paciencia. Para quienes quiz√° deseen una manera m√°s r√°pida de realizar sus gr√°ficos y solamente tomarse el tiempo en a√±adir detalles finales, usaremos ggpubr."
  },
  {
    "objectID": "index.html#medias-aritm√©ticas-observadas",
    "href": "index.html#medias-aritm√©ticas-observadas",
    "title": "Estad√≠stica aplicada con R",
    "section": "Medias aritm√©ticas observadas",
    "text": "Medias aritm√©ticas observadas\n\n# usaremos nuevamente la librer√≠a `tidycomm` para los estad√≠sticos descriptivos\nranas &lt;- read.csv(\"touchon.csv\")\ndescribe(ranas)\n\n# A tibble: 9 √ó 15\n  Varia‚Ä¶¬π     N Missing      M     SD    Min    Q25    Mdn    Q75    Max   Range\n  &lt;chr&gt;   &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 Block      78       0  4.13   2.30   1      2      4      6       8      7    \n2 Tank.U‚Ä¶    78       0 44.2   28.0    1     20.2   40.5   67.5    96     95    \n3 Age.DPO    78       0 64.7   23.8   38.1   47.7   57.4   71.7   141.   103.   \n4 Age.Fr‚Ä¶    78       0 30.7   23.8    4.11  13.7   23.4   37.7   107.   103.   \n5 SVL.in‚Ä¶    78       0 19.0    1.34  16.3   18.0   18.9   19.7    22.3    5.98 \n6 Tail.i‚Ä¶    78       0  5.87   0.845  4.41   5.33   5.68   6.16    8.6    4.19 \n7 SVL.fi‚Ä¶    78       0 19.4    1.44  16.7   18.3   19.2   20.0    23.3    6.62 \n8 Mass.f‚Ä¶    78       0  0.430  0.109  0.269  0.359  0.404  0.462   0.75   0.481\n9 Resorb‚Ä¶    78       0  4.40   0.595  3.38   4.02   4.26   4.79    6.5    3.12 \n# ‚Ä¶ with 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;,\n#   Kurtosis &lt;dbl&gt;, and abbreviated variable name ¬π‚ÄãVariable"
  },
  {
    "objectID": "index.html#gr√°ficos-de-barras",
    "href": "index.html#gr√°ficos-de-barras",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de barras",
    "text": "Gr√°ficos de barras\n\nC√≥digoGr√°fico\n\n\n\nlibrary(ggpubr)\nggbarplot(data = ranas,\n          x = \"Pred\",\n          y = \"Age.FromEmergence\",\n          add = \"mean_se\",\n          fill = \"Pred\")\n\nggbarplot(data = ranas,\n          x = \"Res\",\n          y = \"Age.FromEmergence\",\n          add = \"mean_se\",\n          fill = \"Pred\")"
  },
  {
    "objectID": "index.html#gr√°ficos-de-barras-1",
    "href": "index.html#gr√°ficos-de-barras-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de barras",
    "text": "Gr√°ficos de barras\n\nC√≥digoGr√°fico\n\n\n\np1 &lt;- ggbarplot(data = ranas,\n                x = \"Pred\",\n                y = \"Age.FromEmergence\",\n                add = \"mean_se\",\n                fill = \"Pred\")\n\np1 + labs(title = \"Gr√°fico de barras de edad desde oviposici√≥n\",\n       subtitle = \"Datos del estudio de Prof. Touchon\",\n       caption = \"Gr√°fica propia\",\n       x = \"Predadores\",\n       y = \"Edad desde oviposici√≥n\",\n       color = \"Predador\")"
  },
  {
    "objectID": "index.html#gr√°ficos-de-caja-y-bigote",
    "href": "index.html#gr√°ficos-de-caja-y-bigote",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de caja y bigote",
    "text": "Gr√°ficos de caja y bigote\n\nC√≥digoGr√°fico\n\n\n\nggboxplot(data = ranas,\n          x = \"Pred\",\n          y = \"Age.FromEmergence\",\n          fill = \"Pred\")\n\nggboxplot(data = ranas,\n          x = \"Res\",\n          y = \"Age.FromEmergence\",\n          fill = \"Res\")"
  },
  {
    "objectID": "index.html#gr√°ficos-de-densidad",
    "href": "index.html#gr√°ficos-de-densidad",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de densidad",
    "text": "Gr√°ficos de densidad\n\nC√≥digoGr√°fico\n\n\n\nggdensity(data = ranas,\n          x = \"Age.FromEmergence\", \n          add = \"mean\", \n          rug = \"true\", \n          color = \"Pred\", \n          fill = \"Pred\")\n\nggdensity(data = ranas,\n          x = \"Age.FromEmergence\", \n          add = \"mean\", \n          rug = \"true\", \n          color = \"Res\", \n          fill = \"Res\")"
  },
  {
    "objectID": "index.html#matriz-de-dispersi√≥n",
    "href": "index.html#matriz-de-dispersi√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Matriz de dispersi√≥n",
    "text": "Matriz de dispersi√≥n\n\nC√≥digoGr√°fico\n\n\n\nlibrary(GGally)\nranas_matriz &lt;- ranas[,c(6:12)]\nggpairs(ranas_matriz)"
  },
  {
    "objectID": "index.html#anova-de-una-v√≠a",
    "href": "index.html#anova-de-una-v√≠a",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de una v√≠a",
    "text": "ANOVA de una v√≠a\n\n\nANOVA de una v√≠a se refiere cuando tenemos m√°s de dos tratamientos que est√°n definidos por un solo factor a la vez.\nUsando los datos del Prof.¬†Touchon, vamos a ilustrar el caso del ANOVA de una v√≠a. Para ello, vamos a considerar lo siguiente\n\nSupongamos que estamos interesados en saber si existe alguna diferencia entre la edad de salida del agua Age.FromEmergence determinada por los predadores:\nLos niveles del factor predadores son:\n\nPredadores no letales NL\nPredadores letales L\nControl (sin predadores) C\n\n\nLa \\(H_0\\) en todo ANOVA es simplemente que no existe diferencia entre \\(n\\) tratamientos, y la \\(H_a\\) es que al menos uno de los tratamientos tiene una media distinta."
  },
  {
    "objectID": "index.html#anova-en-r",
    "href": "index.html#anova-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA en R",
    "text": "ANOVA en R\n\n\nExisten dos formas de llevar a cabo ANOVA en R:\n\nCrear un modelo lineal con la funci√≥n lm y luego el ANOVA con la funci√≥n anova sobre el objeto producto de lm.\nAplicar directamente la funci√≥n aov sobre nuestros datos.\n\nAmbas funciones (lm y aov) tienen la misma sintaxis. Personalmente prefiero la primera opci√≥n.\nAdicionalmente, la librer√≠a car ofrece la funci√≥n Anova. El resultado de ambas es pr√°cticamente el mismo para la mayor√≠a de modelos. Sin embargo, personalmente prefiero Anova ya que permite realizar correcciones cuando tenemos datos no balanceados."
  },
  {
    "objectID": "index.html#anova-de-una-v√≠a-en-r",
    "href": "index.html#anova-de-una-v√≠a-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de una v√≠a en R",
    "text": "ANOVA de una v√≠a en R\n\n\nOpci√≥n 1\n\nlibrary(car)\nlm1 &lt;- lm(Age.FromEmergence ~ Pred, data = ranas)\nAnova(lm1)\n\n\nOpci√≥n 2\n\nanova1 &lt;- aov(Age.FromEmergence ~ Pred, data = ranas)\nsummary(anova1)\n\n\n\n\n\n\n\nAnova Table (Type II tests)\n\nResponse: Age.FromEmergence\n          Sum Sq Df F value    Pr(&gt;F)    \nPred        9467  2  10.442 9.986e-05 ***\nResiduals  33999 75                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nPred         2   9467    4733   10.44 9.99e-05 ***\nResiduals   75  33999     453                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova",
    "href": "index.html#diagn√≥sticos-del-anova",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\n\nAntes de conducir pruebas formales para los supuestos del ANOVA, es preciso darle un vistazo a diagn√≥sticos visuales que podemos obtener del mismo.\nEl ANOVA es un caso de regresi√≥n lineal (con predictores categ√≥ricos), por lo que en esta secci√≥n nos centraremos en la interpretaci√≥n de estos diagn√≥sticos desde la perspectiva del ANOVA.\nEn el apartado de regresi√≥n lineal volveremos a profundizar en las interpretaciones de los mismos para ese caso determinado.\nPara acceder a estos diagn√≥sticos, basta usar la funci√≥n plot sobre el objeto donde guardamos los resultados del modelo lm1."
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-1",
    "href": "index.html#diagn√≥sticos-del-anova-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\nlm1 &lt;- lm(Age.FromEmergence ~ Pred, data = ranas)\npar(mfrow = c(2, 2))\nplot(lm1)\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-2",
    "href": "index.html#diagn√≥sticos-del-anova-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA"
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-3",
    "href": "index.html#diagn√≥sticos-del-anova-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\n\n\n\n\n\n\n\nResiduos vs.¬†Valores ajustados\nEn este plot podemos evidenciar departuras del supuesto de la homocedasticidad. Idealmente, la l√≠nea roja que se muestra deber√≠a ir a lo largo de la horizontal en la coordenada cero del eje y (sobre la l√≠nea entrecortada)."
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-4",
    "href": "index.html#diagn√≥sticos-del-anova-4",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\n\n\n\n\n\n\n\nGr√°fico Q-Q\nA diferencia del gr√°fico Q-Q que vimos para las pruebas t, en el eje y de este mismo gr√°fico para el ANOVA (y regresi√≥n lineal) se representan los residuos estandarizados. La interpretaci√≥n es la misma: idealmente los puntos deber√≠an ir a lo largo de la diagonal. Cuando no es as√≠, evidencia una violaci√≥n del supuesto de la normalidad."
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-5",
    "href": "index.html#diagn√≥sticos-del-anova-5",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\n\n\n\n\n\n\n\nRa√≠z cuadrada de los residuos estandarizados vs.¬†Valores ajustados\nSimilar al primer diagn√≥stico, en el caso del ANOVA, nos da una idea de posibles departuras de la homogeneidad de las varianzas. La l√≠nea roja idealmente deber√≠a ser completamente recta."
  },
  {
    "objectID": "index.html#diagn√≥sticos-del-anova-6",
    "href": "index.html#diagn√≥sticos-del-anova-6",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos del ANOVA",
    "text": "Diagn√≥sticos del ANOVA\n\n\n\n\n\n\n\n\nResiduos vs.¬†Apalancamiento\nAquellos puntos que est√©n etiquetados con n√∫meros son mostrados como posibles outliers bajo dos criterios:\n\nEst√°n por fuera de los l√≠mites de la regla del rango intercuart√≠lico (IQR), y\nMarcados como outliers con influencia de apalancamiento mediante la prueba de Cook (distancia de Cook).\n\nEl segundo criterio es un argumento s√≥lido para remover outliers."
  },
  {
    "objectID": "index.html#transformaciones",
    "href": "index.html#transformaciones",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaciones",
    "text": "Transformaciones\n\nlm2 &lt;- lm(log(Age.FromEmergence) ~ Pred, data = ranas)\npar(mfrow = c(2, 2))\nplot(lm2)\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "index.html#transformaciones-1",
    "href": "index.html#transformaciones-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaciones",
    "text": "Transformaciones"
  },
  {
    "objectID": "index.html#prueba-formal-de-normalidad",
    "href": "index.html#prueba-formal-de-normalidad",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba formal de normalidad",
    "text": "Prueba formal de normalidad\n\n\nComo vimos, despu√©s de aplicar la transformaci√≥n logar√≠tmica el gr√°fico Q-Q mejor√≥ considerablemente.\nPara estar seguros, podemos correr un test formal sobre los residuos del modelo con la ayuda de la librer√≠a olsrr mediante su funci√≥n ols_test_normality.\n\n\n\n\nlibrary(olsrr)\nols_test_normality(lm2)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.9802         0.2645 \nKolmogorov-Smirnov        0.0893         0.5625 \nCramer-von Mises          8.6738         0.0000 \nAnderson-Darling          0.5447         0.1566 \n-----------------------------------------------"
  },
  {
    "objectID": "index.html#prueba-formal-de-normalidad-1",
    "href": "index.html#prueba-formal-de-normalidad-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba formal de normalidad",
    "text": "Prueba formal de normalidad\n\n\nO tambi√©n podemos calcular la prueba de Shapiro-Wilk con funciones base de R\n\n\n\n\nresiduos &lt;- resid(lm2)\nshapiro.test(residuos)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.98017, p-value = 0.2645"
  },
  {
    "objectID": "index.html#homogeneidad-de-las-varianzas-en-anova",
    "href": "index.html#homogeneidad-de-las-varianzas-en-anova",
    "title": "Estad√≠stica aplicada con R",
    "section": "Homogeneidad de las varianzas en ANOVA",
    "text": "Homogeneidad de las varianzas en ANOVA\n\n\nLa prueba m√°s usada para chequear la homogeneidad de varianzas de un ANOVA es la de Levene.\nPara ello utilizaremos la funci√≥n leveneTest de la librer√≠a car. Podemos usar esta funci√≥n directamente sobre los datos con la misma sintaxis de lm, o sobre el objeto lm2 en el que anteriormente almacenamos el resultado del modelo lineal con la transformaci√≥n.\n\n\n\n\nleveneTest(lm2, center = \"mean\")\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value  Pr(&gt;F)  \ngroup  2  3.0464 0.05345 .\n      75                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "index.html#anova-de-una-v√≠a-en-r-continuaci√≥n",
    "href": "index.html#anova-de-una-v√≠a-en-r-continuaci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de una v√≠a en R (continuaci√≥n)",
    "text": "ANOVA de una v√≠a en R (continuaci√≥n)\n\n\nAs√≠, una vez que hemos transformado para obtener normalidad en los residuos y chequeado la homogeneidad de varianzas, es tiempo de hecharle un vistazo al resultado del ANOVA:\n\n\n\n\nAnova(lm2)\n\nAnova Table (Type II tests)\n\nResponse: log(Age.FromEmergence)\n          Sum Sq Df F value    Pr(&gt;F)    \nPred       9.710  2  12.389 2.244e-05 ***\nResiduals 29.392 75                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nPor tanto, podemos concluir que al menos uno de los tratamientos es distinto (aceptamos la \\(H_a\\) y rechazamos la \\(H_0\\))"
  },
  {
    "objectID": "index.html#qu√©-tan-distintos",
    "href": "index.html#qu√©-tan-distintos",
    "title": "Estad√≠stica aplicada con R",
    "section": "¬øQu√© tan distintos?",
    "text": "¬øQu√© tan distintos?\n\n\nPreguntas naturales seguidas de estos resultados son: ¬øqu√© tan distintos son los tratamientos entre s√≠?, ¬øpuedo acaso ordernarlos de mayor a menor?, ¬øexisten pares de tratamientos que son iguales?\nPodemos comenzar con una ayuda visual (ligeramente distinto a nuestro AED, usando la transformaci√≥n logar√≠tmica)\n\n\n\n\nC√≥digoGr√°fico\n\n\n\n# usamos ggpubr nuevamente\nranas$log.Age.FromEmergence &lt;- log(ranas$Age.FromEmergence)\nggboxplot(ranas,\n          x = \"Pred\",\n          y = \"log.Age.FromEmergence\",\n          add = \"jitter\",\n          color = \"Pred\")"
  },
  {
    "objectID": "index.html#comparaciones-m√∫ltiples",
    "href": "index.html#comparaciones-m√∫ltiples",
    "title": "Estad√≠stica aplicada con R",
    "section": "Comparaciones m√∫ltiples",
    "text": "Comparaciones m√∫ltiples\n\n\nLos m√©todos de comparaciones m√∫ltiples y gr√°ficos de interacci√≥n nos ayudan a responder estas preguntas.\nEn el caso de los gr√°ficos de interacci√≥n para ANOVA de una v√≠a, no tiene mucho sentido llevarlos a cabo ya que son m√°s √∫tiles para ANOVA de m√∫ltiples v√≠as, as√≠ que los dejaremos para despu√©s.\nLas comparaciones m√∫ltiples m√°s usadas son:\n\nHSD Tukey (Honestly significant difference): lleva a cabo todos los pares de comparaciones posibles entre los niveles de un factor.\nPrueba de Dunnett: Compara los niveles √∫nicamente con respecto al nivel control dentro del factor.\n\nSon conocidas tambi√©n como pruebas post-hoc.\nEn R, una manera de realizar comparaciones m√∫ltiples es mediante las librer√≠as emmeans y multcomp (esta √∫ltima depende de multcompView, as√≠ que no olvides instalarla tambi√©n)."
  },
  {
    "objectID": "index.html#hsd-tukey",
    "href": "index.html#hsd-tukey",
    "title": "Estad√≠stica aplicada con R",
    "section": "HSD Tukey",
    "text": "HSD Tukey\n\nCalculamos las medias marginales a partir del modelo\n\nlibrary(emmeans)\nph1 &lt;- emmeans(lm2, specs = \"Pred\", type = \"response\")\nsummary(ph1)"
  },
  {
    "objectID": "index.html#hsd-tukey-1",
    "href": "index.html#hsd-tukey-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "HSD Tukey",
    "text": "HSD Tukey\nCalculamos las medias marginales a partir del modelo\n\nlibrary(emmeans)\nph1 &lt;- emmeans(lm2, specs = \"Pred\", type = \"response\")\nsummary(ph1)\n\n Pred response   SE df lower.CL upper.CL\n C        34.2 3.79 75     27.4     42.6\n L        15.8 1.75 75     12.7     19.7\n NL       26.2 4.38 75     18.8     36.5\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\n\n\n\nAhora podemos calcular las comparaciones por pares de HSD Tukey\n\n\ntukey_comp &lt;- contrast(ph1, specs = \"Pred\", method = \"tukey\")\ntukey_comp\n\n contrast ratio    SE df null t.ratio p.value\n C / L    2.165 0.339 75    1   4.936  &lt;.0001\n C / NL   1.307 0.262 75    1   1.335  0.3806\n L / NL   0.604 0.121 75    1  -2.516  0.0368\n\nP value adjustment: tukey method for comparing a family of 3 estimates \nTests are performed on the log scale"
  },
  {
    "objectID": "index.html#prueba-de-dunnett",
    "href": "index.html#prueba-de-dunnett",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Dunnett",
    "text": "Prueba de Dunnett\n\n\nPara Dunnett, es importante el establecer el grupo control\n\n\ndunnett_comp &lt;- contrast(ph1, specs = \"Pred\", method = \"dunnett\", ref = \"C\")\ndunnett_comp\n\n contrast ratio     SE df null t.ratio p.value\n L / C    0.462 0.0723 75    1  -4.936  &lt;.0001\n NL / C   0.765 0.1535 75    1  -1.335  0.3177\n\nP value adjustment: dunnettx method for 2 tests \nTests are performed on the log scale \n\n\n\n\n\nFinalmente, otra tabla de resumen de las comparaciones m√∫ltiples es la de agrupar las medias aritm√©ticas marginales con n√∫meros (o letras) de acuerdo a si estas son estad√≠sticamente distintas o no entre si. Para ello podemos usar la librer√≠a multcomp:\n\n\n# multcomp necesita una librer√≠a extra llamada multcompView\n# No olvides instalar multcompView antes de correr este c√≥digo\nlibrary(multcomp)\nmedias_marginales &lt;- cld(ph1)\nmedias_marginales\n\n Pred response   SE df lower.CL upper.CL .group\n L        15.8 1.75 75     12.7     19.7  1    \n NL       26.2 4.38 75     18.8     36.5   2   \n C        34.2 3.79 75     27.4     42.6   2   \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 3 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "index.html#antes-de-continuar-3",
    "href": "index.html#antes-de-continuar-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nEn este punto, antes de continuar hagamos uso nuevamente de la librer√≠a flextable para exportar nuestras tablas a Word.\n\n\n\n\nlibrary(flextable)\ntabla_tukey &lt;- colformat_double(flextable(as.data.frame(tukey_comp)), digits = 3, j = c(2, 3, 6, 7))\ntabla_dunnett &lt;- colformat_double(flextable(as.data.frame(dunnett_comp)), digits = 3, j = c(2, 3, 6, 7))\ntabla_marginal &lt;- colformat_double(flextable(medias_marginales), digits = 3, j = c(2, 3, 5, 6))\n\n\n\n\n\n\ncontrastratioSEdfnullt.ratiop.valueC / L2.1650.3397514.9360.000C / NL1.3070.2627511.3350.381L / NL0.6040.121751-2.5160.037\n\n\n\ncontrastratioSEdfnullt.ratiop.valueL / C0.4620.072751-4.9360.000NL / C0.7650.153751-1.3350.318\n\n\n\nPredresponseSEdflower.CLupper.CL.groupL15.7991.7487512.67319.695 1 NL26.1724.3797518.75436.525  2C34.2083.7867527.44042.645  2"
  },
  {
    "objectID": "index.html#antes-de-continuar-4",
    "href": "index.html#antes-de-continuar-4",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nLa tabla del ANOVA requiere un poquito m√°s de preparaci√≥n y para ello nos ayudaremos de la librer√≠a rstatix para agregar los asteriscos de significancia.\n\n\nlibrary(rstatix)\ntabla_anova &lt;- as.data.frame(Anova(lm2))\ntabla_anova &lt;- cbind(parametro = row.names(tabla_anova), tabla_anova)\ntabla_anova &lt;- add_significance(tabla_anova, \n                 p.col = \"Pr(&gt;F)\", \n                 output.col = \" \",\n                 cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                 symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\ntabla_anova &lt;- colformat_double(flextable(tabla_anova), digits = 3, j = c(2, 4, 5))\ntabla_anova &lt;- add_footer_lines(tabla_anova, \"C√≥digos Signif. 0 '***', 0.001 '**', 0.1 '*', 0.05 '.', 0.1 'ns'\")"
  },
  {
    "objectID": "index.html#antes-de-continuar-5",
    "href": "index.html#antes-de-continuar-5",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\nLa tabla del ANOVA requiere un poquito m√°s de preparaci√≥n y para ello nos ayudaremos de la librer√≠a rstatix para agregar los c√≥digos de significancia.\n\n\nlibrary(rstatix)\ntabla_anova &lt;- as.data.frame(Anova(lm2))\ntabla_anova &lt;- cbind(parametro = row.names(tabla_anova), tabla_anova)\ntabla_anova &lt;- add_significance(tabla_anova, \n                 p.col = \"Pr(&gt;F)\", \n                 output.col = \" \",\n                 cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                 symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\ntabla_anova &lt;- colformat_double(flextable(tabla_anova), digits = 3, j = c(2, 4, 5))\ntabla_anova &lt;- add_footer_lines(tabla_anova, \"C√≥digos Signif. 0 '***', 0.001 '**', 0.1 '*', 0.05 '.', 0.1 'ns'\")\ntabla_anova\n\n\nparametroSum SqDfF valuePr(&gt;F) Pred9.710212.3890.000***Residuals29.39275C√≥digos Signif. 0 '***', 0.001 '**', 0.1 '*', 0.05 '.', 0.1 'ns'"
  },
  {
    "objectID": "index.html#antes-de-continuar-6",
    "href": "index.html#antes-de-continuar-6",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\nsave_as_docx(\"Tabla Anova\" = tabla_anova, \"Tabla Tukey\" = tabla_tukey, \"Tabla Dunnett\" = tabla_dunnett,\n             \"Tabla Medias Marginales Esperadas\" = tabla_marginal,\n             path = \"C:/Users/mmore/Documents/cursos_uce_2023/modulos/uce2023-modulo4/anova.docx\")"
  },
  {
    "objectID": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples",
    "href": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de comparaciones m√∫ltiples",
    "text": "Gr√°ficos de comparaciones m√∫ltiples\n\n\nHay personas que prefieren tener representaciones visuales de las comparaciones m√∫ltiples.\nRealizar este tipo de gr√°ficos sin embargo sol√≠a demandar buena experiencia ya sea en gr√°ficos base o ggplot2.\nAfortunadamente, rstatix nos brinda la posibilidad de llevarlos a cabo de una manera relativamente sencilla.\nLa idea es generar un gr√°fico con las medias marginales observadas de la variable de inter√©s y posicionar sobre este los resultados de las comparaciones m√∫ltiples con sus c√≥digos de significancia (o valores p).\nLas desventajas de esta visualizaci√≥n son:\n\nTienen mayor sentido realizarlas con HSD Tukey\nCuando el n√∫mero de pares de comparaciones es muy grande, el gr√°fico se vuelve m√°s dif√≠cil de interpretar que las tablas.\nrstatix no tiene manera de directamente volver a retransformar variables a sus unidades originales.\n\nOtro gr√°fico de cierta popularidad es el de los grupos de Tukey de las medias marginales (gr√°ficos de barras con los n√∫meros/letras sobre cada categor√≠a). Para esto utilizaremos adem√°s la librer√≠a stringr"
  },
  {
    "objectID": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples-1",
    "href": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de comparaciones m√∫ltiples",
    "text": "Gr√°ficos de comparaciones m√∫ltiples\n\nC√≥digoGr√°fico\n\n\n\nranas$Pred &lt;- factor(ranas$Pred, levels = c(\"C\", \"NL\", \"L\"))\nbxplot &lt;- ggboxplot(ranas, x = \"Pred\", \n                    y = \"Age.FromEmergence\", \n                    color = \"Pred\")\nhsdvals &lt;- emmeans_test(log.Age.FromEmergence ~ Pred, \n                        data = ranas, \n                        p.adjust.method = \"mvt\")\nhsdvals &lt;- add_significance(hsdvals, \n                            p.col = \"p.adj\", \n                            output.col = \"p.adj.signif\",\n                            cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                            symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\nhsdvals &lt;- hsdvals %&gt;% add_xy_position(x = \"Pred\")\nbxplot + stat_pvalue_manual(hsdvals, y.position = c(120, 130, 140))"
  },
  {
    "objectID": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples-2",
    "href": "index.html#gr√°ficos-de-comparaciones-m√∫ltiples-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de comparaciones m√∫ltiples",
    "text": "Gr√°ficos de comparaciones m√∫ltiples\n\nC√≥digoGr√°fico\n\n\n\nlibrary(stringr)\ngruposvals &lt;- as.data.frame(cld(ph1))\ngruposvals$Pred &lt;- factor(gruposvals$Pred, levels = c(\"C\", \"NL\", \"L\"))\nggplot(gruposvals,\n       aes(x = Pred, \n           y = response, \n           fill = Pred)) +\n  geom_bar(stat = \"identity\", \n           show.legend = F, \n           color = \"black\")+\n  geom_errorbar(aes(ymin = response - SE, \n                    ymax = response + SE), \n                width=0.2)+\n  geom_text(aes(label=str_trim(.group), \n                y = response+SE, vjust=-0.5))"
  },
  {
    "objectID": "index.html#anova-de-un-dise√±o-desbalanceado",
    "href": "index.html#anova-de-un-dise√±o-desbalanceado",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de un dise√±o desbalanceado",
    "text": "ANOVA de un dise√±o desbalanceado\n\n\nRecordemos que 18 tanques con predadores no letales fueron descartados debido al brote de una enfermedad.\nEl dise√±o original de Touchon era balanceado. Al perderse unidades experimentales, el dise√±o se le puede denominar como desbalanceado. En otras palabras, el desbalance es la p√©rdida de observaciones.\nLa mayor√≠a de m√©todos estad√≠sticos requieren ser corregidos ante observaciones perdidas para poder tener la certeza de que los estimados que obtenemos no sean sesgados.\nSin adentrarnos en mayor detalle, uno de los componentes de la tabla de ANOVA es la suma de cuadrados. Existen tres tipos de suma de cuadrados: I, II y III.\nEn breve, las sumas II y III se aconseja sean usadas cuando existen interacciones en el ANOVA.\nEn R, la funci√≥n aov calcula la suma de cuadrados tipo I. Este tipo de suma no es conveniente ante la presencia de desbalance de los datos.\nEn cambio, la funci√≥n Anova de la librer√≠a car, usa por default el tipo II que es precisamente el recomendado usar ante la presencia de desbalance.\nEn resumen, s√≠. Hemos utilizado hasta el momento la correcci√≥n adecuada para estos datos."
  },
  {
    "objectID": "index.html#ejercicio-4.9",
    "href": "index.html#ejercicio-4.9",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.9",
    "text": "Ejercicio 4.9\n\nLleva a cabo un ANOVA con todos sus pasos para la variable Resorb.days de los datos de Touchon"
  },
  {
    "objectID": "index.html#prueba-de-kruskal-wallis",
    "href": "index.html#prueba-de-kruskal-wallis",
    "title": "Estad√≠stica aplicada con R",
    "section": "Prueba de Kruskal-Wallis",
    "text": "Prueba de Kruskal-Wallis\n\n\nLa prueba de Kruskal-Wallis es la alternativa no param√©trica al ANOVA de una v√≠a.\nPuede extenderse al ANOVA de m√∫ltiples v√≠as reorganizando el dise√±o experimental.\nSimilar a las pruebas de Wilcoxon, se basa en encontrar diferencias de las medianas en lugar de las medias y su poder ese menor.\nPara ilustrar este ejemplo, tomemos la variable Age.DPO del estudio de Touchon y veamos si existen diferencias con respecto al tratamiento de predador Pred. Age.DPO sin transformaciones no cumple con los supuestos del ANOVA.\n\n\n\n\nkruskal.test(Age.DPO ~ Pred, data = ranas)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Age.DPO by Pred\nKruskal-Wallis chi-squared = 22.255, df = 2, p-value = 1.47e-05"
  },
  {
    "objectID": "index.html#comparaciones-m√∫ltiples-con-kruskal-wallis",
    "href": "index.html#comparaciones-m√∫ltiples-con-kruskal-wallis",
    "title": "Estad√≠stica aplicada con R",
    "section": "Comparaciones m√∫ltiples con Kruskal-Wallis",
    "text": "Comparaciones m√∫ltiples con Kruskal-Wallis\n\n\nCon KW tambi√©n podemos hacer comparaciones m√∫ltiples.\nEn R base contamos con la funci√≥n pairwise.wilcox.test que lleva a cabo comparaciones por pares mediante el m√©todo de Wilcoxon.\n\n\n\n\npairwise.wilcox.test(ranas$Age.DPO, ranas$Pred, p.adjust.method = \"BH\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum exact test \n\ndata:  ranas$Age.DPO and ranas$Pred \n\n   C       NL   \nNL 0.303   -    \nL  9.8e-06 0.019\n\nP value adjustment method: BH"
  },
  {
    "objectID": "index.html#ejercicio-4.10",
    "href": "index.html#ejercicio-4.10",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicio 4.10",
    "text": "Ejercicio 4.10\n\nEncuentra si existen diferencias en la longitud nariz-cloaca al emerger (SVL.initial) con respecto a los predadores Pred en los datos de Touchon. ¬øQu√© m√©todo es factible usar?, ¬øANOVA de una v√≠a o Kruskal-Wallis?"
  },
  {
    "objectID": "index.html#antes-de-continuar-7",
    "href": "index.html#antes-de-continuar-7",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nCon respecto a los DDE que vimos en el m√≥dulo 2, el ANOVA de una v√≠a corresponde directamente al an√°lisis que llevar√≠amos a cabo para un DCA.\nPara extender el modelo a un DBCA de una v√≠a basta el incorporar otro efecto principal en el modelo:\n\n\n\n\nlm3 &lt;- lm(log(Age.FromEmergence) ~ Pred + as.factor(Block), data = ranas)\nAnova(lm3)\n\nAnova Table (Type II tests)\n\nResponse: log(Age.FromEmergence)\n                  Sum Sq Df F value    Pr(&gt;F)    \nPred              9.8369  2 13.9265 8.526e-06 ***\nas.factor(Block)  5.3760  7  2.1746   0.04728 *  \nResiduals        24.0158 68                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nLa interpretaci√≥n de este tipo de ANOVA se enfoca en el valor p de los tratamientos.\nNo tiene mucho sentido el interpretar el valor p del factor de bloque ya que est√° ah√≠ para controlar fuentes de variaci√≥n.\nDe manera similar, cuando extendamos el ANOVA a m√°s factores, el an√°lisis del DBCA factorial se consigue a√±adiendo un efecto principal para el bloque."
  },
  {
    "objectID": "index.html#antes-de-continuar-8",
    "href": "index.html#antes-de-continuar-8",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nPara las pruebas de comparaciones m√∫ltiples, seguimos el mismo procedimiento que describimos anteriormente ignorando el efecto del bloque.\n\n\n\n\nph_dbca &lt;- emmeans(lm3, specs = \"Pred\", type = \"response\")\ncontrast(ph_dbca, specs = \"Pred\", method = \"tukey\")\n\n contrast ratio    SE df null t.ratio p.value\n C / NL    1.24 0.255 68    1   1.036  0.5572\n C / L     2.17 0.322 68    1   5.200  &lt;.0001\n NL / L    1.75 0.360 68    1   2.720  0.0223\n\nResults are averaged over the levels of: Block \nP value adjustment: tukey method for comparing a family of 3 estimates \nTests are performed on the log scale"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as",
    "text": "ANOVA de m√∫ltiples v√≠as\n\n\nEl ANOVA puede extenderse para analizar dos o m√°s factores a la vez. Su nombre entonces var√≠a dependiendo de cu√°ntos factores analicemos, as√≠: ANOVA de dos v√≠as (2 factores), ANOVA de tres v√≠as (3 factores) ‚Ä¶\nEn la pr√°ctica es recomendable dise√±ar experimentos hasta m√°ximo 3 factores:\n\nA m√°s factores, m√°s costosa la investigaci√≥n\nA m√°s factores, sus interacciones son m√°s dif√≠ciles de interpretar\nEs posible inclusive que tengamos resultados sin sentido (interacciones innecesarias)\n\n¬øQu√© son las interacciones?\n\nUna interacci√≥n se refiere cuando los niveles de un factor podr√≠an depender de los niveles de otro.\nPor ejemplo, con los datos de las ranas, podr√≠amos imaginar que en la ausencia de predadores, tener recursos altos o bajos podr√≠a influenciar el tiempo que tomaron los renacuajos en culminar la metamorfosis. Es decir, si hay predadores presentes, podr√≠a darse el caso de que las presas se escondan y coman menos influenciando as√≠ ese tiempo.\nAs√≠, podr√≠amos saber si el effecto de los recursos son influenciados ante la presencia de predadores"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R",
    "text": "ANOVA de m√∫ltiples v√≠as en R\n\n\nVamos a usar nuevamente los datos de Touchon, la variable de respuesta es la edad de metamorfosis Age.DPO y los factores la presencia de predadores Pred y los recursos Res.\nPara un ANOVA de m√∫ltiples v√≠as en R podemos usar la siguiente sintaxis: Factor1*Factor2\nPara ahorrarnos tiempo, sup√≥ngamos que ya corrimos un primer ANOVA, y encontramos que usando el logaritmo de Age.DPO podemos normalizar los residuos. Pero nos encontramos con esto:\n\n\n\n\nlm4 &lt;- lm(log(Age.DPO) ~ Pred*Res, data = ranas)\nleveneTest(lm4, center = \"mean\")\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value    Pr(&gt;F)    \ngroup  5  6.0253 0.0001033 ***\n      72                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n¬°La homogeneidad de las varianzas no se cumple! üò±\n¬°Ninguna otra transformaci√≥n funciona!"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r-1",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R",
    "text": "ANOVA de m√∫ltiples v√≠as en R"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r-2",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R",
    "text": "ANOVA de m√∫ltiples v√≠as en R\n\n\nA parte de reir, en este tipo de situaciones (que son bastante comunes), tenemos dos alternativas:\n\nRealizar pruebas no param√©tricas, o\nCalcular ANOVAs con correcciones para heterodasticidad.\n\nPero como acu√±√≥ el Ec. y estad√≠stico Milton Friedman: ‚ÄúNo existe tal cosa como un almuerzo gratis‚Äù, usar la segunda opci√≥n no es tan f√°cil como hemos venido viendo.\nEn R, tenemos estos caminos (de peor a mejor opci√≥n):\n\nRealizar el ANOVA usando la correcci√≥n de White-Huber disponible en la librer√≠a car, pero al costo de conducir comparaciones m√∫ltiples posiblemente sesgadas (siguiendo la l√≥gica de realizarlas con emmeans).\nUtilizar rstatix para un ANOVA con la correcci√≥n de Welch, seguido de comparaciones m√∫ltiples con la correcci√≥n de Games-Howell y poder todav√≠a realizar sus gr√°ficos al costo de romper la secuencia de aprendizaje que hemos venido llevando para el ANOVA.\nUtilizar las librer√≠as nlme para reparametrizar el modelo en forma de un modelo lineal generalizado, y posteriormente usar car y emmeans para el ANOVA y las comparaciones m√∫ltiples, respectivamente. Pero al costo de no poder graficarlas con rstatix sino desde 0.\n\nA continuaci√≥n entonces iremos en este orden de las opciones: 2, 3 y 1 (la √∫ltima para ejemplificar cu√°l ser√≠a el camino suponiendo que la homocedasticidad se hubiese cumplido)."
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-2",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R. Opc. 2",
    "text": "ANOVA de m√∫ltiples v√≠as en R. Opc. 2\n\n\nEl inconveniente de usar la correcci√≥n de Welch es que esta se puede aplicar solo a ANOVAs de una v√≠a.\nEntonces, de manera similar a lo hicimos para poder analizar por Kruskall-Wallis un dise√±o factorial, tenemos que crear una variable dummy combinando los dos factores para correr un ANOVA de una v√≠a.\nDebemos tener en cuenta que al realizar esto, reducimos poder de la prueba estad√≠stica.\n\n\n\n\nranas$log.Age.DPO &lt;- log(ranas$Age.DPO)\nranas$tratamiento &lt;- paste(ranas$Pred, ranas$Res, sep = \"-\")\nanova_op2 &lt;- ranas %&gt;%\n  welch_anova_test(log.Age.DPO ~ tratamiento)"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-2-1",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-2-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R. Opc. 2",
    "text": "ANOVA de m√∫ltiples v√≠as en R. Opc. 2\n\nEl inconveniente de usar la correcci√≥n de Welch es que esta se puede aplicar solo a ANOVAs de una v√≠a.\nEntonces, de manera similar a lo hicimos para poder analizar por Kruskall-Wallis un dise√±o factorial, tenemos que crear una variable dummy combinando los dos factores para correr un ANOVA de una v√≠a.\nDebemos tener en cuenta que al realizar esto, reducimos poder de la prueba estad√≠stica.\n\n\nranas$log.Age.DPO &lt;- log(ranas$Age.DPO)\nranas$tratamiento &lt;- paste(ranas$Pred, ranas$Res, sep = \"-\")\nranas$tratamiento &lt;- factor(ranas$tratamiento, levels = c(\"C-Lo\", \"NL-Lo\", \"C-Hi\", \"L-Lo\", \"NL-Hi\", \"L-Hi\"))\nanova_op2 &lt;- ranas %&gt;%\n  welch_anova_test(log.Age.DPO ~ tratamiento)\nanova_op2\n\n# A tibble: 1 √ó 7\n  .y.             n statistic   DFn   DFd           p method     \n* &lt;chr&gt;       &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      \n1 log.Age.DPO    78      17.2     5  24.0 0.000000305 Welch ANOVA\n\n\n\n\nAhora podemos realizar las comparaciones de HSD Tukey (con correcci√≥n de Games-Howell)\n\n\ngames_comp &lt;- ranas %&gt;% games_howell_test(log.Age.DPO ~ tratamiento)\ngames_comp &lt;- add_significance(games_comp, \n                                p.col = \"p.adj\", \n                                output.col = \"p.adj.signif\",\n                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                                symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\ngames_comp\n\n# A tibble: 15 √ó 8\n   .y.         group1 group2 estimate conf.low conf.high      p.adj p.adj.signif\n   &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;       \n 1 log.Age.DPO C-Lo   NL-Lo  -0.155     -0.772    0.462  0.936      ns          \n 2 log.Age.DPO C-Lo   C-Hi   -0.440     -0.700   -0.180  0.000261   ***         \n 3 log.Age.DPO C-Lo   L-Lo   -0.485     -0.754   -0.217  0.0000932  ***         \n 4 log.Age.DPO C-Lo   NL-Hi  -0.493     -0.821   -0.166  0.002      **          \n 5 log.Age.DPO C-Lo   L-Hi   -0.643     -0.877   -0.408  0.00000114 ***         \n 6 log.Age.DPO NL-Lo  C-Hi   -0.285     -0.902    0.331  0.545      ns          \n 7 log.Age.DPO NL-Lo  L-Lo   -0.331     -0.947    0.286  0.419      ns          \n 8 log.Age.DPO NL-Lo  NL-Hi  -0.339     -0.961    0.284  0.433      ns          \n 9 log.Age.DPO NL-Lo  L-Hi   -0.488     -1.11     0.133  0.129      ns          \n10 log.Age.DPO C-Hi   L-Lo   -0.0452    -0.258    0.168  0.986      ns          \n11 log.Age.DPO C-Hi   NL-Hi  -0.0531    -0.351    0.244  0.988      ns          \n12 log.Age.DPO C-Hi   L-Hi   -0.202     -0.362   -0.0425 0.008      **          \n13 log.Age.DPO L-Lo   NL-Hi  -0.00797   -0.310    0.294  1          ns          \n14 log.Age.DPO L-Lo   L-Hi   -0.157     -0.334    0.0196 0.099      .           \n15 log.Age.DPO NL-Hi  L-Hi   -0.149     -0.440    0.142  0.448      ns          \n\n\n\n\n\nFinalizamos con el gr√°fico de estas\n\n\ngames_comp &lt;- games_comp %&gt;% \n  add_xy_position(x = \"tratamiento\", step.increase = 1)\nggboxplot(ranas,\n          x = \"tratamiento\",\n          y = \"log.Age.DPO\") + \n  stat_pvalue_manual(games_comp, \n                     hide.ns = T,\n                     y.position = c(5.1,5.5,5.9,6.3,6.7,7.1))"
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-3",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R. Opc. 3",
    "text": "ANOVA de m√∫ltiples v√≠as en R. Opc. 3\n\n\nLa tercera opci√≥n involucra el reparametrizar el modelo para poder analizarlo como un modelo lineal generalizado.\nEn breve, una de las ventajas de los modelos lineales generalizados es que pueden asumir varianzas distintas a trav√©s de modelar directamente la heterodasticidad.\nPara su implementaci√≥n usaremos la librer√≠a nlme\n\n\n\n\nlibrary(nlme)\nanova_op3 &lt;- gls(log(Age.DPO) ~ Pred*Res,\n                 data = ranas,\n                 weights = varIdent(form = ~1|Pred*Res)) \n\n\n\n\nMediante la librer√≠a car podemos obtener la tabla del ANOVA (o especificamente llamada Analisis de Desviaci√≥n)\n\n\nAnova(anova_op3)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: log(Age.DPO)\n         Df   Chisq Pr(&gt;Chisq)    \nPred      2 41.5704  9.400e-10 ***\nRes       1 30.6580  3.078e-08 ***\nPred:Res  2  8.0607    0.01777 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nAhora, usando emmeans podemos calcular el HSD de Tukey directamente sin necesidad de correcciones. Una consideraci√≥n importante es que, cuando tenemos dos factores debemos hacer las comparaciones de cada factor a la vez a lo largo de los niveles del otro.\n\n\n\n\ntukey_comp_pred &lt;- emmeans(anova_op3, specs = \"Pred\", by = \"Res\", method = \"tukey\") # medias marginales esperadas\ncontrast(tukey_comp_pred, specs = \"Pred\", by = \"Res\", method = \"tukey\")\n\nRes = Hi:\n contrast estimate     SE    df t.ratio p.value\n C - NL     0.0531 0.0873 14.09   0.608  0.8179\n C - L      0.2022 0.0509 20.74   3.971  0.0020\n NL - L     0.1491 0.0765  9.54   1.949  0.1779\n\nRes = Lo:\n contrast estimate     SE    df t.ratio p.value\n C - NL     0.1548 0.1717  8.55   0.901  0.6536\n C - L      0.4854 0.0879 27.66   5.526  &lt;.0001\n NL - L     0.3306 0.1650  7.37   2.004  0.1783\n\nDegrees-of-freedom method: satterthwaite \nResults are given on the log (not the response) scale. \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\n\n\ntukey_comp_res &lt;- emmeans(anova_op3, specs = \"Res\", by = \"Pred\", method = \"tukey\") # medias marginales esperadas\ncontrast(tukey_comp_res, specs = \"Res\", by = \"Pred\", method = \"tukey\")\n\nPred = C:\n contrast estimate     SE    df t.ratio p.value\n Hi - Lo    -0.440 0.0847 26.13  -5.199  &lt;.0001\n\nPred = NL:\n contrast estimate     SE    df t.ratio p.value\n Hi - Lo    -0.339 0.1730  8.64  -1.957  0.0834\n\nPred = L:\n contrast estimate     SE    df t.ratio p.value\n Hi - Lo    -0.157 0.0560 19.63  -2.803  0.0111\n\nDegrees-of-freedom method: satterthwaite \nResults are given on the log (not the response) scale. \n\n\n\nPara graficar estas comparaciones mediante esta opci√≥n es necesario el empezar de cero con ggplot2. La raz√≥n es que rstatix no tiene las capacidades de lidiar con interacciones provenientes de emmeans (no es compatible con la sintaxis de los comandos contrast de arriba) por lo que dejaremos esta opci√≥n hasta aqu√≠."
  },
  {
    "objectID": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-1",
    "href": "index.html#anova-de-m√∫ltiples-v√≠as-en-r.-opc.-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "ANOVA de m√∫ltiples v√≠as en R. Opc. 1",
    "text": "ANOVA de m√∫ltiples v√≠as en R. Opc. 1\n\n\nFinalmente, asumamos que no tuvimos el problema de heterodasticidad y pudimos haber seguido el curso normal para realizar las comparaciones m√∫ltiples usando solamente car, emmeans y multcomp.\nEste es el transcurso normal de t√≥picos en el aprendizaje del ANOVA de m√∫ltiples v√≠as:\n\n\n\n\nTabla del ANOVA con car (mencionamos que car es capaz de llevar a cabo una correcci√≥n de heterodasticidad, esta se consigue agregando el argumento white.adjust = T dentro de la funci√≥n Anova)\n\n\nAnova(lm4)\n\nAnova Table (Type II tests)\n\nResponse: log(Age.DPO)\n          Sum Sq Df F value    Pr(&gt;F)    \nPred      1.9446  2 18.7561 2.775e-07 ***\nRes       1.8241  1 35.1871 9.576e-08 ***\nPred:Res  0.3254  2  3.1384   0.04934 *  \nResiduals 3.7324 72                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nAl igual que en la opci√≥n 3, calculamos las comparaciones m√∫ltiples viendo a cada factor a la vez a lo largo de los niveles del otro.\n\n\ntukey_comp_pred1 &lt;- emmeans(lm4, specs = \"Pred\", by = \"Res\", type = \"response\")\ncontrast(tukey_comp_pred1, specs = \"Pred\", method = \"tukey\")\n\nRes = Hi:\n contrast ratio     SE df null t.ratio p.value\n C / NL    1.05 0.1088 72    1   0.515  0.8644\n C / L     1.22 0.0985 72    1   2.512  0.0374\n NL / L    1.16 0.1198 72    1   1.445  0.3234\n\nRes = Lo:\n contrast ratio     SE df null t.ratio p.value\n C / NL    1.17 0.1205 72    1   1.500  0.2968\n C / L     1.62 0.1308 72    1   6.030  &lt;.0001\n NL / L    1.39 0.1436 72    1   3.204  0.0057\n\nP value adjustment: tukey method for comparing a family of 3 estimates \nTests are performed on the log scale \n\n\n\n\n\ntukey_comp_res1 &lt;- emmeans(lm4, specs = \"Res\", by = \"Pred\", type = \"response\")\ncontrast(tukey_comp_res1, specs = \"Pred\", method = \"tukey\", adjust = \"holm\")\n\nPred = C:\n contrast ratio     SE df null t.ratio p.value\n Hi / Lo  0.644 0.0518 72    1  -5.470  &lt;.0001\n\nPred = NL:\n contrast ratio     SE df null t.ratio p.value\n Hi / Lo  0.713 0.0867 72    1  -2.782  0.0069\n\nPred = L:\n contrast ratio     SE df null t.ratio p.value\n Hi / Lo  0.855 0.0688 72    1  -1.951  0.0549\n\nTests are performed on the log scale"
  },
  {
    "objectID": "index.html#antes-de-continuar-9",
    "href": "index.html#antes-de-continuar-9",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nMuchas personas gustan de las tablas de grupos de Tukey para las medias marginales esperadas en dise√±os experimentales factoriales al estilo que usamos para poder conducir la opci√≥n 2 anteriormente descrita.\nEsta pr√°ctica es innecesaria si el investigador es capaz de hacer buenas inferencias bas√°ndose en las comparaciones por factor a lo largo de los niveles del otro.\nNo tienen ning√∫n problema operacional ya que a la final es una reparametrizaci√≥n v√°lida del modelo.\nSin embargo, cuando el modelo sobre el cual son aplicadas es incorrecto, son m√°s susceptibles de reflejar valores p que concluyen con inferencias falaces.\nEn el largo ejemplo de las opciones a mano para lidiar con heterodasticidad, podemos con seguridad afirmar que del peor al mejor modelo su orden ser√≠a: Opci√≥n 1 &lt; Opci√≥n 2 &lt; Opci√≥n 3.\nPara ilustrar esto, con la variable dummy que creamos en la opci√≥n 2, calculemos los grupos Tukey de las medias marginales esperadas en las opciones 1 y 3 para su comparaci√≥n."
  },
  {
    "objectID": "index.html#antes-de-continuar-10",
    "href": "index.html#antes-de-continuar-10",
    "title": "Estad√≠stica aplicada con R",
    "section": "Antes de continuar",
    "text": "Antes de continuar\n\n\nGrupos Tukey de las medias marginales esperadas en la opci√≥n 1\n\n\nlm_op1 &lt;- lm(log(Age.DPO) ~ tratamiento, data = ranas)\nemm_op1 &lt;- emmeans(lm_op1, specs = \"tratamiento\", type = \"response\")\nt_grupos_op1 &lt;- contrast(emm_op1, specs = \"tratamiento\", method = \"tukey\")\nt_grupos_op1 &lt;- add_significance(as.data.frame(t_grupos_op1), \n                                p.col = \"p.value\", \n                                output.col = \"p.adj.signif.op1\",\n                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                                symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\n\n\n\n\nGrupos Tukey de las medias marginales esperadas en la opci√≥n 3\n\n\nlm_op3 &lt;- gls(log(Age.DPO) ~ tratamiento,\n                 data = ranas,\n                 weights = varIdent(form = ~1|tratamiento)) \nemm_op3 &lt;- emmeans(lm_op3, specs = \"tratamiento\", type = \"response\")\nt_grupos_op3 &lt;- contrast(emm_op3, specs = \"tratamiento\", method = \"tukey\")\nt_grupos_op3 &lt;- add_significance(as.data.frame(t_grupos_op3), \n                                p.col = \"p.value\", \n                                output.col = \"p.adj.signif.op3\",\n                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n                                symbols = c(\"***\", \"**\", \"*\", \".\", \"ns\"))\n\n\n\n\nUn poco de carpinter√≠a\n\n\ncolnames(games_comp)[c(7,8)] &lt;- c(\"p.value.op2\", \"p.adj.signif.op2\")\ncolnames(t_grupos_op3)[7] &lt;- \"p.value.op3\"\ncolnames(t_grupos_op1)[7] &lt;- \"p.value.op1\"\n\ncomp_table &lt;- cbind(t_grupos_op3[,1],\n                    t_grupos_op1[,c(7, 8)],\n                    games_comp[,c(7, 8)],\n                    t_grupos_op3[,c(7, 8)])\n\ncomp_table &lt;- flextable(comp_table)\nfinal_comp_table &lt;- colformat_double(comp_table, j = c(2, 4, 6), digits = 3)\nfinal_comp_table\n\n\nt_grupos_op3[, 1]p.value.op1p.adj.signif.op1p.value.op2p.adj.signif.op2p.value.op3p.adj.signif.op3(C-Lo) / (NL-Lo)0.665ns0.936ns0.936ns(C-Lo) / (C-Hi)0.000***0.000***0.000***(C-Lo) / (L-Lo)0.000***0.000***0.000***(C-Lo) / (NL-Hi)0.000***0.002**0.001**(C-Lo) / (L-Hi)0.000***0.000***0.000***(NL-Lo) / (C-Hi)0.075.0.545ns0.545ns(NL-Lo) / (L-Lo)0.024*0.419ns0.419ns(NL-Lo) / (NL-Hi)0.072.0.433ns0.433ns(NL-Lo) / (L-Hi)0.000***0.129ns0.129ns(C-Hi) / (L-Lo)0.993ns0.986ns0.987ns(C-Hi) / (NL-Hi)0.995ns0.988ns0.988ns(C-Hi) / (L-Hi)0.134ns0.008**0.008**(L-Lo) / (NL-Hi)1.000ns1.000ns1.000ns(L-Lo) / (L-Hi)0.380ns0.099.0.101ns(NL-Hi) / (L-Hi)0.699ns0.448ns0.435ns"
  },
  {
    "objectID": "index.html#gr√°ficos-de-interacci√≥n",
    "href": "index.html#gr√°ficos-de-interacci√≥n",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de interacci√≥n",
    "text": "Gr√°ficos de interacci√≥n\n\n\nEs una forma de representar las predicciones lineales de un modelo con respecto a los niveles de sus factores.\nEs recomendable usarlos con factores de hasta 3 niveles y en ANOVAS de dos factores as√≠ como tambi√©n con las medias marginales esperadas.\nExisten diversas formas de realizarlos en R:\n\nLibrer√≠a base de R (solo puede hacerlo con medias marginales observadas‚Ä¶ al menos hasta donde tengo conocimiento)\nConstruirlos desde cero con ggplot2 (para las opciones 2 y 3).\nUsar librer√≠as accesorias de ggplot2 como interactions. (Esta alternativa solo es v√°lida para la primera opci√≥n que presentamos)"
  },
  {
    "objectID": "index.html#gr√°ficos-de-interacci√≥n-en-r",
    "href": "index.html#gr√°ficos-de-interacci√≥n-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "Gr√°ficos de interacci√≥n en R",
    "text": "Gr√°ficos de interacci√≥n en R\n\n\n\nlibrary(interactions)\ngraf_inter1 &lt;- cat_plot(\n  lm4,\n  pred = Pred,\n  modx = Res,\n  geom = \"line\",\n  data = ranas\n)\ngraf_inter1\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(interactions)\ngraf_inter2 &lt;- cat_plot(\n  lm4,\n  pred = Res,\n  modx = Pred,\n  geom = \"line\",\n  data = ranas\n)\ngraf_inter2"
  },
  {
    "objectID": "index.html#ejercicios-4.11",
    "href": "index.html#ejercicios-4.11",
    "title": "Estad√≠stica aplicada con R",
    "section": "Ejercicios 4.11",
    "text": "Ejercicios 4.11\n\nLleva a cabo un ANOVA de dos v√≠as para las variables Resorb.days y los factores Pred y Res. La pregunta a investigar es saber si existe una interacci√≥n entre la presencia de predadores a distintos niveles de recursos que afecte el tiempo de reabsorci√≥n de la cola en los renacuajos de ranas arb√≥reas de ojos rojos.\nA pesar de que el modelo para Resorb.day que acabas de hacer cumple con los supuestos del ANOVA, solo por aprendizaje, conduce una prueba de Kruskal-Wallis usando los mismos factores.\n¬øC√≥mo implementar√≠as un DBCA factorial con estos datos?"
  },
  {
    "objectID": "index.html#introducci√≥n-2",
    "href": "index.html#introducci√≥n-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\n\n\nOtro modelo estad√≠stico ampliamente usado es la regresi√≥n lineal.\nSe diferencia del ANOVA al considerar un predictor continuo (no un factor categ√≥rico).\nLos supuestos de la regresi√≥n lineal son:\n\nExistencia de una relaci√≥n lineal entre las variables continuas objeto de la regresi√≥n\nNormalidad de los residuos\nQue no exista multicolinearidad (en el caso de regresi√≥n m√∫ltiple)\nQue no exista auto correlaci√≥n (que las observaciones no dependan una de otra dentro de una misma variable)\nHomogeneidad de la varianza de los residuos\n\nContrario al ANOVA, no existen correcciones o m√©todos alternativos cuando las transformaciones fallan.\nPor esto, lo que se recomienda hacer es mencionar todos los detalles de la conducci√≥n del modelo. Cosa que rara vez pasa.\nEn regresi√≥n lineal es quiz√° en el m√©todo que m√°s se abusa del remover outliers."
  },
  {
    "objectID": "index.html#regresi√≥n-lineal-en-r",
    "href": "index.html#regresi√≥n-lineal-en-r",
    "title": "Estad√≠stica aplicada con R",
    "section": "Regresi√≥n lineal en R",
    "text": "Regresi√≥n lineal en R\n\n\nUsando los datos de Touchon, podr√≠amos preguntarnos si el tama√±o de las ranas al final de la metamorfosis SVL.final est√° influenciado por la edad en finalizar la metamorfosis Age.DPO.\nEsta regresi√≥n lineal ser√≠a de la siguiente forma:\n\n\n\n\nlm6 &lt;- lm(SVL.final ~ Age.DPO, data = ranas)\nsummary(lm6)\n\n\nCall:\nlm(formula = SVL.final ~ Age.DPO, data = ranas)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1414 -0.9521 -0.1297  0.6842  3.4349 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21.285436   0.416763  51.073  &lt; 2e-16 ***\nAge.DPO     -0.029437   0.006052  -4.864 6.08e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.262 on 76 degrees of freedom\nMultiple R-squared:  0.2374,    Adjusted R-squared:  0.2273 \nF-statistic: 23.65 on 1 and 76 DF,  p-value: 6.081e-06\n\n\n\n\n\nPero antes de cualquier inferencia, vamos a darle un vistazo a los diagn√≥sticos de la regresi√≥n lineal"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\npar(mfrow = c(2, 2))\nplot(lm6)\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-1",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-2",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\n\n\n\n\n\n\n\nResiduos vs.¬†Valores ajustados\nEn el ANOVA vimos como este plot suger√≠a departuras de la homocedasticidad. En el caso de la regresi√≥n lineal, los residuos al no estar agrupados en categor√≠as presentan mayor informaci√≥n sobre este supuesto. Adicionalmente, curvaturas en la l√≠nea roja evidencian tambi√©n departuras de la linearidad. Esto quiere decir que la relaci√≥n entre las variables no es completamente lineal. A veces esto puede corregirse con transformaciones."
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-3",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-3",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\n\nEs ideal. (b) Es indicativo de no linearidad. (c) Evidencia de heterodasticidad. (d) Evidencia de una tendencia temporal"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-4",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-4",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\n\n\n\n\n\n\n\nGr√°fico Q-Q\nMisma explicaci√≥n que antes"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-5",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-5",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\n\n\n\n\n\n\n\nRa√≠z cuadrada de los residuos estandarizados vs.¬†Valores ajustados\nMisma explicaci√≥n que antes"
  },
  {
    "objectID": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-6",
    "href": "index.html#diagn√≥sticos-de-la-regresi√≥n-lineal-6",
    "title": "Estad√≠stica aplicada con R",
    "section": "Diagn√≥sticos de la regresi√≥n lineal",
    "text": "Diagn√≥sticos de la regresi√≥n lineal\n\n\n\n\n\n\n\n\nResiduos vs.¬†Apalancamiento\nAquellos puntos que est√©n etiquetados con n√∫meros son mostrados como posibles outliers bajo dos criterios:\n\nEst√°n por fuera de los l√≠mites de la regla del rango intercuart√≠lico (IQR), y\nMarcados como outliers con influencia de apalancamiento mediante la prueba de Cook (distancia de Cook).\n\nEl segundo criterio es un argumento s√≥lido para remover outliers."
  },
  {
    "objectID": "index.html#pruebas-formales-de-los-supuestos",
    "href": "index.html#pruebas-formales-de-los-supuestos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Pruebas formales de los supuestos",
    "text": "Pruebas formales de los supuestos\n\n\nComo vimos, los supuestos de la regresi√≥n lineal son m√°s que para el ANOVA.\nExisten varias pruebas formales para chequear cada uno de sus supuestos, sin embargo rara vez son empleadas.\nLa raz√≥n yace en que si los aplic√°ramos todo el tiempo, no har√≠amos regresiones lineales ni el 10% de las veces.\nSi tienes curiosidad en estas pruebas puedes visitar este enlace.\nDe alguna manera podemos decir que de hecho, los estad√≠sticos somos m√°s laxos con la regresi√≥n lineal, sin embargo esto es bajo el supuesto no estad√≠stico de que estas departuras de los supuestos fueran debidamente documentadas y plasmadas en los trabajos cient√≠ficos, lo cual lamentablemente no pasa muy a menudo.\nExisten por supuesto m√©todos que no dependen de todos estos supuestos (por ejemplo: regresiones lineales Bayesianas, modelos lineales generalizados correctamente parametrizados) pero no son parte de este curso."
  },
  {
    "objectID": "index.html#transformaci√≥n-de-datos",
    "href": "index.html#transformaci√≥n-de-datos",
    "title": "Estad√≠stica aplicada con R",
    "section": "Transformaci√≥n de datos",
    "text": "Transformaci√≥n de datos\n\n\nAl igual que en el ANOVA, podemos recurrir a transformaciones de datos que nos permitan aliviar varios de los supuestos no cumplidos de la regresi√≥n lineal.\nEn el presente caso, esto lo logramos al utilizar el logaritmo natural de las dos variables del modelo\n\n\n\n\nlm6 &lt;- lm(log(SVL.final) ~ log(Age.DPO), data = ranas)\npar(mfrow = c(2, 2))\nplot(lm6)\n\n\n\npar(mfrow = c(1, 1))\nsummary(lm6)\n\n\nCall:\nlm(formula = log(SVL.final) ~ log(Age.DPO), data = ranas)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.182298 -0.049070  0.000516  0.038342  0.159057 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.44001    0.09211  37.345  &lt; 2e-16 ***\nlog(Age.DPO) -0.11624    0.02232  -5.208 1.58e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06244 on 76 degrees of freedom\nMultiple R-squared:  0.263, Adjusted R-squared:  0.2533 \nF-statistic: 27.12 on 1 and 76 DF,  p-value: 1.581e-06"
  },
  {
    "objectID": "index.html#interpretaci√≥n-de-la-regresi√≥n-lineal",
    "href": "index.html#interpretaci√≥n-de-la-regresi√≥n-lineal",
    "title": "Estad√≠stica aplicada con R",
    "section": "Interpretaci√≥n de la regresi√≥n lineal",
    "text": "Interpretaci√≥n de la regresi√≥n lineal\n\n\\[\ny = mx + b\n\\]\n\n\n\n\n\nCall:\nlm(formula = log(SVL.final) ~ log(Age.DPO), data = ranas)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.182298 -0.049070  0.000516  0.038342  0.159057 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.44001    0.09211  37.345  &lt; 2e-16 ***\nlog(Age.DPO) -0.11624    0.02232  -5.208 1.58e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06244 on 76 degrees of freedom\nMultiple R-squared:  0.263, Adjusted R-squared:  0.2533 \nF-statistic: 27.12 on 1 and 76 DF,  p-value: 1.581e-06\n\n\n\n\n\nPor cada incremento en una unidad del logaritmo de Age.DPO, tenemos una unidad en descenso del logaritmo de SVL.final\n\n\n\n\nggplot(ranas, aes(x = log(Age.DPO), y = log(SVL.final))) +\n  geom_point()+\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "index.html#el-m√°gico-r2",
    "href": "index.html#el-m√°gico-r2",
    "title": "Estad√≠stica aplicada con R",
    "section": "El m√°gico \\(R^2\\)",
    "text": "El m√°gico \\(R^2\\)"
  },
  {
    "objectID": "index.html#el-m√°gico-r2-1",
    "href": "index.html#el-m√°gico-r2-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "El m√°gico \\(R^2\\)",
    "text": "El m√°gico \\(R^2\\)\n\n\nQuiz√° muchos hayan escuchado que un \\(R^2\\) cercano a 1 es ‚Äúideal‚Äù cuando realizamos una regresi√≥n lineal.\nRecuerdo incluso haber sido indoctrinado acerca de m√°rgenes para un buen \\(R^2\\) (algo as√≠ como que por encima del 80% es ‚Äúbueno‚Äù, mayor al 90% es excelente y 100% es el Nirvana).\nEn breve, \\(R^2\\) NO ES NINGUNA DE LAS SIGUIENTES COSAS:\n\nUna m√©trica de bondad de ajuste: no nos dice si el modelo se ajusta bien a los datos.\nUna m√©trica del error de predicci√≥n: no mide para nada que tan bueno es el modelo para predecir futuras observaciones.\nUna m√©trica que permita comparar modelos usando variables transformadas: es com√∫n jugar a transformar los datos para ver de que manera se puede inflarlo hacia el santo grial.\nUna m√©trica que permita que tan bien una variable explica otra: en el ejemplo que vimos, y en toda regresi√≥n lineal, si cambiamos el predictor por respuesta y viceversa, tendremos exactamente el mismo \\(R^2\\)\n\n\\(R^2\\) es simplemente una medida de la cantidad de variaci√≥n que un modelo espec√≠fico explica. ¬øTiene alguna utilidad pr√°ctica? no lo s√©, en 10 a√±os como estad√≠stico no lo he usado nunca, al menos no, voluntariamente‚Ä¶"
  },
  {
    "objectID": "index.html#el-m√°gico-r2-2",
    "href": "index.html#el-m√°gico-r2-2",
    "title": "Estad√≠stica aplicada con R",
    "section": "El m√°gico \\(R^2\\)",
    "text": "El m√°gico \\(R^2\\)\n\n\nLo que visto es carnicer√≠as de datos por inflar \\(R^2\\) debido a esta mala interpretaci√≥n que no se sabe su origen exacto (pero quiz√° aqu√≠ uno de tantos culpables perdidos en la historia).\n\n\n\n\nAc√° les dejo unos cuantos recursos que pueden revisar en m√°s detalle si les interesa:\n\nEl paper ‚ÄúHow not to lie with Statistics: Avoiding common mistakes in Quantitative Political Science‚Äù Un art√≠culo extenso pero que contiene una secci√≥n dedicada a desmitificar esta mala pr√°ctica.\nLas notas de la clase del Prof.¬†Cosma Shalizi de la Universidad Carnegie Mellon donde hermosamente destruye los mitos en torno al \\(R^2\\) citando f√≥rmulas y principios estad√≠sticos.\nUn blog de Clay Ford, consultor estad√≠stico de la Universidad de Virginia donde demuestra con R que valores de \\(R^2\\) cercanos a 0 no necesariamente implican un mal modelo, ni valores cercanos 1 son indicativo de modelos destacados."
  },
  {
    "objectID": "index.html#interpretaci√≥n-de-la-regresi√≥n-lineal-1",
    "href": "index.html#interpretaci√≥n-de-la-regresi√≥n-lineal-1",
    "title": "Estad√≠stica aplicada con R",
    "section": "Interpretaci√≥n de la regresi√≥n lineal",
    "text": "Interpretaci√≥n de la regresi√≥n lineal\n\n\nSin embargo una interpretaci√≥n en la escala logar√≠tmica no es completamente entendible, al menos para alguien ajeno al an√°lisis que realizamos.\nPodr√≠amos hacer la retransformaci√≥n de las variables a sus unidades originales y generar un gr√°fico de las predicciones. A la final se reduce a matem√°tica b√°sica.\nAfortunadamente la librer√≠a ggeffects nos salva de ese dilema!\n\n\n\n\nlibrary(ggeffects)\npredicciones &lt;- ggpredict(lm6)\npredicciones\n\n$Age.DPO\n# Predicted values of SVL.final\n\nAge.DPO | Predicted |         95% CI\n------------------------------------\n     35 |     20.63 | [20.05, 21.23]\n     50 |     19.79 | [19.46, 20.13]\n     60 |     19.38 | [19.11, 19.65]\n     75 |     18.88 | [18.57, 19.20]\n     90 |     18.48 | [18.08, 18.90]\n    105 |     18.16 | [17.66, 18.67]\n    120 |     17.88 | [17.30, 18.48]\n    145 |     17.49 | [16.79, 18.22]\n\nattr(,\"class\")\n[1] \"ggalleffects\" \"list\"        \nattr(,\"model.name\")\n[1] \"lm6\"\n\n\n\n\n\nY finalmente el gr√°fico de predicciones\n\n\nplot(predicciones)\n\n$Age.DPO"
  }
]