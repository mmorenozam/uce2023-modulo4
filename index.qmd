---
title: "Estad√≠stica aplicada con R"
subtitle: "M√≥dulo 4: Principios de Estad√≠stica"
title-slide-attributes:
  data-background-image: images/logo.jpeg
  data-background-size: contain
  data-background-opacity: "0.2"
author: 
  - name: Mauricio Moreno, PhD
    affiliations:
      - Cient√≠fico Bioestad√≠stico en Bayer AG
logo: images/logo.jpeg
format: 
  revealjs:
    slide-number: true
    width: 1366
    preview-links: auto
    touch: true
    chalkboard:
      theme: whiteboard
      boardmarker-width: 4
      buttons: false
    revealjs-plugins:
      - pointer
editor: visual
---

# Definiciones b√°sicas

## Antes de comenzar

::: incremental
-   Uno de los objetivos de este curso es el evitar en la medida de lo posible el adentrarnos en teor√≠a estad√≠stica. Entre los temas que dejaremos de lado est√°n:

    -   Teor√≠a de la probabilidad b√°sica

    -   Descripci√≥n a detalle de la distribuci√≥n normal

    -   Descripci√≥n a detalle de otras distribuciones

-   Sin embargo, es preciso el comenzar por algunas definiciones que inevitablemente ser√°n necesarias para entender de mejor manera el resto del mismo.
:::

::: footer
Para qui√©n est√© interesado en un recurso para ver estos temas a profundidad, recomiendo el libro de [Danielle Navarro: *Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}
:::

## Muestras, poblaciones y muestreos

::: incremental
-   **Muestra**: Es un conjunto de observaciones que provienen de una poblaci√≥n de inter√©s. Idealmente, esta deber√≠a ser lo suficientemente grande para hacer inferencias de esa poblaci√≥n.

-   **Poblaci√≥n**: Es el conjunto de todas las posibles observaciones de las que tengamos inter√©s en realizar inferencias. Es vital el definir adecuadamente sus caracter√≠sticas.

-   **Muestreo**: Es el proceso por el cual obtendremos nuestra muestra para un estudio. En estudios experimentales, el muestreo se entiende tambi√©n como el proceso de aleatorizaci√≥n/randomizaci√≥n de unidades experimentales.
:::

## Muestreo simple sin reemplazo

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/simple1.png){fig-align="center" width="900"}

## Muestreo simple con reemplazo

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/simple2.png){fig-align="center" width="1020"}

## Otros tipos de muestreo

::: incremental
-   **Muestreo sistem√°tico**: consiste en tomar un determinado elemento de la poblaci√≥n siguiendo un patr√≥n. Por ejemplo, escoger los m√∫ltiplos de cuatro enumerados en una lista de posibles individuos de estudio (sol√≠a ser una pr√°ctica com√∫n en ensayos cl√≠nicos).

-   **Muestreo a conveniencia**: consiste en incluir en el estudio a todos los elementos disponibles de la poblaci√≥n de inter√©s. Esto sucede sobre todo con poblaciones escasas o de dificil acceso (ejemplo, realizar estudios en comunidades LGBTIQ+).

-   **Muestreo estratificado**: es una combinaci√≥n del muestreo simple con los sujetos agrupados por alguna caracter√≠stica en com√∫n, por ejemplo sexo, edad, h√°bitat (suele ser usado en exit polls y conteos r√°pidos).
:::

## Par√°metros poblacionales y estad√≠sticos muestrales

::: incremental
-   Los par√°metros poblacionales son caracter√≠sticas de toda una poblaci√≥n (ejemplo, supongamos que el IQ de toda una poblaci√≥n puede estar caracterizado por una media aritm√©tica, $\mu$, igual a 100, con una desviaci√≥n est√°ndar, $\sigma$, igual a 15).

-   Si tomo una muestra de 100 individuos de dicha poblaci√≥n, podr√≠a tener una media aritm√©tica de esta muestra, $\overline{X}$, igual a 101.4 y una desviaci√≥n est√°ndar de la muestra, $s$, igual a 13.7.

-   En otras palabras, la $\overline{X}$ y $s$ son aproximaciones a los valores verdareros de $\mu$ y $\sigma$ de esa poblaci√≥n.
:::

## Ley de los n√∫meros grandes

::: incremental
-   La ley de los n√∫meros grandes establece que a medida que aumenta el tama√±o de una muestra, $\overline{X}$ y $s$ estar√°n m√°s y m√°s cerca de los valores verdaderos $\mu$ y $\sigma$.

-   Esta es una de las razones por las cuales en la conducci√≥n de experimentos siempre se aconseja el intentar recabar tantas observaciones sea posible.
:::

::: columns
::: {.column .fragment width="50%"}
```{r echo=T, eval=T, error=T}
set.seed(123)
IQ1 <- rnorm(100, mean = 100, sd = 15)
mean(IQ1)
sd(IQ1)
```
:::

::: {.column .fragment width="50%"}
```{r echo=T, eval=T, error=T}
set.seed(123)
IQ2 <- rnorm(100000, mean = 100, sd = 15)
mean(IQ2)
sd(IQ2)
```
:::
:::

## Distribuci√≥n de muestreo {.smaller}

::: incremental
-   La idea de poder medir enormes n√∫meros de individuos es irreal.

-   Sin embargo, consideremos el siguiente escenario: si en lugar de medir el IQ de 100000 personas, repito el experimento una y otra vez pero en grupos de 5, puedo observar que la *distribuci√≥n de las medias aritm√©ticas* de todos estos experimentos adopta la forma de una distribuci√≥n normal
:::

. . .

![](images/sampling_hist.gif){fig-align="center" width="400"}

## Distribuci√≥n de muestreo {visibility="uncounted"}

::: incremental
-   Esta distribuci√≥n toma el nombre **distribuci√≥n de muestreo de la media aritm√©tica**.

-   Lo que nos demuestra es que, incluso ante reducidos n√∫meros de observaciones en una muestra, la media aritm√©tica de esta muestra ($\overline{X}$) estar√° pr√≥xima a la media aritm√©tica verdadera de la poblaci√≥n ($\mu$).
:::

. . .

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/table1.png){fig-align="center" width="550"}

## Teorema del l√≠mite central {.smaller}

::: incremental
-   El teorema del l√≠mite central establece que siempre que el n√∫mero de observaciones sea lo suficientemente grande, la distribuci√≥n de muestreo de la media aritm√©tica tender√° a ser normal independientemente de si la distribuci√≥n de las observaciones es normal o no.

-   Ejemplo: supongamos que el ancho del caparaz√≥n de una especie de tortugas est√° comprendido entre 4 y 10 cent√≠metros. En otras palabras, si observamos al azar una tortuga de esta poblaci√≥n, sabemos que el ancho del caparaz√≥n estar√° en este rango. En t√©rminos de una distribuci√≥n, podemos decir que el ancho del caparaz√≥n en una poblaci√≥n de 1000 tortugas podr√≠a verse de esta manera:
:::

. . .

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=3.2, fig.width=5}
set.seed(123)
data <- runif(n=1000, min=4, max=10)
hist(data, col='steelblue', main='Histograma del ancho de caparazones')
```

## Teorema del l√≠mite central {visibility="uncounted"}

![](images/sampling_hist1.gif){fig-align="center" width="600"}

## Teorema del l√≠mite central {visibility="uncounted"}

::: incremental
-   Es gracias al teorema del l√≠mite central que la mayor parte de m√©todos estad√≠sticos giran alrededor de la normalidad.

-   Sin embargo, c√≥mo ya hemos mencionado, requiere a veces de un considerable n√∫mero de observaciones para que se cumpla y no todas las veces esto es posible en la pr√°ctica.

-   Por ello, en el desarrollo del curso iremos mostrando ejemplos de cuando esto no ocurre y que medidas podemos tomar en tales casos.
:::

## Estimaci√≥n de par√°metros de poblaci√≥n

**Media aritm√©tica**

| S√≠mbolo     | ¬øQu√© es?                                        | ¬øSabemos qu√© es?         |
|----------|-------------------------------------|----------------------|
| $\overline{X}$   | Media aritm√©tica de la muestra                  | Calculada de los datos   |
| $\mu$       | Verdadera media aritm√©tica de la poblaci√≥n      | Casi nunca es conocida   |
| $\hat{\mu}$ | Estimado de la media aritm√©tica de la poblaci√≥n | S√≠, identica a $\overline{X}$ |

$$
\overline{X} = \frac{1}{n}\sum^{n}_{i=1}\left(X_i\right)
$$

## Estimaci√≥n de par√°metros de poblaci√≥n {visibility="uncounted"}

**Desviaci√≥n est√°ndar**

| S√≠mbolo        | ¬øQu√© es?                                          | ¬øSabemos qu√© es?           |
|----------|------------------------------------|----------------------|
| $s$            | Desviaci√≥n est√°ndar de la muestra                 | Calculada de los datos     |
| $\sigma$       | Verdadera desviaci√≥n est√°ndar de la poblaci√≥n     | Casi nunca es conocida     |
| $\hat{\sigma}$ | Estimado de la deviaci√≥n est√°ndar de la poblaci√≥n | S√≠, pero no es igual a $s$ |

::: columns
::: {.column width="50%"}
$$
s = \sqrt{\frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2} 
$$
:::

::: {.column width="50%"}
$$
\sigma = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2} 
$$
:::
:::


## Estimaci√≥n de par√°metros de poblaci√≥n {visibility="uncounted"}

**Varianza**

| S√≠mbolo        | ¬øQu√© es?                                          | ¬øSabemos qu√© es?           |
|----------|------------------------------------|----------------------|
| $s^2$            | Varianza de la muestra                 | Calculada de los datos     |
| $\sigma^2$       | Verdadera varianza de la poblaci√≥n     | Casi nunca es conocida     |
| $\hat{\sigma}^2$ | Estimado de la varianza de la poblaci√≥n | S√≠, pero no es igual a $s^2$ |

::: columns
::: {.column width="50%"}
$$
s^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2
$$
:::

::: {.column width="50%"}
$$
\sigma^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 
$$
:::
:::


## Intervalos de confianza {.smaller}

::: incremental

-   C√≥mo hemos visto, los estimados de las verdaderas $\mu$ y $\sigma$ ($\hat{\mu}$ y $\hat{\sigma}$) provienen de distribuciones de muestreo, y como tales, inherentemente poseen cierto grado de incertidumbre.

-   Los intervalos de confianza son medidas que nos permiten tener una idea de esa incertidumbre.

-   En el estudio de la distribuci√≥n normal est√°ndar tenemos el conocimiento que existe un 95% de chances que una cantidad normalmente distribuida colectada al azar, estar√° distante de la media aritm√©tica entre $\pm$ 1.96 desviaciones est√°ndar.

:::

. . .

$$
\overline{X} - \left(1.96\times\frac{\sigma}{\sqrt{n}}\right) \leq \mu \leq \overline{X} + \left(1.96\times\frac{\sigma}{\sqrt{n}}\right)
$$

::: incremental

-   Y se interpreta como: **con un 95\% de confianza, podemos esperar que la media aritm√©tica verdadera de la poblaci√≥n de inter√©s se encuentra contenida entre...**

:::

. . .

$$
\text{IC}_{95}=\overline{X} \pm \left(1.96\times\frac{\sigma}{\sqrt{n}}\right) 
$$

## Intervalos de confianza {.smaller visibility="uncounted"}

::: incremental

-   Sin embargo, como mencionamos $\sigma$ es casi nunca conocido, y es necesario hacer una correcci√≥n a la f√≥rmula anterior. La distribuci√≥n normal trabaja bien baja la presunci√≥n de un numero grande de observaciones.

-   En su lugar, en 1908 el estad√≠stico [Gosset](https://en.wikipedia.org/wiki/Student%27s_t-distribution){target="_blank"} parametriz√≥ una distribuci√≥n para muestras peque√±as que asemeja a la normal. Con el tiempo, esta distribuci√≥n adopt√≥ el nombre de *Student*.

-   Y es precisamente que la f√≥rmula anterior es corregida con la distribuci√≥n de Student y as√≠ poder calcular intervalos de confianza para muestras peque√±as usando $s$ en lugar de $\sigma$:

:::

. . .

$$
\text{IC}_{95}=\overline{X} \pm \left(t_{n-1,\alpha/2}\times\frac{s}{\sqrt{n}}\right) 
$$

::: incremental

-   Donde el valor $t_{n-1,\alpha/2}$ refiere a:

    -   $n-1$: los grados de libertad, igual al n√∫mero de observaciones $n$ de la muestra, menos 1
    
    -   $\alpha$: es el nivel de significancia (probabilidad de obtener un resultado err√≥neo por azar).
    
    -   Estos valores en el pasado se encontraban tabulados en libros de texto, hoy contamos con R!

:::

## Intervalos de confianza {visibility="uncounted" autoanimate="true"}

::: incremental

-   Regresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el $\text{IC}_{95}$ 

:::

. . .

```{r echo=T, eval=T, error=T}
#| code-line-numbers: "1|2|3|4|5|6|7"
IQ_muestra <- c(101, 98, 116, 96, 129)   # muestra
n <- 5                                   # n√∫mero de observaciones
t95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%
x <- mean(IQ_muestra)                    # media aritm√©tica de la muestra
s <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra
ls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95
li <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95
```

## Intervalos de confianza {autoanimate="true" visibility="uncounted"}


-   Regresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el $\text{IC}_{95}$ 



```{r echo=T, eval=T, error=T}
#| code-line-numbers: "8"
IQ_muestra <- c(101, 98, 116, 96, 129)   # muestra
n <- 5                                   # n√∫mero de observaciones
t95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%
x <- mean(IQ_muestra)                    # media aritm√©tica de la muestra
s <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra
ls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95
li <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95
print(paste0("Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [",round(li,0),", ",round(ls,0),"]"))
```

## Ejercicios 4.1

La concentraci√≥n media de glucosa en ratones sanos se ha estimado en un rango entre 80 y 100 mg/dL. En un experimento, se han medido las siguientes concentraciones de glucosa en 10 ratones de una l√≠nea gen√©tica se presume tendr√≠a potencial de ser modelo de hiperglucemia despu√©s de unas cuantas m√°s generaciones de cruce selectivo:

. . .

```{r echo=T, eval=F, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
```

. . .

-   Calcula la media aritm√©tica $\overline{X}$, la desviaci√≥n de est√°ndar $s$ y el intervalo de confianza al 95\% de la concentraci√≥n de glucosa en estos ratones. Sin recurrir a pruebas estad√≠sticas formales, ¬ødir√≠as que sus niveles de glucosa est√°n dentro de lo normal o hay raz√≥n para desconfiar que son hipergluc√©micos?

-   Calcula el $\text{IC}_{95}$ sin usar la distribuci√≥n de Student y nota la diferencia.

# Pruebas de hip√≥tesis

## Hip√≥tesis de investigaci√≥n vs. hip√≥tesis estad√≠sticas {.smaller}

::: incremental 

-   Una hip√≥tesis de investigaci√≥n gira alrededor del desarrollar una conclusi√≥n cient√≠fica acerca de un tema de inter√©s del investigador. Ejemplos: *el fumar causa c√°ncer*, *las vacunas causan/previenen enfermedades*.

    -   Es decir, pueden tener una naturaleza subjetiva, que expresan la pregunta del investigador de una manera general sin mayor descripci√≥n del ¬øc√≥mo? voy a probar o descartarla, ni ¬øen qu√© extensi√≥n?.

-   Hip√≥tesis estad√≠sticas, por el contrario, deben ser matem√°ticamente precisas y basadas en las caracter√≠sticas de los datos que recolectemos con el fin de probar o descartar la hip√≥tesis de investigaci√≥n. 

    -   C√≥mo es de esperar, el probar o descartar una hip√≥tesis estad√≠stica ser√° √∫nicamente v√°lida para la poblaci√≥n sobre la cual una muestra fue tomada. 

    -   Es ah√≠ donde radica la importancia en definir la poblaci√≥n sujeto de estudio de manera planificada con el objetivo de que cumpla tantos detalles sean necesarios de la hip√≥tesis de investigaci√≥n. Ejemplo, el modelo animal m√°s usado es el rat√≥n. Si bien es cierto constituye uno de los primeros pasos en el desarrollo de muchas investigaciones, los hallazgos en ratones NO pueden ser inmediatamente atribuibles a suceder en seres humanos.

:::
    
## Hip√≥tesis nula y alternativa {.smaller}

::: incremental

-   La formulaci√≥n de hip√≥tesis estad√≠sticas puede reducirse a establer preguntas de investigaci√≥n en forma de las hip√≥tesis nula y alternativa.

-   La m√°s sencilla manera de formular esta dupla, es la siguiente. Supongamos que tenemos dos grupos experimentales para probar la eficiencia de un nuevo procedimiento quir√∫rgico. Un grupo de pacientes ser√° sometido a la intervenci√≥n tradicional (control), y el otro grupo al nuevo procedimiento (experimental).

    -   La hip√≥tesis nula ($H_0$) establece que: no existe diferencia entre el grupo control y el grupo experimental,
    
    -   Mientras que la hip√≥tesis alternativa ($H_a$) establece que: s√≠ existe differencia entre ambos.
    
:::

. . .

```{=tex}
\begin{align}
H_0& : \mu_c = \mu_e& H_0& : \mu_c- \mu_e =0 \\
H_a& : \mu_c \neq \mu_e& H_a& : \mu_c- \mu_e \neq 0
\end{align}
```


## Tipos de errores

::: incremental

-   Al llevar a cabo pruebas de hip√≥tesis pueden ocurrir errores

:::

. . .

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(xtable)
```

```{r, results='asis'}
dat <- data.frame(
  " " = c("H_{0}\\text{ es verdadera}", "H_{0}\\text{ es falsa}"),
  "\\text{Acepta }H_{0}" = c("\\text{Desici√≥n correcta}", "\\text{Error tipo II}"),
  "\\text{Rechaza }H_{0}" = c("\\text{Error tipo I}", "\\text{Desici√≥n correcta}"),
  check.names = FALSE
)

M <- print(xtable(dat, align=rep("|c|", ncol(dat)+1)), 
           floating = FALSE, tabular.environment="array", 
           comment=FALSE, print.results=FALSE, 
           include.rownames = FALSE,
           sanitize.text.function = function(x) x)
cat(M)
```

. . .

-   ¬øDe qu√© depende que aceptemos correctamente o no la hip√≥tesis nula?

. . .

Las pruebas estad√≠sticas dependen de la cantidad de variaci√≥n y la diferencia entre tratamientos a detectar (**tama√±o del efecto**). La soluci√≥n: aumentar el n√∫mero de observaciones

## Poder de una prueba estad√≠stica

::: incremental

-   El poder de una prueba estad√≠stica es la probabilidad de rechazar la hip√≥tesis nula cuando esta es de hecho falsa.

-   Se puede derivar de la tabla anterior

:::

. . .


```{r, results='asis'}
dat <- data.frame(
  " " = c("H_{0}\\text{ es verdadera}", "H_{0}\\text{ es falsa}"),
  "\\text{Acepta }H_{0}" = c("1-\\alpha\\text{ (Prob. decisi√≥n correcta)}", "\\beta\\text{ (Taza Error tipo II)}"),
  "\\text{Rechaza }H_{0}" = c("\\alpha\\text{ (Taza Error tipo I)}", "1-\\beta\\text{ (Poder)}"),
  check.names = FALSE
)

M <- print(xtable(dat, align=rep("|c|", ncol(dat)+1)), 
           floating = FALSE, tabular.environment="array", 
           comment=FALSE, print.results=FALSE, 
           include.rownames = FALSE,
           sanitize.text.function = function(x) x)
cat(M)
```

. . .

-   En la pr√°ctica, existen f√≥rmulas cerradas para la determinaci√≥n del n√∫mero m√≠nimo de observaciones para alcanzar un poder adecuado ($\ge$ 80\%).


## Tama√±o del efecto {.smaller}

::: incremental

-   El tama√±o del efecto ($\theta$) es un valor que por lo general es determinado por el investigador y que puede ser la diferencia de inter√©s a detectar en una prueba estad√≠stica.

-   Por simplicidad, vamos a enfocarnos en el ejercicio de los ratones. Supongamos que el investigador est√° interesado en saber cual ser√≠a el n√∫mero de ratones que necesitar√≠a para con un 80\% de poder, encontrar una diferencia entre la media aritm√©tica de su muestra y un valor que considera razonable chequear igual a 100 mg/dL. Este √∫ltimo valor viene a ser el $\theta$.

-   Las hip√≥tesis de esta prueba se ver√≠an as√≠

:::

. . .


```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r = \theta \\
H_a& : \mu_c- \mu_r \neq \theta
\end{align}
```

::: incremental

-   Sin embargo, la pregunta del investigador a√∫n est√° incompleta. [**A tu criterio, ¬øqu√© falta?**]{.fragment}

-   Al formular hip√≥tesis, hemos considerado el caso m√°s simple hasta el momento. Pero recordando la idea inicial del experimento de los ratones, la opci√≥n l√≥gica ser√≠a preguntarnos ¬øcu√°ntos ratones necesitamos para estar seguros que la poblaci√≥n sea hipergluc√©mica? (cuyo valor de glucosa en sangre est√© por encima del de un rat√≥n sano)

:::

## Pruebas de dos colas


```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r = \theta \\
H_a& : \mu_c- \mu_r \neq \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/dcolas.gif){fig-align="center" width="400"}


## Pruebas de una cola


```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r \le \theta \\
H_a& : \mu_c- \mu_r > \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/ucolagreat.gif){fig-align="center" width="400"}

## Pruebas de una cola {visibility="uncounted"}


```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r \ge \theta \\
H_a& : \mu_c- \mu_r < \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/ucolaless.gif){fig-align="center" width="400"}


## Un ejemplo de an√°lisis de poder

::: incremental

-   Retomando el poder de una prueba estad√≠stica (aunque no es un objetivo de este curso), culminaremos esta secci√≥n ejemplificando un an√°lisis de poder con nuestro ejemplo del IQ de una muestra de participantes de una determinada poblaci√≥n.

-   Sin entrar en mayor detalle, esto puede lograrse mediante el uso de la librer√≠a `pwr`

-   El tama√±o del efecto para an√°lisis de poder tiene que ser estandarizado

:::

. . .

$$
\theta = \frac{\hat{\mu}_r-\hat{\mu}_c}{s}
$$

::: footer
Para mayor detalle del uso de `pwr` en an√°lisis de poder, puedes acceder a [este recurso](https://med.und.edu/research/daccota/_files/pdfs/berdc_resource_pdfs/sample_size_r_module.pdf){target="_blank"}

:::

## Un ejemplo de an√°lisis de poder{.smaller visibility="uncounted"}

::: incremental

-   Acerca del IQ de la muestra de una poblaci√≥n, supongamos que el investigador est√° interesado en saber el n√∫mero de participantes necesarios para conducir un estudio donde se pueda demostrar que un valor de 100 en IQ esta dentro de la media aritm√©tica del IQ de la poblaci√≥n de donde se tom√≥ la muestra.

:::

. . .

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "3|4|5|6|8|10|11|12|13|14"
library(pwr)

IQ_muestra <- c(101, 98, 116, 96, 129)
s <- sd(IQ_muestra)
uc <- mean(IQ_muestra)
ur <- 100

theta <- (ur-uc)/s

pwr.t.test(d = theta, 
           sig.level = 0.05,
           power = 0.80,
           type = "one.sample",
           alternative = "two.sided")
```

## Un ejemplo de an√°lisis de poder{visibility="uncounted"}

```{r echo=T, eval=T, error=T}
library(pwr)

IQ_muestra <- c(101, 98, 116, 96, 129)
s <- sd(IQ_muestra)
uc <- mean(IQ_muestra)
ur <- 100

theta <- (ur-uc)/s

pwr.t.test(d = theta, 
           sig.level = 0.05,
           power = 0.80,
           type = "one.sample",
           alternative = "two.sided")
```


## Ejercicio 4.2

A partir de los estad√≠sticos de muestreo de la muestra de ratones del ejemplo anterior, ¬øcu√°l ser√≠a el n√∫mero de los mismos para en un futuro experimento llevar a cabo una prueba estad√≠stica con al menos 80\% de poder si el objetivo es demostrar que de hecho la media aritm√©tica de esta l√≠nea de ratones est√° por encima del l√≠mite superior de 100 mg/dL de glucosa en sangre que se sabe poseen ratones saludables? 

```{r echo=T, eval=F, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
```

## Valores cr√≠ticos y el valor p

::: incremental

-   Pero ¬øc√≥mo sabemos si una hip√≥tesis es aceptada o rechazada?

-   Regresando al concepto de los intervalos de confianza, los cuartiles de la distribuci√≥n de Student calculados a un nivel de significancia $\alpha$ son valores cr√≠ticos sobre los cuales se determina el rechazo o aceptaci√≥n de la hip√≥tesis nula.

-   El valor p, describe que tan probable ser√≠a observar resultados de la prueba asumiendo que la hip√≥tesis nula no hubiese sido rechazada. Por ello, a menores valores p, mayor la diferencia estad√≠stica con respecto a la hip√≥tesis alternativa.

:::

# Pruebas estad√≠sticas param√©tricas

## Antes de continuar

::: incremental

-   Para esta secci√≥n del curso usaremos algunas de las tablas de datos del libro [*Using R for Introductory Statistics*](https://www.routledge.com/Using-R-for-Introductory-Statistics/Verzani/p/book/9781466590731#:~:text=Resources%20Support%20Material-,Book%20Description,small%2C%20task%2Doriented%20steps.){target="_blank"}, como tambi√©n de la librer√≠a `datarium`.

-   Para ello, instalaremos las librer√≠as de R: `UsingR` y `datarium`.

:::

. . .


```{r echo=T, eval=T, error=T}
library(UsingR)
library(datarium)
```

::: incremental

-   En esta secci√≥n iniciaremos directamente con la conducci√≥n de las pruebas sin una formal evaluaci√≥n de la normalidad de los datos. M√°s tarde veremos que algunas de las tablas de datos no est√°n normalmente distribuidas üòâ

:::

## Pruebas t {.smaller}

::: incremental

-   Las pruebas t son usadas para encontrar la diferencia entre dos medias aritm√©ticas.

-   La $H_0$ en estas pruebas es que las medias aritm√©ticas son las mismas.

-   Se rechaza la $H_0$ cuando el valor p resultante es $<$ 0.05

-   Existen tres tipos de pruebas t

    -   Pruebas t de una muestra
    
    -   Pruebas t de muestras independientes
    
    -   Pruebas t de muestras emparejadas
    
-   Estas pruebas fueron desarrolladas bajo la suposici√≥n de la normalidad y de homogeneidad de las varianzas.

-   De acuerdo a lo que hemos visto acerca del teorema del l√≠mite central, muestras grandes casi aseguran la normalidad.

-   Cuando el n√∫mero de observaciones en una muestra es peque√±o, es recomendable llevar a cabo un test de normalidad para decidir si es posible llevar a cabo una prueba t o una de sus alternativas.

:::


## Prueba t de una muestra

::: incremental

-   Es usada para comparar la media aritm√©tica de una muestra con un valor conocido (un est√°ndar por ejemplo).

-   Por lo general la el valor al que se va a comparar proviene de referencias bibliogr√°ficas, pre-experimentos o supociones fundamentadas.

-   Regresando a nuestro ejemplo de los ratones, determinemos si la media de la muestra es mayor al l√≠mite superior de glucosa de ratones saludables.

:::

## Prueba t de una muestra {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "1|2|3|4"
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
t.test(glc_rat,
       mu = 100,
       alternative = "greater")
```

## Prueba t de una muestra {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=T, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
t.test(glc_rat,
       mu = 100,
       alternative = "greater")
```

## Ejercicio 4.3 {.smaller}

La tabla de datos `blood` de la librer√≠a `UsingR` tiene las medidas de presi√≥n sist√≥lica de sangre correspondientes a 15 pacientes (columna "machine"). De acuerdo al Centro de Prevenci√≥n y Control de Enfermedades de los Estados Unidos (CDC), una presi√≥n sist√≥lica saludable est√° por debajo de 120 mm Hg. Determina si la media de la muestra contenida en esta tabla de datos est√° por debajo de este valor sugerido por el CDC.

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `blood` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(blood)
blood
```

**Tip: para acceder a la columna con las presiones sist√≥licas, usa la siguiente sintaxis: `blood$machine`**

## Prueba t de muestras independientes

::: incremental

-   Es usado para comparar las medias aritm√©ticas de dos grupos independientes.

-   Por ejemplo, si deseas comparar las medias aritm√©ticas de individuos agrupados por sexo.

-   Para ilustrar esta prueba, vamos a hacer uso de la tabla de datos de `genderweight` de la librer√≠a `datarium`.

    -   Veamos si existe una diferencia significativa en la media del peso entre hombres y mujeres

:::

. . . 

```{r echo=T, eval=T, error=T}
data(genderweight)
```

## Prueba t de muestras independientes {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
t.test(genderweight$weight ~ genderweight$group)
```

## Ejercicio 4.4 {.smaller}

La tabla de datos `normtemp` de la librer√≠a `UsingR` tiene las medidas en grados Fahrenheit de temperatura corporal (columna "temperature" ) correspodientes a 65 mujeres y 65 hombres (columna "gender"). Determina si existe una diferencia entre las temperaturas corporales de hombres y mujeres.

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `normtemp` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(normtemp)
normtemp
```

**Tip: para acceder a las columnas con las temperaturas corporales y sexo, usa la siguiente sintaxis: `normtemp$temperature` y `normtemp$gender` respectivamente**


## Prueba t para muestras emparejadas

::: incremental

-   Es usado para comparar las medias de dos grupos que guardan una relaci√≥n.

-   Esto solo ocurre cuando las medidas se han realizado a partir de los mismos grupos. Por ejemplo, al inicio y al final de un experimento.

-   Para esta prueba, vamos a usar la tabla de datos `crime` de la librer√≠a `UsingR`

    -   Veamos si existe una diferencia en las tasas de crimen (# de reportes/100000 habitantes) en 50 estados de los Estados unidos entre 1983 y 1993

:::

. . .

```{r echo=T, eval=T, error=T}
data(crime)
```

## Prueba t para muestras emparejadas {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
t.test(x = crime$y1983, y = crime$y1993, paired = TRUE)
mean(crime$y1983)
mean(crime$y1993)
```

## Ejercicio 4.5

La tabla de datos `mice2` de la librer√≠a `datarium` tiene las medidas del peso de 10 ratones antes y despu√©s de haber sido sometidos a una determinada dieta. Encuentra si existe una diferencia significativa en el peso de estos ratones antes y despu√©s del r√©gimen de dieta al que fueron expuestos. ¬øGanaron o perdieron peso?

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `normtemp` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(mice2)
mice2
```

**Tip: usa el mismo tips de los ejemplos anteriores**

## Normalidad de una muestra

::: incremental

-   Hasta este momento, hemos asumido que todos los datos analizados son normalmente distribuidos.

-   Por esta raz√≥n, no he introducido las pruebas que en la pr√°ctica deber√≠as realizar en orden de determinar que prueba estad√≠stica es la m√°s adecuada para realizar inferencias estad√≠sticas.

-   Existen dos tipos de pruebas para establecer si una muestra es normalmente distribuida o no

    -   Indirectamente: gr√°fico Q-Q
    
    -   Prueba formal de normalidad Shapiro-Wilk

:::

## Gr√°fico Q-Q

::: incremental

-   El gr√°fico Q-Q es una prueba visual indirecta de la normalidad.

-   Consiste en crear un gr√°fico de dispersi√≥n entre los valores observados de una muestra vs. los valores que deber√≠an estos tener si siguieran una distribuci√≥n normal.

-   Mientras el gr√°fico de dispersi√≥n m√°s concentra sus puntos a lo largo de una diagonal, m√°s cercanos est√°n los datos de la muestra a seguir un distribuci√≥n normal.

-   Es muy subjetivo.

:::


## Gr√°fico Q-Q {visibility="uncounted"} 

```{r echo=T, eval=T, error=T}
y <- rnorm(n = 100, mean = 0, sd = 1) # simulamos 100 observaciones de una normal estandar
qqnorm(y)                             # producimos el gr√°fico Q-Q

```

## Prueba de normalidad Shapiro-Wilk

::: incremental

-   La $H_0$ de esta prueba es que un set de $n$ observaciones es normalmente distribuido.

-   Otro conocido m√©todo es Kolmogorov-Smirnov. Sin embargo, Shapiro-Wilk es m√°s apropiado para cuando el n√∫mero de muestras es menor a 50.

-   Probemos entonces si los datos de crimen en los Estados Unidos son normalmente distribuidos:

    -   Como en este caso tenemos dos muestras, debemos chequear la normalidad de cada grupo sujeto de comparaci√≥n por separado.

:::

## Prueba de normalidad Shapiro-Wilk {visibility="uncounted}

::: columns
::: {.column .fragment width="50%"}

```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1983)     
```


:::

::: {.column .fragment width="50%"}
```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1993)     
```

:::
:::

::: incremental

-   **¬°Los datos no son normalmente distribuidos!** üò±

-   Antes de recurrir a pruebas para datos no normales, podemos recurrir a probar transformaciones de los datos. Las transformaciones m√°s usadas son:

    -   La ra√≠z cuadrada (si los datos no contienen n√∫meros negativos)
    
    -   Elevar al cuadrado 
    
    -   Logaritmo (si los datos solo incluyen n√∫meros reales positivos, cero excluido)

:::


## Prueba de normalidad Shapiro-Wilk {visibility="uncounted}

::: columns
::: {.column .fragment width="50%"}

Ra√≠z cuadrada

```{r echo=T, eval=T, error=T}
shapiro.test(sqrt(crime$y1983))     
```


:::

::: {.column .fragment width="50%"}

Elevar al cuadrado

```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1983^2)     
```

:::
:::

::: columns
::: {.column .fragment width="50%"}

Logaritmo

```{r echo=T, eval=T, error=T}
shapiro.test(log(crime$y1983))     
```


:::

::: {.column .fragment width="50%"}

Chequeemos con el otro grupo

```{r echo=T, eval=T, error=T}
shapiro.test(log(crime$y1993))     
```

:::
:::

## Prueba de normalidad Shapiro-Wilk {visibility="uncounted}

. . .

**Ojo con las transformaciones**

::: incremental

-   Existe un m√©todo m√°s sofisticado para "normalizar" una muestra. [[La transformaci√≥n de Box-Cox.](https://www.r-bloggers.com/2022/10/box-cox-transformation-in-r/)]{.fragment}

-   Cuando se trabaja con muestras transformadas, el objetivo es poder revertir la transformaci√≥n a las unidades reales para as√≠ poder hacer conclusiones sobre las inferencias estad√≠sticas.

-   En otras palabras, una misma transformaci√≥n **debe** aplicarse a todos los grupos a ser comparados. **NO** tiene ning√∫n sentido tratar de realizar inferencias entre grupos donde se hayan usado distintas transformaciones para normalizarlos.

-   Si el n√∫mero de observaciones es muy reducido, no hay transformaci√≥n que funcione y se recomienda usar directamente pruebas no param√©tricas.

:::

## Ejercicios 4.6 {.smaller}

-   Chequea si los datos que usamos en el ejercicio 4.5 de la tabla de datos `mice2` son normalmente distribuidos.

-   En la librer√≠a `UsingR` tenemos disponible una lista con 5 objetos bajo el nombre `cancer`. Esta contiene el tiempo de sobreviviencia en d√≠as de pacientes con distintos tipos de c√°ncer desde el momento de su diagn√≥stico hasta su deceso. Chequea si los datos correspondientes a cancer de colon son normalmente distribuidos. Si no lo son, prueba si puedes normalizarlos usando alguna de las tres transformaciones que vimos. En el caso que m√°s de una transformaci√≥n funcione, ¬øcu√°l escoger√≠as para continuar con alguna prueba estad√≠stica, y por qu√©?

**Tip: usa el siguiente c√≥digo para extraer en un vector los datos de pacientes con c√°ncer de colon:**

```{r echo=T, eval=T, error=T}
data(cancer)
colon <- cancer$colon
```

# Pruebas estad√≠sticas no param√©tricas

## Pruebas de Wilcoxon para datos no normales

::: incremental

-   Las pruebas de Wilcoxon usan la mediana como criterio para evaluar la $H_0$.

-   Lastimosamente, estas pruebas son usualmente menos poderosas (mayor tasa de errores tipo II).

-   Tiene dos formas:

    -   Pruebas para una muestra (an√°loga a la prueba t para una muestra)
    
    -   Pruebas para dos muestras (an√°loga a las pruebas t para dos muestras independientes y emparejadas)

:::


## Prueba de Wilcoxon para una muestra 

::: incremental

-   [Prof. Danielle Navarro](https://learningstatisticswithr.com/){target="_blank"} midi√≥ el nivel de felicidad de sus estudiantes antes y despu√©s de su clase de Estad√≠stica. Ella estaba interesada en saber si el tomar una clase de Estad√≠stica tiene alg√∫n efecto en la felicidad de sus estudiantes. Los datos que obtuvo no est√°n normalmente distribuidos. Por ello, se vio en la necesidad de llevar a cabo una prueba de Wilcoxon.

-   En este caso, la $H_0$, es que la diferencia de la mediana de la felicidad de sus estudiantes antes y despu√©s de la clase deber√≠a ser igual a cero para clamar que no existe tal efecto.

:::


## Prueba de Wilcoxon para una muestra {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
# Primero recreo la tabla de Prof. Navarro
felicidad <- data.frame(before = c(30,43,21,24,23,40,29,56,38,16),
                        after = c(6,29,11,31,17,2,31,21,8,21))
felicidad$change <- felicidad$after - felicidad$before

wilcox.test(felicidad$change, mu = 0)
```

## Prueba de Wilcoxon para dos muestras

::: incremental

-   Regresando al ejemplo de la tabla de datos `genderweight`, sus datos no est√°n normalmente distribuidos üòÆ

-   Suponiendo que no encontramos una transformaci√≥n adecuada para normalizarlos, usaremos la prueba de Wilcoxon para muestras independientes.

:::

. . .

```{r echo=T, eval=T, error=T}
wilcox.test(genderweight$weight ~ genderweight$group, paired = F)
```

## Ejercicios 4.7

-   Con el vector de nombre `colon` que creaste en el ejercicio 4.6, aplica una prueba de Wilcoxon para una muestra bajo la hip√≥tesis de que la mediana de los d√≠as de superviviencia de un paciente con c√°ncer de colon es de 370 d√≠as.

-   A partir de la tabla de datos de felicidad de la Prof. Navarro, lleva a cabo una prueba de Wilcoxon para dos muestras emparejadas de la felicidad de los estudiantes antes y despu√©s de recibir una clase de Estad√≠stica. Compara el resultado con la prueba que de una muestra que us√© de ejemplo. ¬øPor qu√© no hay diferencia?.

# Pruebas b√°sicas para datos discretos

## Tablas de contingencia

::: incremental
-   Una tabla de contigencia nos sirve para ver si los valores de una variable categ√≥rica dependen de los valores de otra variable categ√≥rica.

-   El an√°lisis de contingencia nos permite probar formalmente la asociaci√≥n entre dos o m√°s variables categ√≥ricas.

    -   ¬øQu√© tan probable es que beban m√°s alcohol personas que fuman con respecto a aquellas que no?

    -   ¬øLas personas que toman una aspirina diaria tienen menos probabilidad de sufrir un ataque card√≠aco con respecto a las que no?
:::

## Tabla de contingencia $n \times n$

![](images/cont1.png){fig-align="center" width="649" height="260"}

::: footer
[Modificado de Milo≈° Gejdo≈°, *et al.* (2019) *Int. J. Environ. Res. Public Health* **16**(1)](https://www.mdpi.com/1660-4601/16/1/141){target="_blank"}
:::

## Tabla de contingencia $n \times n$ {visibility="uncounted"}

![](images/cont2.png){fig-align="center" width="649" height="260"}

::: incremental
-   La variable B (o respuesta) contendr√° como posibles resultados "√©xito" o "fracaso".

-   La variable A (o explanatoria) posee las clases que identifican los grupos cuya probabilidad es sujeto de comparaci√≥n.
:::

::: footer
[Modificado de Milo≈° Gejdo≈°, *et al.* (2019) *Int. J. Environ. Res. Public Health* **16**(1)](https://www.mdpi.com/1660-4601/16/1/141){target="_blank"}
:::

## Cociente de probabilidad para tablas de contingencia $2 \times 2$

::: incremental
-   El cociente de probabilidad mide la magnitud de asociaci√≥n entre dos variables categ√≥ricas cuando estas tienen dos clases.

-   En una tabla de contingencia $2 \times 2$, el cociente de probabilidad (OR) se define como:
:::

. . .

$$ OR=\frac{n_{11}/n_{12}}{n_{21}/n_{22}} $$

## Cociente de probabilidad para tablas de contingencia $2 \times 2$ {visibility="uncounted"}

::: incremental
-   La interpretaci√≥n del OR depende de la magnitud del mismo:

    -   Igual a 1, los eventos (clase de la variable explanatoria) son independientes de la variable de respuesta.

    -   Mayor o menor a 1, existe una relaci√≥n positiva o negativa de la variable explanatoria con la variable de respuesta.

    -   La magnitud de OR depende de la clase tomada como base en el an√°lisis.
:::

## Cociente de probabilidad en R {auto-animate="true"}

. . .

Usaremos para este ejemplo los datos del Titanic. La pregunta de investigaci√≥n es: ¬øtuvieron las mujeres mayores probabilidades de salvarse durante el hundimiento del Titanic?

. . .

1.  Cargamos en nuestro ambiente la tabla de datos (librer√≠a `datarium`)


```{r echo=T, eval=T, error=T}
data(titanic.raw)
```


. . .

2.  Definimos las clases de referencia


```{r echo=F, eval=F, error=T}
head(titanic.raw, 4)
```


```{r echo=T, eval=T, error=T}
titanic.raw$Survived <- relevel(titanic.raw$Survived, ref = "Yes")
titanic.raw$Sex <- relevel(titanic.raw$Sex, ref = "Female")
```


## Cociente de probabilidad en R {.smaller visibility="uncounted"}

::: columns
::: {.column .fragment width="55%"}
3.  Creamos la tabla de contingencia

```{r echo=T, eval=T, error=T}
tabla_cont <- table(titanic.raw$Sex, titanic.raw$Survived)
```
:::

::: {.column .fragment width="45%"}
<br>

```{r echo=T, eval=T, error=T}
tabla_cont
```
:::
::: 

. . .

::: columns
::: {.column .fragment width="55%"}
4.  Calculamos el OR

```{r echo=T, eval=T, error=T}
oddratio <- fisher.test(tabla_cont)
```
:::

::: {.column .fragment width="45%"}

<br>
```{r echo=T, eval=T, error=T}
oddratio 
```

:::
:::


## ¬øC√≥mo interpretamos estos resultados? {.smaller}

::: columns
::: {.column width="45%"}
<br>

```{r echo=T, eval=T, error=T}
oddratio
```
:::

::: {.column width="55%"}
::: incremental
-   Vemos que el cociente de probabilidad (OR) es 10. La interpretaci√≥n es: durante el hundimiento del Titanic fue 10 veces m√°s probable que un pasajero se salve si este era mujer.

-   Adicionalmente, del valor p de la prueba estad√≠stica exacta de Fisher menor al 0.05, se puede concluir que este cociente de probabilidad es significativo. En otras palabras, existe evidencia estad√≠stica significativa para afirmar que las probabilidades de sobrevivir durante el hundimiento del Titanic fueron 10 veces m√°s para pasajeras mujeres en comparaci√≥n a los hombres.
:::
:::
::: 

# An√°lisis de Varianza (ANOVA)

## Introducci√≥n

::: incremental

-   Hasta el momento nos hemos enfocado a los casos donde comparamos las medias entre dos grupos.

-   El An√°lisis de Varianza, desarrollado por Fisher a inicios del siglo 20

:::


# ¬°Gracias!