---
title: "Estad√≠stica aplicada con R"
subtitle: "M√≥dulo 4: Herramientas Estad√≠sticas"
title-slide-attributes:
  data-background-image: images/logo.jpeg
  data-background-size: contain
  data-background-opacity: "0.2"
author: 
  - name: Mauricio Moreno, PhD
logo: images/logo.jpeg
format: 
  revealjs:
    css: styles.css
    slide-number: true
    width: 1366
    preview-links: auto
    touch: true
    chalkboard:
      theme: whiteboard
      boardmarker-width: 4
      buttons: false
    revealjs-plugins:
      - pointer
---

# Definiciones b√°sicas

## Antes de comenzar

::: incremental
-   Uno de los objetivos de este curso es el evitar en la medida de lo posible el adentrarnos en teor√≠a estad√≠stica. Entre los temas que dejaremos de lado est√°n:

    -   Teor√≠a de la probabilidad b√°sica

    -   Descripci√≥n a detalle de la distribuci√≥n normal

    -   Descripci√≥n a detalle de otras distribuciones

-   Sin embargo, es preciso el comenzar por algunas definiciones que inevitablemente ser√°n necesarias para entender de mejor manera el resto del mismo.
:::

::: footer
Para qui√©n est√© interesado en un recurso para ver estos temas a profundidad, recomiendo el libro de [Danielle Navarro: *Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}
:::

## Muestras, poblaciones y muestreos

::: incremental
-   **Muestra**: Es un conjunto de observaciones que provienen de una poblaci√≥n de inter√©s. Idealmente, esta deber√≠a ser lo suficientemente grande para hacer inferencias de esa poblaci√≥n.

-   **Poblaci√≥n**: Es el conjunto de todas las posibles observaciones de las que tengamos inter√©s en realizar inferencias. Es vital el definir adecuadamente sus caracter√≠sticas.

-   **Muestreo**: Es el proceso por el cual obtendremos nuestra muestra para un estudio. En estudios experimentales, el muestreo se entiende tambi√©n como el proceso de aleatorizaci√≥n/randomizaci√≥n de unidades experimentales.
:::

## Muestreo simple sin reemplazo

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/simple1.png){fig-align="center" width="900"}

## Muestreo simple con reemplazo

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/simple2.png){fig-align="center" width="1020"}

## Otros tipos de muestreo

::: incremental
-   **Muestreo sistem√°tico**: consiste en tomar un determinado elemento de la poblaci√≥n siguiendo un patr√≥n. Por ejemplo, escoger los m√∫ltiplos de cuatro enumerados en una lista de posibles individuos de estudio (sol√≠a ser una pr√°ctica com√∫n en ensayos cl√≠nicos).

-   **Muestreo a conveniencia**: consiste en incluir en el estudio a todos los elementos disponibles de la poblaci√≥n de inter√©s. Esto sucede sobre todo con poblaciones escasas o de dificil acceso (ejemplo, realizar estudios en comunidades LGBTIQ+).

-   **Muestreo estratificado**: es una combinaci√≥n del muestreo simple con los sujetos agrupados por alguna caracter√≠stica en com√∫n, por ejemplo sexo, edad, h√°bitat (suele ser usado en exit polls y conteos r√°pidos).
:::

## Par√°metros poblacionales y estad√≠sticos muestrales

::: incremental
-   Los par√°metros poblacionales son caracter√≠sticas de toda una poblaci√≥n (ejemplo, supongamos que el IQ de toda una poblaci√≥n puede estar caracterizado por una media aritm√©tica, $\mu$, igual a 100, con una desviaci√≥n est√°ndar, $\sigma$, igual a 15).

-   Si tomo una muestra de 100 individuos de dicha poblaci√≥n, podr√≠a tener una media aritm√©tica de esta muestra, $\overline{X}$, igual a 101.4 y una desviaci√≥n est√°ndar de la muestra, $s$, igual a 13.7.

-   En otras palabras, la $\overline{X}$ y $s$ son aproximaciones a los valores verdareros de $\mu$ y $\sigma$ de esa poblaci√≥n.
:::

## Ley de los n√∫meros grandes

::: incremental
-   La ley de los n√∫meros grandes establece que a medida que aumenta el tama√±o de una muestra, $\overline{X}$ y $s$ estar√°n m√°s y m√°s cerca de los valores verdaderos $\mu$ y $\sigma$.

-   Esta es una de las razones por las cuales en la conducci√≥n de experimentos siempre se aconseja el intentar recabar tantas observaciones sea posible.
:::

::: columns
::: {.column .fragment width="50%"}
```{r echo=T, eval=T, error=T}
set.seed(123)
IQ1 <- rnorm(100, mean = 100, sd = 15)
mean(IQ1)
sd(IQ1)
```
:::

::: {.column .fragment width="50%"}
```{r echo=T, eval=T, error=T}
set.seed(123)
IQ2 <- rnorm(100000, mean = 100, sd = 15)
mean(IQ2)
sd(IQ2)
```
:::
:::

## Distribuci√≥n de muestreo {.smaller}

::: incremental
-   La idea de poder medir enormes n√∫meros de individuos es irreal.

-   Sin embargo, consideremos el siguiente escenario: si en lugar de medir el IQ de 100000 personas, repito el experimento una y otra vez pero en grupos de 5, puedo observar que la *distribuci√≥n de las medias aritm√©ticas* de todos estos experimentos adopta la forma de una distribuci√≥n normal
:::

. . .

![](images/sampling_hist.gif){fig-align="center" width="400"}

## Distribuci√≥n de muestreo {visibility="uncounted"}

::: incremental
-   Esta distribuci√≥n toma el nombre **distribuci√≥n de muestreo de la media aritm√©tica**.

-   Lo que nos demuestra es que, incluso ante reducidos n√∫meros de observaciones en una muestra, la media aritm√©tica de esta muestra ($\overline{X}$) estar√° pr√≥xima a la media aritm√©tica verdadera de la poblaci√≥n ($\mu$).
:::

. . .

![Tomado de [*Learning Statistics with R*](https://learningstatisticswithr.com/){target="_blank"}](images/table1.png){fig-align="center" width="550"}

## Teorema del l√≠mite central {.smaller}

::: incremental
-   El teorema del l√≠mite central establece que siempre que el n√∫mero de observaciones sea lo suficientemente grande, la distribuci√≥n de muestreo de la media aritm√©tica tender√° a ser normal independientemente de si la distribuci√≥n de las observaciones es normal o no.

-   Ejemplo: supongamos que el ancho del caparaz√≥n de una especie de tortugas est√° comprendido entre 4 y 10 cent√≠metros. En otras palabras, si observamos al azar una tortuga de esta poblaci√≥n, sabemos que el ancho del caparaz√≥n estar√° en este rango. En t√©rminos de una distribuci√≥n, podemos decir que el ancho del caparaz√≥n en una poblaci√≥n de 1000 tortugas podr√≠a verse de esta manera:
:::

. . .

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=3.2, fig.width=5}
set.seed(123)
data <- runif(n=1000, min=4, max=10)
hist(data, col='steelblue', main='Histograma del ancho de caparazones')
```

## Teorema del l√≠mite central {visibility="uncounted"}

![](images/sampling_hist1.gif){fig-align="center" width="600"}

## Teorema del l√≠mite central {visibility="uncounted"}

::: incremental
-   Es gracias al teorema del l√≠mite central que la mayor parte de m√©todos estad√≠sticos giran alrededor de la normalidad.

-   Sin embargo, c√≥mo ya hemos mencionado, requiere a veces de un considerable n√∫mero de observaciones para que se cumpla y no todas las veces esto es posible en la pr√°ctica.

-   Por ello, en el desarrollo del curso iremos mostrando ejemplos de cuando esto no ocurre y que medidas podemos tomar en tales casos.
:::

## Estimaci√≥n de par√°metros de poblaci√≥n

**Media aritm√©tica**

| S√≠mbolo        | ¬øQu√© es?                                        | ¬øSabemos qu√© es?              |
|---------|----------------------------------|----------------------|
| $\overline{X}$ | Media aritm√©tica de la muestra                  | Calculada de los datos        |
| $\mu$          | Verdadera media aritm√©tica de la poblaci√≥n      | Casi nunca es conocida        |
| $\hat{\mu}$    | Estimado de la media aritm√©tica de la poblaci√≥n | S√≠, identica a $\overline{X}$ |

$$
\overline{X} = \frac{1}{n}\sum^{n}_{i=1}\left(X_i\right)
$$

## Estimaci√≥n de par√°metros de poblaci√≥n {visibility="uncounted"}

**Desviaci√≥n est√°ndar**

| S√≠mbolo        | ¬øQu√© es?                                          | ¬øSabemos qu√© es?           |
|---------|------------------------------------|--------------------|
| $s$            | Desviaci√≥n est√°ndar de la muestra                 | Calculada de los datos     |
| $\sigma$       | Verdadera desviaci√≥n est√°ndar de la poblaci√≥n     | Casi nunca es conocida     |
| $\hat{\sigma}$ | Estimado de la deviaci√≥n est√°ndar de la poblaci√≥n | S√≠, pero no es igual a $s$ |

::: columns
::: {.column width="50%"}
$$
s = \sqrt{\frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2} 
$$
:::

::: {.column width="50%"}
$$
\sigma = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2} 
$$
:::
:::

## Estimaci√≥n de par√°metros de poblaci√≥n {visibility="uncounted"}

**Varianza**

| S√≠mbolo          | ¬øQu√© es?                                | ¬øSabemos qu√© es?             |
|---------|------------------------------|-----------------------|
| $s^2$            | Varianza de la muestra                  | Calculada de los datos       |
| $\sigma^2$       | Verdadera varianza de la poblaci√≥n      | Casi nunca es conocida       |
| $\hat{\sigma}^2$ | Estimado de la varianza de la poblaci√≥n | S√≠, pero no es igual a $s^2$ |

::: columns
::: {.column width="50%"}
$$
s^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2
$$
:::

::: {.column width="50%"}
$$
\sigma^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 
$$
:::
:::

## Intervalos de confianza {.smaller}

::: incremental
-   C√≥mo hemos visto, los estimados de las verdaderas $\mu$ y $\sigma$ ($\hat{\mu}$ y $\hat{\sigma}$) provienen de distribuciones de muestreo, y como tales, inherentemente poseen cierto grado de incertidumbre.

-   Los intervalos de confianza son medidas que nos permiten tener una idea de esa incertidumbre.

-   En el estudio de la distribuci√≥n normal est√°ndar tenemos el conocimiento que existe un 95% de chances que una cantidad normalmente distribuida colectada al azar, estar√° distante de la media aritm√©tica entre $\pm$ 1.96 desviaciones est√°ndar.
:::

. . .

$$
\overline{X} - \left(1.96\times\frac{\sigma}{\sqrt{n}}\right) \leq \mu \leq \overline{X} + \left(1.96\times\frac{\sigma}{\sqrt{n}}\right)
$$

::: incremental
-   Y se interpreta como: **con un 95% de confianza, podemos esperar que la media aritm√©tica verdadera de la poblaci√≥n de inter√©s se encuentra contenida entre...**
:::

. . .

$$
\text{IC}_{95}=\overline{X} \pm \left(1.96\times\frac{\sigma}{\sqrt{n}}\right) 
$$

## Intervalos de confianza {.smaller visibility="uncounted"}

::: incremental
-   Sin embargo, como mencionamos $\sigma$ es casi nunca conocido, y es necesario hacer una correcci√≥n a la f√≥rmula anterior. La distribuci√≥n normal trabaja bien baja la presunci√≥n de un numero grande de observaciones.

-   En su lugar, en 1908 el estad√≠stico [Gosset](https://en.wikipedia.org/wiki/Student%27s_t-distribution){target="_blank"} parametriz√≥ una distribuci√≥n para muestras peque√±as que asemeja a la normal. Con el tiempo, esta distribuci√≥n adopt√≥ el nombre de *Student*.

-   Y es precisamente que la f√≥rmula anterior es corregida con la distribuci√≥n de Student y as√≠ poder calcular intervalos de confianza para muestras peque√±as usando $s$ en lugar de $\sigma$:
:::

. . .

$$
\text{IC}_{95}=\overline{X} \pm \left(t_{n-1,\alpha/2}\times\frac{s}{\sqrt{n}}\right) 
$$

::: incremental
-   Donde el valor $t_{n-1,\alpha/2}$ refiere a:

    -   $n-1$: los grados de libertad, igual al n√∫mero de observaciones $n$ de la muestra, menos 1

    -   $\alpha$: es el nivel de significancia (probabilidad de obtener un resultado err√≥neo por azar).

    -   Estos valores en el pasado se encontraban tabulados en libros de texto, hoy contamos con R!
:::

## Intervalos de confianza {visibility="uncounted" autoanimate="true"}

::: incremental
-   Regresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el $\text{IC}_{95}$
:::

. . .

```{r echo=T, eval=T, error=T}
#| code-line-numbers: "1|2|3|4|5|6|7"
IQ_muestra <- c(101, 98, 116, 96, 129)   # muestra
n <- 5                                   # n√∫mero de observaciones
t95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%
x <- mean(IQ_muestra)                    # media aritm√©tica de la muestra
s <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra
ls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95
li <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95
```

## Intervalos de confianza {autoanimate="true" visibility="uncounted"}

-   Regresando al ejemplo del IQ, supongamos que medimos al azar el IQ de 5 personas y deseamos calcular el $\text{IC}_{95}$

```{r echo=T, eval=T, error=T}
#| code-line-numbers: "8"
IQ_muestra <- c(101, 98, 116, 96, 129)   # muestra
n <- 5                                   # n√∫mero de observaciones
t95 <- qt(p = 0.975, df = n -1)          # valor de Student para 4 grados de libertad al 5%
x <- mean(IQ_muestra)                    # media aritm√©tica de la muestra
s <- sd(IQ_muestra)                      # desviaci√≥n est√°ndar de la muestra
ls <- x + (t95*s/(n-1))                  # l√≠mite superior del IC95
li <- x - (t95*s/(n-1))                  # l√≠mite inferior del IC95
print(paste0("Con un 95% de confianza podemos esperar que la verdadera media aritm√©tica de IQ de esta poblaci√≥n se encuentre entre [",round(li,0),", ",round(ls,0),"]"))
```

## Ejercicios 4.1

La concentraci√≥n media de glucosa en ratones sanos se ha estimado en un rango entre 80 y 100 mg/dL. En un experimento, se han medido las siguientes concentraciones de glucosa en 10 ratones de una l√≠nea gen√©tica se presume tendr√≠a potencial de ser modelo de hiperglucemia despu√©s de unas cuantas m√°s generaciones de cruce selectivo:

. . .

```{r echo=T, eval=F, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
```

. . .

-   Calcula la media aritm√©tica $\overline{X}$, la desviaci√≥n de est√°ndar $s$ y el intervalo de confianza al 95% de la concentraci√≥n de glucosa en estos ratones. Sin recurrir a pruebas estad√≠sticas formales, ¬ødir√≠as que sus niveles de glucosa est√°n dentro de lo normal o hay raz√≥n para desconfiar que son hipergluc√©micos?

-   Calcula el $\text{IC}_{95}$ sin usar la distribuci√≥n de Student y nota la diferencia.

# Pruebas de hip√≥tesis

## Hip√≥tesis de investigaci√≥n vs. hip√≥tesis estad√≠sticas {.smaller}

::: incremental
-   Una hip√≥tesis de investigaci√≥n gira alrededor del desarrollar una conclusi√≥n cient√≠fica acerca de un tema de inter√©s del investigador. Ejemplos: *el fumar causa c√°ncer*, *las vacunas causan/previenen enfermedades*.

    -   Es decir, pueden tener una naturaleza subjetiva, que expresan la pregunta del investigador de una manera general sin mayor descripci√≥n del ¬øc√≥mo? voy a probar o descartarla, ni ¬øen qu√© extensi√≥n?.

-   Hip√≥tesis estad√≠sticas, por el contrario, deben ser matem√°ticamente precisas y basadas en las caracter√≠sticas de los datos que recolectemos con el fin de probar o descartar la hip√≥tesis de investigaci√≥n.

    -   C√≥mo es de esperar, el probar o descartar una hip√≥tesis estad√≠stica ser√° √∫nicamente v√°lida para la poblaci√≥n sobre la cual una muestra fue tomada.

    -   Es ah√≠ donde radica la importancia en definir la poblaci√≥n sujeto de estudio de manera planificada con el objetivo de que cumpla tantos detalles sean necesarios de la hip√≥tesis de investigaci√≥n. Ejemplo, el modelo animal m√°s usado es el rat√≥n. Si bien es cierto constituye uno de los primeros pasos en el desarrollo de muchas investigaciones, los hallazgos en ratones NO pueden ser inmediatamente atribuibles a suceder en seres humanos.
:::

## Hip√≥tesis nula y alternativa {.smaller}

::: incremental
-   La formulaci√≥n de hip√≥tesis estad√≠sticas puede reducirse a establer preguntas de investigaci√≥n en forma de las hip√≥tesis nula y alternativa.

-   La m√°s sencilla manera de formular esta dupla, es la siguiente. Supongamos que tenemos dos grupos experimentales para probar la eficiencia de un nuevo procedimiento quir√∫rgico. Un grupo de pacientes ser√° sometido a la intervenci√≥n tradicional (control), y el otro grupo al nuevo procedimiento (experimental).

    -   La hip√≥tesis nula ($H_0$) establece que: no existe diferencia entre el grupo control y el grupo experimental,

    -   Mientras que la hip√≥tesis alternativa ($H_a$) establece que: s√≠ existe differencia entre ambos.
:::

. . .

```{=tex}
\begin{align}
H_0& : \mu_c = \mu_e& H_0& : \mu_c- \mu_e =0 \\
H_a& : \mu_c \neq \mu_e& H_a& : \mu_c- \mu_e \neq 0
\end{align}
```
## Tipos de errores

::: incremental
-   Al llevar a cabo pruebas de hip√≥tesis pueden ocurrir errores
:::

. . .

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(xtable)
```

```{r, results='asis'}
dat <- data.frame(
  " " = c("H_{0}\\text{ es verdadera}", "H_{0}\\text{ es falsa}"),
  "\\text{Acepta }H_{0}" = c("\\text{Desici√≥n correcta}", "\\text{Error tipo II}"),
  "\\text{Rechaza }H_{0}" = c("\\text{Error tipo I}", "\\text{Desici√≥n correcta}"),
  check.names = FALSE
)

M <- print(xtable(dat, align=rep("|c|", ncol(dat)+1)), 
           floating = FALSE, tabular.environment="array", 
           comment=FALSE, print.results=FALSE, 
           include.rownames = FALSE,
           sanitize.text.function = function(x) x)
cat(M)
```

. . .

-   ¬øDe qu√© depende que aceptemos correctamente o no la hip√≥tesis nula?

. . .

Las pruebas estad√≠sticas dependen de la cantidad de variaci√≥n y la diferencia entre tratamientos a detectar (**tama√±o del efecto**). La soluci√≥n: aumentar el n√∫mero de observaciones

## Poder de una prueba estad√≠stica

::: incremental
-   El poder de una prueba estad√≠stica es la probabilidad de rechazar la hip√≥tesis nula cuando esta es de hecho falsa.

-   Se puede derivar de la tabla anterior
:::

. . .

```{r, results='asis'}
dat <- data.frame(
  " " = c("H_{0}\\text{ es verdadera}", "H_{0}\\text{ es falsa}"),
  "\\text{Acepta }H_{0}" = c("1-\\alpha\\text{ (Prob. decisi√≥n correcta)}", "\\beta\\text{ (Taza Error tipo II)}"),
  "\\text{Rechaza }H_{0}" = c("\\alpha\\text{ (Taza Error tipo I)}", "1-\\beta\\text{ (Poder)}"),
  check.names = FALSE
)

M <- print(xtable(dat, align=rep("|c|", ncol(dat)+1)), 
           floating = FALSE, tabular.environment="array", 
           comment=FALSE, print.results=FALSE, 
           include.rownames = FALSE,
           sanitize.text.function = function(x) x)
cat(M)
```

. . .

-   En la pr√°ctica, existen f√≥rmulas cerradas para la determinaci√≥n del n√∫mero m√≠nimo de observaciones para alcanzar un poder adecuado ($\ge$ 80%).

## Tama√±o del efecto {.smaller}

::: incremental
-   El tama√±o del efecto ($\theta$) es un valor que por lo general es determinado por el investigador y que puede ser la diferencia de inter√©s a detectar en una prueba estad√≠stica.

-   Por simplicidad, vamos a enfocarnos en el ejercicio de los ratones. Supongamos que el investigador est√° interesado en saber cual ser√≠a el n√∫mero de ratones que necesitar√≠a para con un 80% de poder, encontrar una diferencia entre la media aritm√©tica de su muestra y un valor que considera razonable chequear igual a 100 mg/dL. Este √∫ltimo valor viene a ser el $\theta$.

-   Las hip√≥tesis de esta prueba se ver√≠an as√≠
:::

. . .

```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r = \theta \\
H_a& : \mu_c- \mu_r \neq \theta
\end{align}
```

::: incremental
-   Sin embargo, la pregunta del investigador a√∫n est√° incompleta. [**A tu criterio, ¬øqu√© falta?**]{.fragment}

-   Al formular hip√≥tesis, hemos considerado el caso m√°s simple hasta el momento. Pero recordando la idea inicial del experimento de los ratones, la opci√≥n l√≥gica ser√≠a preguntarnos ¬øcu√°ntos ratones necesitamos para estar seguros que la poblaci√≥n sea hipergluc√©mica? (cuyo valor de glucosa en sangre est√© por encima del de un rat√≥n sano)
:::

## Pruebas de dos colas

```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r = \theta \\
H_a& : \mu_c- \mu_r \neq \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/dcolas.gif){fig-align="center" width="400"}

## Pruebas de una cola

```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r \ge \theta \\
H_a& : \mu_c- \mu_r < \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/ucolagreat.gif){fig-align="center" width="400"}

## Pruebas de una cola {visibility="uncounted"}

```{=tex}
\begin{align}
H_0& : \mu_c- \mu_r \le \theta \\
H_a& : \mu_c- \mu_r > \theta
\end{align}
```

![Imagen tomada de [*UCLA: Advanced Research Computing*](https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-the-differences-between-one-tailed-and-two-tailed-tests/){target="_blank"}](images/ucolaless.gif){fig-align="center" width="400"}

## Un ejemplo de an√°lisis de poder

::: incremental
-   Retomando el poder de una prueba estad√≠stica (aunque no es un objetivo de este curso), culminaremos esta secci√≥n ejemplificando un an√°lisis de poder con nuestro ejemplo del IQ de una muestra de participantes de una determinada poblaci√≥n.

-   Sin entrar en mayor detalle, esto puede lograrse mediante el uso de la librer√≠a `pwr`

-   El tama√±o del efecto para an√°lisis de poder tiene que ser estandarizado
:::

. . .

$$
\theta = \frac{\hat{\mu}_r-\hat{\mu}_c}{s}
$$

::: footer
Para mayor detalle del uso de `pwr` en an√°lisis de poder, puedes acceder a [este recurso](https://med.und.edu/research/daccota/_files/pdfs/berdc_resource_pdfs/sample_size_r_module.pdf){target="_blank"}
:::

## Un ejemplo de an√°lisis de poder {.smaller visibility="uncounted"}

::: incremental
-   Acerca del IQ de la muestra de una poblaci√≥n, supongamos que el investigador est√° interesado en saber el n√∫mero de participantes necesarios para conducir un estudio donde se pueda demostrar que un valor de 100 en IQ esta dentro de la media aritm√©tica del IQ de la poblaci√≥n de donde se tom√≥ la muestra.
:::

. . .

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "3|4|5|6|8|10|11|12|13|14"
library(pwr)

IQ_muestra <- c(101, 98, 116, 96, 129)
s <- sd(IQ_muestra)
uc <- mean(IQ_muestra)
ur <- 100

theta <- (ur-uc)/s

pwr.t.test(d = theta, 
           sig.level = 0.05,
           power = 0.80,
           type = "one.sample",
           alternative = "two.sided")
```

## Un ejemplo de an√°lisis de poder {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
library(pwr)

IQ_muestra <- c(101, 98, 116, 96, 129)
s <- sd(IQ_muestra)
uc <- mean(IQ_muestra)
ur <- 100

theta <- (ur-uc)/s

pwr.t.test(d = theta, 
           sig.level = 0.05,
           power = 0.80,
           type = "one.sample",
           alternative = "two.sided")
```

## Ejercicio 4.2

A partir de los estad√≠sticos de muestreo de la muestra de ratones del ejemplo anterior, ¬øcu√°l ser√≠a el n√∫mero de los mismos para en un futuro experimento llevar a cabo una prueba estad√≠stica con al menos 80% de poder si el objetivo es demostrar que de hecho la media aritm√©tica de esta l√≠nea de ratones est√° por encima del l√≠mite superior de 100 mg/dL de glucosa en sangre que se sabe poseen ratones saludables?

```{r echo=T, eval=F, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
```

## Valores cr√≠ticos y el valor p

::: incremental
-   Pero ¬øc√≥mo sabemos si una hip√≥tesis es aceptada o rechazada?

-   Regresando al concepto de los intervalos de confianza, los cuartiles de la distribuci√≥n de Student calculados a un nivel de significancia $\alpha$ son valores cr√≠ticos sobre los cuales se determina el rechazo o aceptaci√≥n de la hip√≥tesis nula.

-   El valor p, describe que tan probable ser√≠a observar resultados de la prueba asumiendo que la hip√≥tesis nula no hubiese sido rechazada. Por ello, a menores valores p, mayor la diferencia estad√≠stica con respecto a la hip√≥tesis alternativa.
:::

## Antes de continuar

![](images/cena.png){fig-align="center"}

::: footer
Imagen tomada de [aqu√≠](https://arbor-analytics.com/post/2022-10-10-p-ing-in-the-woods-p-values-in-forest-science/){target="_blank"}
:::

## Antes de continuar {.smaller visibility="uncounted"}

::: incremental
-   El umbral de 0.05 es una convenci√≥n arbitraria [creada por Fischer](https://www.bmj.com/rapid-response/2011/11/03/origin-5-p-value-threshold#:~:text=statistician%20RA%20Fisher%20in%201926%20%5B1%5D.){target="_blank"} en los inicios de la estad√≠stica moderna.

-   Lastimosamente, se ha generalizado la idea de que por m√°s m√≠nima sea la diferencia con respecto a 0.05, esta representa la diferencia entre publicar o no (en el campo acad√©mico), entre lanzar o no un nuevo f√°rmaco/producto al mercado (en la industria).

-   En 2014, debido a un fallo de la [corte suprema de justicia de los Estados Unidos](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5017929/#:~:text=A%20statistically%20significant%20test%20result,that%20no%20effect%20was%20observed.){target="_blank"} que le dio la potestad a los inversionistas de farmace√∫ticas a demandarlas por fallar en reportar efectos secundarios de sus productos a pesar de haber sido hallados estad√≠sticamente no significativos, la Asociaci√≥n Americana de Estad√≠stica (ASA) se vio en la necesidad de definir m√°s exhaustivamente el concepto del valor p.

-   Entre las recomendaciones de la ASA, se enfatiz√≥ el dar mayor prioridad a la estimaci√≥n de otros estad√≠sticos complementarios al valor p, tales como intervalos de confianza u otros provenientes de la estad√≠stica Bayesiana (intervalos de credibilidad, factores de Bayes).

-   Esta √∫ltima (estad√≠stica Bayesiana), ofrece una interpretaci√≥n m√°s natural de la estad√≠stica al poder interpretar todos sus resultados en t√©rminos de probabilidades y no en n√∫meros arbirtrarios como el valor p.

-   En resumen, una investigaci√≥n no es in√∫til si el valor p sobrepasa o est√° por debajo de 0.05 por cantidades peque√±as.
:::

## Antes de continuar {.smaller visibility="uncounted" .smaller}

::: incremental
-   En su lugar, en escenarios en que el valor p est√° alejado por una d√©cima o varias cent√©simas de 0.05, los resultados deber√≠an interpretarse como indeterminados para generalizar sobre la poblaci√≥n objeto de estudio y espec√≠ficos a las condiciones experimentales (an√°lisis estad√≠sticos, instrumentos de medici√≥n, etc) bajo las cuales fueron tomadas y modeladas las mediciones.

-   En el contexto de los modelos estad√≠sticos que veremos m√°s adelante, esto ha derivado en un "temor" del investigador cuando los resultados no pasan los chequeos de los supuestos sobre los que estos modelos se cimentan. Sobre todo cuando el valor p dista de 0.05 por √≠nfimas cantidades.

-   Esto puede llevar a malas pr√°cticas cient√≠ficas tales como: no reportar el resultado de los chequeos, blindar los datos, escoger "outliers" y removerlos y en el peor de los casos, manipular los datos para tratar de acomodar nuestros datos a estos chequeos.

-   Todo lo que he mencionado, no solamente constituyen casos de mala conducta cient√≠fica, sino lo que hoy en d√≠a se le conoce como *p hacking* (que se puede resumir a torturar los datos hasta que nos confiesen una verdad agradable a nuestros prop√≥sitos).

:::

# Pruebas estad√≠sticas param√©tricas

## Datos para esta secci√≥n

::: incremental
-   Para esta secci√≥n del curso usaremos algunas de las tablas de datos del libro [*Using R for Introductory Statistics*](https://www.routledge.com/Using-R-for-Introductory-Statistics/Verzani/p/book/9781466590731#:~:text=Resources%20Support%20Material-,Book%20Description,small%2C%20task%2Doriented%20steps.){target="_blank"}, como tambi√©n de la librer√≠a `datarium`.

-   Para ello, instalaremos las librer√≠as de R: `UsingR` y `datarium`.
:::

. . .

```{r echo=T, eval=T, error=T}
library(UsingR)
library(datarium)
```

## Pruebas t {.smaller}

::: incremental
-   Las pruebas t son usadas para encontrar la diferencia entre dos medias aritm√©ticas.

-   La $H_0$ en estas pruebas es que las medias aritm√©ticas son las mismas.

-   Se rechaza la $H_0$ cuando el valor p resultante es $<$ 0.05

-   Existen tres tipos de pruebas t

    -   Pruebas t de una muestra

    -   Pruebas t de muestras independientes

    -   Pruebas t de muestras emparejadas

-   Estas pruebas fueron desarrolladas bajo la suposici√≥n de la **normalidad** y de **homogeneidad de las varianzas**.

-   De acuerdo a lo que hemos visto acerca del teorema del l√≠mite central, muestras grandes casi aseguran la normalidad.

-   Cuando el n√∫mero de observaciones en una muestra es peque√±o, es recomendable llevar a cabo un test de normalidad para decidir si es posible una prueba t o una de sus alternativas.
:::

## Normalidad de una muestra

::: incremental
-   Antes de llevar a cabo las pruebas t, hemos mencionado sus supuestos. Por ello, es aconsejable el siempre realizar estas pruebas antes de usarlas.

-   Existen dos tipos de pruebas para establecer si una muestra es normalmente distribuida o no

    -   Indirectamente: gr√°fico Q-Q

    -   Prueba formal de normalidad (ejemplo: Shapiro-Wilk)

-   **En el caso del ANOVA**, es importante enfatizar que estas pruebas no necesariamente tienen que hacerse antes de la prueba, como ya veremos m√°s adelante.
:::

## Gr√°fico Q-Q

::: incremental
-   El gr√°fico Q-Q es una prueba visual indirecta de la normalidad.

-   Consiste en crear un gr√°fico de dispersi√≥n entre los valores observados de una muestra vs. los valores que deber√≠an estos tener si siguieran una distribuci√≥n normal.

-   Mientras en el gr√°fico de dispersi√≥n los puntos m√°s se distribuyan a lo largo de una diagonal, m√°s cercanos est√°n los datos de la muestra a seguir un distribuci√≥n normal.

-   Su desventaja es que es muy subjetivo, y a menudo requiere una prueba formal para poder confirmarlo.
:::

## Gr√°fico Q-Q {visibility="uncounted"}

```{r echo=T, eval=F, error=T, fig.width=6, fig.align='center'}
#| code-line-numbers: "1|2|3"
set.seed(123)
y <- rnorm(n = 30, mean = 0, sd = 1)  # simulamos 30 observaciones de una normal estandar
qqnorm(y)                             # producimos el gr√°fico Q-Q
```

## Gr√°fico Q-Q {visibility="uncounted"}

```{r echo=T, eval=T, error=T, fig.width=6, fig.align='center'}
set.seed(123)
y <- rnorm(n = 30, mean = 0, sd = 1)  # simulamos 30 observaciones de una normal estandar
qqnorm(y)                             # producimos el gr√°fico Q-Q
```

## Prueba de normalidad Shapiro-Wilk

::: incremental
-   La $H_0$ de esta prueba (y del resto de pruebas formales de normalidad) es que un set de $n$ observaciones es normalmente distribuido.

-   Otro conocido m√©todo es Kolmogorov-Smirnov. Sin embargo, Shapiro-Wilk es m√°s apropiado para cuando el n√∫mero de muestras es menor a 50.

-   Para ilustrar su uso, chequeemos la normalidad de los datos que simulamos anteriormente
:::

. . .

```{r echo=T, eval=T, error=T, fig.width=6, fig.align='center'}
shapiro.test(y)
```

## Prueba de homogeneidad de las varianzas {.smaller}

::: incremental
-   En el caso de comparaciones entre las medias de dos grupos, la homogeneidad de varianzas puede chequearse usando la prueba F.

-   La prueba t de una muestra no requiere chequear este supuesto.

-   Para ilustrar su uso, creemos otro vector con datos simulados. En este caso, un igual n√∫mero de observaciones con la misma desviaci√≥n est√°ndar pero diferente media:
:::

. . .

```{r echo=T, eval=T, error=T, fig.width=6, fig.align='center'}
set.seed(123)
x <- rnorm(n = 30, mean = 4, sd = 1)
var.test(x, y)
```

## Supuestos en la pr√°ctica {.scrollable}

::: incremental
-   Usemos las pruebas con datos reales, esta vez con la tabla de datos `crime` de la librer√≠a `Using R`.

-   Esta tabla de datos contiene registros de las tasas de crimen (# de reportes/100000 habitantes) en 50 estados en los Estados Unidos correspondiente a los a√±os 1983 y 1993.

-   Sin enfocarnos por el momento en que prueba t espec√≠fica usaremos, limit√©monos a chequear la normalidad y la homogeneidad de varianzas entre las tasas de crimen registradas en 1983 y 1993.
:::

. . .

```{r echo=T, eval=T, error=T}
data(crime)
```

::: columns
::: {.column .fragment width="50%"}
Normalidad 1983

```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1983)     
```
:::

::: {.column .fragment width="50%"}
Normalidad 1993

```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1993)     
```
:::
:::

. . .

Homogeneidad de las varianzas

```{r echo=T, eval=T, error=T, fig.width=6, fig.align='center'}
var.test(crime$y1983, crime$y1993)
```

![](images/calmarno.jpg){fig-align="center"}

## Transformaci√≥n de variables

::: incremental
-   A menudo nos encontraremos con conjuntos de observaciones que no cumplen uno o ninguno de los supuestos.

-   Antes de considerar pruebas no param√©tricas, podemos intentar transformaciones de variables para regresar al mundo de las pruebas param√©tricas. Las transformaciones m√°s usadas son:

    -   La ra√≠z cuadrada (si los datos no contienen n√∫meros negativos)

    -   Elevar al cuadrado

    -   Logaritmo (si los datos solo incluyen n√∫meros reales positivos, cero excluido)
:::

## Transformaci√≥n de variables {visibility="\"uncounted"}

::: incremental
-   Existe un m√©todo m√°s sofisticado para "normalizar" una muestra. [[La transformaci√≥n de Box-Cox.](https://www.r-bloggers.com/2022/10/box-cox-transformation-in-r/)]{.fragment}

-   Cuando se trabaja con muestras transformadas, el objetivo es poder revertir la transformaci√≥n a las unidades reales para as√≠ poder hacer conclusiones sobre las inferencias estad√≠sticas.

-   En otras palabras, una misma transformaci√≥n **debe** aplicarse a todos los grupos a ser comparados. **NO** tiene ning√∫n sentido tratar de realizar inferencias entre grupos donde se hayan usado distintas transformaciones para normalizarlos.

-   Si el n√∫mero de observaciones es muy reducido, usualmente no hay transformaci√≥n que funcione y se recomienda usar directamente pruebas no param√©tricas.
:::

## Transformaci√≥n de variables {.scrollable visibility="\"uncounted"}

::: columns
::: {.column .fragment width="50%"}
Ra√≠z cuadrada

```{r echo=T, eval=T, error=T}
shapiro.test(sqrt(crime$y1983))     
```
:::

::: {.column .fragment width="50%"}
Elevar al cuadrado

```{r echo=T, eval=T, error=T}
shapiro.test(crime$y1983^2)     
```
:::
:::

::: columns
::: {.column .fragment width="50%"}
Logaritmo

```{r echo=T, eval=T, error=T}
shapiro.test(log(crime$y1983))     
```
:::

::: {.column .fragment width="50%"}
Chequeemos con el otro grupo

```{r echo=T, eval=T, error=T}
shapiro.test(log(crime$y1993))     
```
:::
:::

. . .

Homogeneidad de las varianzas con transformaci√≥n logar√≠tmica

```{r echo=T, eval=T, error=T, fig.width=6, fig.align='center'}
var.test(log(crime$y1983), log(crime$y1993))
```

![](images/kid.jpg){fig-align="center"}

## Prueba t de una muestra

::: incremental
-   Es usada para comparar la media aritm√©tica de una muestra con un valor conocido (un est√°ndar por ejemplo).

-   Por lo general el valor al que se va a comparar proviene de referencias bibliogr√°ficas, pre-experimentos o supociones fundamentadas.

-   En este caso, el supuesto que debe cumplirse es el de la normalidad de los datos

-   Regresando a nuestro ejemplo de los ratones, determinemos si la media de la muestra es mayor al l√≠mite superior de glucosa de ratones saludables.
:::

## Prueba t de una muestra {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "1|2|3|4"
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
t.test(glc_rat,
       mu = 100,
       alternative = "greater")
```

## Prueba t de una muestra {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=T, error=T}
glc_rat <- c(108.7, 93.7, 52.7, 79.0, 74.7, 131.9, 99.5, 63.3, 98.6, 92.7)
t.test(glc_rat,
       mu = 100,
       alternative = "greater")
```

## Ejercicio 4.3 {.smaller}

La tabla de datos `blood` de la librer√≠a `UsingR` tiene las medidas de presi√≥n sist√≥lica de sangre correspondientes a 15 pacientes (columna "machine"). De acuerdo al Centro de Prevenci√≥n y Control de Enfermedades de los Estados Unidos (CDC), una presi√≥n sist√≥lica saludable est√° por debajo de 120 mm Hg. Determina si la media de la muestra contenida en esta tabla de datos est√° por debajo de este valor sugerido por el CDC.

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `blood` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(blood)
blood
```

**Tip: para acceder a la columna con las presiones sist√≥licas, usa la siguiente sintaxis: `blood$machine`**

## Prueba t de muestras independientes

::: incremental
-   Es usado para comparar las medias aritm√©ticas de dos grupos independientes.

-   Por ejemplo, si deseas comparar las medias aritm√©ticas de individuos agrupados por sexo.

-   Para ilustrar esta prueba, vamos a hacer uso de la tabla de datos de `genderweight` de la librer√≠a `datarium`.

    -   Veamos si existe una diferencia significativa en la media del peso entre hombres y mujeres
:::

. . .

```{r echo=T, eval=T, error=T}
data(genderweight)
```

## Prueba t de muestras independientes {.scrollable .smaller visibility="uncounted"}

::: columns
::: {.column .fragment width="50%"}
Chequeamos normalidad: Group M

```{r echo=T, eval=T, error=T}
shapiro.test(subset(genderweight, group == "M")$weight)     
```
:::

::: {.column .fragment width="50%"}
Chequeamos normalidad: Group F

```{r echo=T, eval=T, error=T}
shapiro.test(subset(genderweight, group == "F")$weight)     
```
:::
:::

. . .

Chequeamos la homogeneidad de las varianzas

```{r echo=T, eval=T, error=T}
var.test(genderweight$weight ~ genderweight$group)
```

::: incremental
-   **¬°La homogeneidad de las varianzas no se cumple!** üò±

-   ¬øDebemos transformar? [No necesariamente]{.fragment}

-   El no cumplir con el supuesto de la homogeneidad de varianzas no es un gran problema gracias a varias correcciones.

-   La funci√≥n base de R `t.test` cuenta con el argumento `var.equal = F` como default.

-   Bajo este argumento, no se asumen varianzas iguales entre los grupos y en su lugar R lleva a cabo la aproximaci√≥n de Welch para lidiar con este problema.

:::

## Prueba t de muestras independientes {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
t.test(genderweight$weight ~ genderweight$group)
```

## Ejercicio 4.4 {.smaller}

La tabla de datos `normtemp` de la librer√≠a `UsingR` tiene las medidas en grados Fahrenheit de temperatura corporal (columna "temperature" ) correspodientes a 65 mujeres y 65 hombres (columna "gender"). Determina si existe una diferencia entre las temperaturas corporales de hombres y mujeres.

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `normtemp` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(normtemp)
normtemp
```

**Tip: para acceder a las columnas con las temperaturas corporales y sexo, usa la siguiente sintaxis: `normtemp$temperature` y `normtemp$gender` respectivamente**

## Prueba t para muestras emparejadas

::: incremental
-   Es usado para comparar las medias de dos grupos que guardan una relaci√≥n.

-   Esto solo ocurre cuando las medidas se han realizado a partir de los mismos grupos. Por ejemplo, al inicio y al final de un experimento.

-   Para esta prueba, vamos a usar la tabla de datos `crime` de la librer√≠a `UsingR`

    -   Veamos si existe una diferencia en las tasas de crimen (# de reportes/100000 habitantes) en 50 estados de los Estados unidos entre 1983 y 1993
:::

. . .

```{r echo=T, eval=T, error=T}
data(crime)
```

## Prueba t para muestras emparejadas {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=F, error=T}
#| code-line-numbers: "1|2|3"
t.test(x = log(crime$y1983), y = log(crime$y1993), paired = TRUE)
exp(mean(log(crime$y1983)))
exp(mean(log(crime$y1993)))
```

## Prueba t para muestras emparejadas {visibility="uncounted" autoanimate="true"}

```{r echo=T, eval=T, error=T}
t.test(x = log(crime$y1983), y = log(crime$y1993), paired = TRUE)
exp(mean(log(crime$y1983)))
exp(mean(log(crime$y1993)))
```

## Ejercicio 4.5

La tabla de datos `mice2` de la librer√≠a `datarium` tiene las medidas del peso de 10 ratones antes y despu√©s de haber sido sometidos a una determinada dieta. Encuentra si existe una diferencia significativa en el peso de estos ratones antes y despu√©s del r√©gimen de dieta al que fueron expuestos. ¬øGanaron o perdieron peso?

Copia y pega las siguientes l√≠neas de c√≥digo a tu script. Luego de ejecutarlas, una tabla de datos de nombre `mice2` aparecer√° disponible en la ventana del ambiente de RStudio

```{r echo=T, eval=F, error=T}
data(mice2)
mice2
```

**Tip: usa el mismo tips de los ejemplos anteriores**

## Ejercicios 4.6 {.smaller}

-   En la librer√≠a `UsingR` tenemos disponible una lista con 5 objetos bajo el nombre `cancer`. Esta contiene el tiempo de sobreviviencia en d√≠as de pacientes con distintos tipos de c√°ncer desde el momento de su diagn√≥stico hasta su deceso. Chequea si los datos correspondientes a c√°ncer de colon son normalmente distribuidos. Si no lo son, prueba si puedes normalizarlos usando alguna de las tres transformaciones que vimos. En el caso que m√°s de una transformaci√≥n funcione, ¬øcu√°l escoger√≠as para continuar con alguna prueba estad√≠stica, y por qu√©?

**Tip: usa el siguiente c√≥digo para extraer en un vector los datos de pacientes con c√°ncer de colon:**

```{r echo=T, eval=T, error=T}
data(cancer)
colon <- cancer$colon
```

# Pruebas estad√≠sticas no param√©tricas

## Pruebas de Wilcoxon para datos no normales

::: incremental
-   Las pruebas de Wilcoxon usan la mediana como criterio para evaluar la $H_0$.

-   Lastimosamente, estas pruebas son usualmente menos poderosas (mayor tasa de errores tipo II).

-   Tiene dos formas:

    -   Pruebas para una muestra (an√°loga a la prueba t para una muestra)

    -   Pruebas para dos muestras (an√°loga a las pruebas t para dos muestras independientes y emparejadas)
:::

## Prueba de Wilcoxon para una muestra

::: incremental
-   [Prof. Danielle Navarro](https://learningstatisticswithr.com/){target="_blank"} midi√≥ el nivel de felicidad de sus estudiantes antes y despu√©s de su clase de Estad√≠stica. Ella estaba interesada en saber si el tomar una clase de Estad√≠stica tiene alg√∫n efecto en la felicidad de sus estudiantes. Los datos que obtuvo no est√°n normalmente distribuidos. Por ello, se vio en la necesidad de llevar a cabo una prueba de Wilcoxon.

-   En este caso, la $H_0$, es que la diferencia de la mediana de la felicidad de sus estudiantes antes y despu√©s de la clase deber√≠a ser igual a cero para clamar que no existe tal efecto.
:::

## Prueba de Wilcoxon para una muestra {visibility="uncounted"}

```{r echo=T, eval=T, error=T}
# Primero recreo la tabla de Prof. Navarro
felicidad <- data.frame(before = c(30,43,21,24,23,40,29,56,38,16),
                        after = c(6,29,11,31,17,2,31,21,8,21))
felicidad$change <- felicidad$after - felicidad$before

wilcox.test(felicidad$change, mu = 0)
```

## Prueba de Wilcoxon para dos muestras

::: incremental
-   Regresando al ejemplo de la tabla de datos `genderweight`, supongamos que estos no est√°n normalmente distribuidos.

-   Usaremos la prueba de Wilcoxon para muestras independientes para ver si existe diferencia entre los pesos de hombres y mujeres.
:::

. . .

```{r echo=T, eval=T, error=T}
wilcox.test(genderweight$weight ~ genderweight$group, paired = F)
```

## Ejercicios 4.7

-   Con el vector de nombre `colon` que creaste en el ejercicio 4.6, aplica una prueba de Wilcoxon para una muestra bajo la hip√≥tesis de que la mediana de los d√≠as de superviviencia de un paciente con c√°ncer de colon es de 370 d√≠as.

-   A partir de la tabla de datos de felicidad de la Prof. Navarro, lleva a cabo una prueba de Wilcoxon para dos muestras emparejadas de la felicidad de los estudiantes antes y despu√©s de recibir una clase de Estad√≠stica. Compara el resultado con la prueba de una muestra que us√© de ejemplo. ¬øPor qu√© no hay diferencia?.

# Pruebas para datos discretos

## Introducci√≥n

::: incremental

-   Para valores discretos univariados tenemos:

    -   Estad√≠sticos descriptivos
    
    -   Prueba de bondad de ajuste de $\chi^2$

-   Para datos discretos bivariados arreglados en **Tablas de contingencia** tenemos:
    
    -   Prueba de independencia de $\chi^2$
    
    -   Prueba exacta de Fisher

:::

## Revisitando los estad√≠sticos descriptivos {.smaller .scrollable}

::: incremental

-   Recordar√°n que en m√≥dulo de an√°lisis exploratorio de datos vimos los estad√≠sticos descriptivos usando la funci√≥n base `summary`. 

-   Sin embargo, para los fines del AED, `summary` es suficiente para tener una idea de estos estad√≠sticos pero su exportaci√≥n a tablas de Word es un proceso tedioso.

-   Aprovechando esta oportunidad, vamos a ver una forma de ver a los estad√≠sticos descriptivos con la posibilidad de exportarlos a Word de una manera sencilla.

-   Para ello usaremos la librer√≠a `tidycomm`, `flextable` y `palmerpenguins`.

:::

. . .

```{r echo=T, eval=T, error=T}
library(tidycomm)
library(palmerpenguins)
library(flextable)

data("penguins")
penguins_cat <- describe_cat(penguins)
penguins_cat
```

## Tablas de estad√≠sticos descriptivos {.smaller visibility="uncounted" .scrollable}

**Tablas de estad√≠sticos descriptivos de variables continuas**

```{r echo=T, eval=T, error=T}
penguins_con <- describe(penguins)
penguins_con
```

. . .

```{r echo=T, eval=T, error=T}
tabla1 <- flextable(penguins_cat)
tabla2 <- flextable(penguins_con)
tabla2
```

. . .

```{r echo=T, eval=T, error=T}
tabla1 <- flextable(penguins_cat)
tabla2 <- flextable(penguins_con)
tabla2 <- colformat_double(tabla2, j = c(3:15), digits = 2)
tabla2
save_as_docx("Tabla1" = tabla1, "Tabla2" = tabla2,
             path = "C:/Users/mmore/Documents/cursos_uce_2023/modulos/uce2023-modulo4/descriptivos.docx")
```


## Prueba de bondad de ajuste $\chi^2$ {.smaller}

::: incremental

-   Permite el comparar que tan bien se ajustan las proporciones (probabilidades) observadas en las categor√≠as de una variable discreta con respecto de una probabilidad hipot√©tica de estas.

-   Volviendo con los ping√ºinos de Palmer, supongamos que quisieramos probar que la distribuci√≥n observada de estos a lo largo de las tres islas donde fueron encontrados es igual 1/3 por isla.

-   La $H_0$ ser√≠a: encontramos la misma proporci√≥n de ping√ºinos en cada isla (1/3 = 1/3 = 1/3)

:::

. . .

-   Checamos cu√°ntos ping√ºinos fueron observados por isla

```{r echo=T, eval=T, error=T}
table(penguins$island)
```

. . . 

-   Llevamos a cabo la prueba de bondad de ajuste de $\chi^2$

```{r echo=T, eval=T, error=T}
penguins_isla <- c(168, 124, 52)
chisq.test(penguins_isla, p = c(1/3, 1/3, 1/3))
```


## Tablas de contingencia

::: incremental
-   Una tabla de contigencia nos sirve para ver si los valores de una variable categ√≥rica dependen de los valores de otra variable categ√≥rica.

    -   ¬øQu√© tan probable es que beban m√°s alcohol personas que fuman con respecto a aquellas que no?

    -   ¬øLas personas que toman una aspirina diaria tienen menos probabilidad de sufrir un ataque card√≠aco con respecto a las que no?
    
    -   ¬øDurante la tragedia del Titanic, tuvieron tanto hombres como mujeres los mismos chances de salvarse?
:::

## Tabla de contingencia $n \times n$

![](images/cont1.png){fig-align="center" width="649" height="260"}

::: footer
[Modificado de Milo≈° Gejdo≈°, *et al.* (2019) *Int. J. Environ. Res. Public Health* **16**(1)](https://www.mdpi.com/1660-4601/16/1/141){target="_blank"}
:::


## Prueba de independencia de $\chi^2$ {.smaller .scrollable}

::: incremental

-   Puede usarse con 2 variables discretas con m√°s de dos categor√≠as. 

-   La $H_0$ en esta prueba es que las filas y columnas de la tabla de contingencia son independientes.

:::

. . . 

-   Construimos la tabla de contingencia

```{r echo=T, eval=T, error=T}
cont_tabla <- xtabs(~ island + species, data = penguins)
cont_tabla
```

. . . 

-   Llevamos a cabo la prueba de independencia de $\chi^2$

```{r echo=T, eval=T, error=T}
chisq <- chisq.test(cont_tabla)
chisq
```

## Dependencia entre las filas y las columnas

. . . 

-   Extraemos los residuos (residuos) de la prueba $\chi^2$

```{r echo=T, eval=T, error=T}
residuos <- chisq$residuals
```


::: columns
::: {.column .fragment width="50%"}
-   Con ayuda de la librer√≠a `corrplot` podemos ver a las dependencias una por una

```{r echo=T, eval=F, error=T}
library(corrplot)
corrplot(residuos, is.corr = F)
```

:::

::: {.column .fragment width="50%"}


```{r echo=F, eval=T, error=T}
library(corrplot)
corrplot(residuos, is.corr = F)
```
:::
:::

## Ejercicio 4.8

La tabla de datos `housetasks` tiene una tabla de contingencia con dos variables discretas, en las filas: tareas del hogar, y en las columnas: responsable (de llevarlas a cabo). Las celdas de esta tabla cuentan el n√∫mero de veces que estas preguntas fueron contestadas en una encuesta. Para acceder a esta tabla, copia, pega y ejecuta las siguientes l√≠neas de c√≥digo:

```{r echo=T, eval=F, error=T}
file_path <- "http://www.sthda.com/sthda/RDoc/data/housetasks.txt"
housetasks <- read.delim(file_path, row.names = 1)
```

Realiza una prueba de independencia de $\chi^2$ en esta tabla de contigencia.

## Prueba exacta de Fisher

::: incremental

-   Es usada cuando el conteo de las combinaciones de las clases de dos variables discretas es peque√±o. Cuando este n√∫mero es muy grande, la funci√≥n de R `fisher.test` devuelve un mensaje sugiriendo usar otra prueba estad√≠stica en su lugar.

-   Tambi√©n se puede usar cuando las variables discretas tienen varias categor√≠as. Sin embargo, su uso m√°s com√∫n es en tablas de contingencia 2 \times 2. 

-   Esto √∫ltimo por cu√°nto introduce un estad√≠stico conocido como cociente de probabilidades (en ingl√©s: *odds ratio*) que sirve para hacer conclusiones interesantes.

:::

## Tabla de contingencia $2 \times 2$ {visibility="uncounted"}

![](images/cont2.png){fig-align="center" width="649" height="260"}

::: incremental
-   La variable B (o respuesta) contendr√° como posibles resultados "√©xito" o "fracaso".

-   La variable A (o explanatoria) posee las clases que identifican los grupos cuya probabilidad es sujeto de comparaci√≥n.
:::

::: footer
[Modificado de Milo≈° Gejdo≈°, *et al.* (2019) *Int. J. Environ. Res. Public Health* **16**(1)](https://www.mdpi.com/1660-4601/16/1/141){target="_blank"}
:::


## Cociente de probabilidad para tablas de contingencia $2 \times 2$

::: incremental
-   El cociente de probabilidad mide la magnitud de asociaci√≥n entre dos variables categ√≥ricas cuando estas tienen dos clases (categor√≠as).

-   En una tabla de contingencia $2 \times 2$, el cociente de probabilidad (OR) se define como:
:::

. . .

$$ OR=\frac{n_{11}/n_{12}}{n_{21}/n_{22}} $$

## Cociente de probabilidad para tablas de contingencia $2 \times 2$ {visibility="uncounted"}

::: incremental
-   La interpretaci√≥n del OR depende de la magnitud del mismo:

    -   Igual a 1, los eventos (clase de la variable explanatoria) son independientes de la variable de respuesta.

    -   Mayor o menor a 1, existe una relaci√≥n positiva o negativa de la variable explanatoria con la variable de respuesta.

    -   La magnitud de OR depende de la clase tomada como referencia en el an√°lisis.
    
    -   Los coecientes de probabilidad son m√°s f√°ciles de interpretar cuando son $\ge$ 1
:::

## Cociente de probabilidad en R {auto-animate="true"}

. . .

Usaremos para este ejemplo los datos del Titanic. La pregunta de investigaci√≥n es: ¬øtuvieron las mujeres mayores chances de salvarse durante el hundimiento del Titanic?

. . .

1.  Cargamos en nuestro ambiente la tabla de datos (librer√≠a `datarium`)

```{r echo=T, eval=T, error=T}
data(titanic.raw)
```

. . .

2.  Definimos las clases de referencia

```{r echo=F, eval=F, error=T}
head(titanic.raw, 4)
```

```{r echo=T, eval=T, error=T}
titanic.raw$Survived <- relevel(titanic.raw$Survived, ref = "Yes")
titanic.raw$Sex <- relevel(titanic.raw$Sex, ref = "Female")
```

## Cociente de probabilidad en R {.smaller visibility="uncounted"}

::: columns
::: {.column .fragment width="55%"}
3.  Creamos la tabla de contingencia

```{r echo=T, eval=T, error=T}
tabla_cont <- table(titanic.raw$Sex, titanic.raw$Survived)
```
:::

::: {.column .fragment width="45%"}
<br>

```{r echo=T, eval=T, error=T}
tabla_cont
```
:::
:::

. . .

::: columns
::: {.column .fragment width="55%"}
4.  Calculamos el OR

```{r echo=T, eval=T, error=T}
oddratio <- fisher.test(tabla_cont)
```
:::

::: {.column .fragment width="45%"}
<br>

```{r echo=T, eval=T, error=T}
oddratio 
```
:::
:::

## ¬øC√≥mo interpretamos estos resultados? {.smaller}

::: columns
::: {.column width="45%"}
<br>

```{r echo=T, eval=T, error=T}
oddratio
```
:::

::: {.column width="55%"}
::: incremental
-   Vemos que el cociente de probabilidad (OR) es 10. La interpretaci√≥n es: durante el hundimiento del Titanic fue 10 veces m√°s probable que un pasajero se salve si este era mujer.

-   Adicionalmente, del valor p de la prueba estad√≠stica exacta de Fisher menor al 0.05, se puede concluir que este cociente de probabilidad es significativo. En otras palabras, existe evidencia estad√≠stica significativa para afirmar que las probabilidades de sobrevivir durante el hundimiento del Titanic fueron 10 veces m√°s para pasajeras mujeres en comparaci√≥n a los hombres.
:::
:::
:::

# An√°lisis de Varianza (ANOVA)

## Introducci√≥n

::: incremental
-   Hasta el momento nos hemos enfocado a los casos donde comparamos las medias entre dos grupos.

-   Pero es m√°s com√∫n el evaluar distintos tratamientos al mismo tiempo, como ya vimos en el m√≥dulo 2 del curso.

-   Para ello, contamos con el ANOVA, desarrollado por el estad√≠stico Ronald Fisher a inicios del siglo 20, y que sin duda es el m√©todo estad√≠stico m√°s usado hoy en d√≠a.

-   Su nombre puede ser confuso. [El objetivo de un ANOVA es el de determinar la existencia de diferencias entre las medias aritm√©ticas de las muestras representativas de $n$ poblaciones (o en t√©rminos m√°s precisos, tratamientos).]{.fragment}
:::

## Supuestos del ANOVA {.smaller}

::: incremental
1.  Independencia de los datos: conseguida mediante una correcta randomizaci√≥n y definici√≥n del experimento.

2.  Homogeneidad de las varianzas: la varianza entre los tratamientos es la misma.

3.  **Normalidad**: [pero, ¬øde qu√© exactamente?]{.fragment}

-   Siempre ha existido una confusi√≥n de este supuesto. C√≥mo vimos antes, la normalidad es un requisito para conducir pruebas t, y lo es tambi√©n para el ANOVA.

-   Muchos libros de texto y otros recursos, mencionan que los datos de cada tratamiento deben ser normalmente distribuidos para llevar a cabo un ANOVA. [Esto es cierto e impr√°ctico a la vez.]{.fragment}

-   Mencionamos que como m√≠nimo deber√≠amos contar con 3 repeticiones por tratamiento. [Pero, ¬øson 3 repeticiones suficientes para alcanzar la normalidad?]{.fragment}

-   Es com√∫n el sugerir el llevar a cabo una prueba de normalidad antes de un ANOVA, pero esto tiene varios problemas que supongo no te han dicho antes:

    -   Cada tratamiento tiene su propia media, en caso de medias muy distantes entre s√≠, la prueba puede fallar.

    -   En su lugar, podr√≠as correr una prueba por cada tratamiento. Esto solo funciona con un considerable n√∫mero de observaciones/tratamiento (3 no son suficientes).
:::

## Supuestos del ANOVA {.smaller visibility="uncounted"}

::: incremental
-   Esta confusi√≥n nos puede llevar a soluciones err√≥neas como transformar datos, borrar outliers o utilizar pruebas no param√©tricas innecesariamente.

-   Entonces, ¬ø**normalidad** de qu√©?

-   De los residuos estandarizados!... [¬øQu√© es un residual?]{.fragment}
    
    -   Un residual es la diferencia entre una observaci√≥n y su predicci√≥n
    
    -   Un residual estandarizado resulta de la divisi√≥n del residual para la ra√≠z cuadrada de la predicci√≥n
    
    -   La distribuci√≥n muestral de los residuos estandarizados tiene media 0 y desviaci√≥n est√°ndar 1

-   Y es sobre esta distribuci√≥n que los valores cr√≠ticos del ANOVA (valores F) son calculados. Es decir, estos no dependen enteramente de los datos originales, por lo tanto los datos originales no tienen que ser necesariamente normalmente distribuidos.

-   Pero, ¬øpor qu√© la confusi√≥n? [Solo cuando el n√∫mero de observaciones es lo suficientemente grande (y ya sabemos que distribuci√≥n tiene la media muestral cuando el n√∫mero incrementa), se tiene la certeza que los residuos ser√°n normalmente distribuidos.]{.fragment}

-   En resumen, es mejor chequear la normalidad despu√©s que realizamos el ANOVA.

:::

## El dataset de recursos por depredaci√≥n

![](images/frog.jpg){fig-align="center"}

::: footer
Imagen tomada por [David Mark](https://pixabay.com/users/12019-12019/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=69813){target="_blank"} de [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=69813){target="_blank"}
:::

## El dataset de recursos por depredaci√≥n {.smaller visibility="uncounted"}

::: incremental
-   Los datos que usaremos en esta y otras secciones corresponden a un experimento del [Prof. Justin C. Touchon](https://www.jstor.org/stable/23436298){target="_blank"} acerca de la interacci√≥n entre predadores y recursos.

-   El experimento consisti√≥ de m√∫ltiples tanques (mesocosmos) dispuestos al aire libre en Gamboa, Panam√°. Los investigadores ten√≠an por objetivo el saber como la variaci√≥n en la incubaci√≥n de huevos de la rana arb√≥rea de ojos rojos podr√≠a afectar su desarrollo hasta la metamorfosis bajo varias combinaciones de recursos y predadores.

-   Los tratamientos fueron los siguientes:

    -   Edad de incubaci√≥n: Temprana (`E`: 4 d√≠as despu√©s de la oviposici√≥n) o tard√≠a (`L`: 6 d√≠as despu√©s de la oviposici√≥n).

    -   Predadores: control (`C`), no letal (`NL`: larvas de lib√©lula enjauladas) y letal (`L`: larvas de lib√©lula libres)

    -   Recursos: bajo (`Lo`: 0.75 g) o alto (`Hi`: 1.5 g) de comida suministrados cada 5 d√≠as.

-   Los mesocosmos fueron colocados en 8 bloques de 12 tanques cada uno.

-   El experimento inici√≥ con 50 renacuajos por tanque y termin√≥ cuando todos los renacuajos alcanzaron la metamorfosis, o murieron.
:::

## El dataset de recursos por depredaci√≥n {.smaller visibility="uncounted"}

::: incremental
-   Variables de respuesta:

    -   Edad de metaformosis contada desde el d√≠a de oviposici√≥n (`Age.DPO`).

    -   Edad de salida del agua (`Age.FromEmergence`)

    -   Longitud nariz-cloaca al emerger (`SVL.initial`)

    -   Longitud de la cola al emerger (`Tail.initial`)

    -   Longitud nariz-cloaca al t√©rmino de la reabsorci√≥n de la cola (`SVL.final`)

    -   Peso al t√©rmino de la reabsorci√≥n de la cola (`Mass.final`)

    -   N√∫mero de d√≠as requeridos por cada metamorfo para reabsorber completamente la cola (`Resorb.days`)

-   18 tanques conteniendo predadores no letales fueron descartados debido al brote de una enfermedad

-   **NOTA:** el dataset original de Touchon contiene alrededor de 2500 observaciones. Sin embargo, para poder usar los datos bajo los supuestos del ANOVA es necesario reducirlos a las medias aritm√©ticas de cada tratamiento por cuanto se tratan de pseudo repeticiones. Esta reducci√≥n ya est√° hecha en el archivo "touchon.csv" disponible con el [resto de materiales extras del curso.](https://mmorenozam.github.io/est-apl-uce-2023-website/materiales.html){target="_blank"}
:::


## Explorando este dataset

::: incremental

-   Haremos una exploraci√≥n b√°sica del dataset anteriormente descrito: gr√°ficos de caja y bigote, de barras, de densidad y matrices de dispersi√≥n.

-   Como estos datos han sido pre-procesados, omitiremos el mapa de observaciones perdidas.

-   Para esto, aprovecho la oportunidad para introducir otro par de librer√≠as √∫tiles

-   Como vimos anteriormente, `ggplot2` es una poderosa librer√≠a de visualizaci√≥n de datos cuyo uso es relativamente sencillo. Sin embargo, su dominio requiere un poco de tiempo y paciencia. Para quienes quiz√° deseen una manera m√°s r√°pida de realizar sus gr√°ficos y solamente tomarse el tiempo en a√±adir detalles finales, usaremos `ggpubr`.

:::

## Medias aritm√©ticas observadas

```{r echo=T, eval=T, error=T, fig.align = 'center'}
# usaremos nuevamente la librer√≠a `tidycomm` para los estad√≠sticos descriptivos
ranas <- read.csv("touchon.csv")
describe(ranas)
```

## Gr√°ficos de barras {.scrollable}

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
library(ggpubr)
ggbarplot(data = ranas,
          x = "Pred",
          y = "Age.FromEmergence",
          add = "mean_se",
          fill = "Pred")

ggbarplot(data = ranas,
          x = "Res",
          y = "Age.FromEmergence",
          add = "mean_se",
          fill = "Pred")
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=6}
library(ggpubr)
ggbarplot(data = ranas,
          x = "Pred",
          y = "Age.FromEmergence",
          add = "mean_se",
          fill = "Pred")

ggbarplot(data = ranas,
          x = "Res",
          y = "Age.FromEmergence",
          add = "mean_se",
          fill = "Res")
```
:::

## Gr√°ficos de barras {visibility="uncounted" .scrollable}

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
p1 <- ggbarplot(data = ranas,
                x = "Pred",
                y = "Age.FromEmergence",
                add = "mean_se",
                fill = "Pred")

p1 + labs(title = "Gr√°fico de barras de edad desde oviposici√≥n",
       subtitle = "Datos del estudio de Prof. Touchon",
       caption = "Gr√°fica propia",
       x = "Predadores",
       y = "Edad desde oviposici√≥n",
       color = "Predador")
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=6}
p1 <- ggbarplot(data = ranas,
                x = "Pred",
                y = "Age.FromEmergence",
                add = "mean_se",
                fill = "Pred")

p1 + labs(title = "Gr√°fico de barras de edad desde oviposici√≥n",
       subtitle = "Datos del estudio de Prof. Touchon",
       caption = "Gr√°fica propia",
       x = "Predadores",
       y = "Edad desde oviposici√≥n (d)",
       fill = "Predador")
```
:::

## Gr√°ficos de caja y bigote {.scrollable}

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
ggboxplot(data = ranas,
          x = "Pred",
          y = "Age.FromEmergence",
          fill = "Pred")

ggboxplot(data = ranas,
          x = "Res",
          y = "Age.FromEmergence",
          fill = "Res")
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=6}
ggboxplot(data = ranas,
          x = "Pred",
          y = "Age.FromEmergence",
          fill = "Pred")

ggboxplot(data = ranas,
          x = "Res",
          y = "Age.FromEmergence",
          fill = "Res")
```
:::

## Gr√°ficos de densidad {.scrollable}

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
ggdensity(data = ranas,
          x = "Age.FromEmergence", 
          add = "mean", 
          rug = "true", 
          color = "Pred", 
          fill = "Pred")

ggdensity(data = ranas,
          x = "Age.FromEmergence", 
          add = "mean", 
          rug = "true", 
          color = "Res", 
          fill = "Res")
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=6}
ggdensity(data = ranas,
          x = "Age.FromEmergence", 
          add = "mean", 
          rug = "true", 
          color = "Pred", 
          fill = "Pred")

ggdensity(data = ranas,
          x = "Age.FromEmergence", 
          add = "mean", 
          rug = "true", 
          color = "Res", 
          fill = "Res")
```
:::

## Matriz de dispersi√≥n {.scrollable}

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
library(GGally)
ranas_matriz <- ranas[,c(6:12)]
ggpairs(ranas_matriz)
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center'}
library(GGally)
ranas_matriz <- ranas[,c(6:12)]
ggpairs(ranas_matriz)
```
:::



## ANOVA de una v√≠a {.smaller}

::: incremental
-   ANOVA de una v√≠a se refiere cuando tenemos m√°s de dos tratamientos que est√°n definidos por un solo factor a la vez.

-   Usando los datos del Prof. Touchon, vamos a ilustrar el caso del ANOVA de una v√≠a. Para ello, vamos a considerar lo siguiente

    -   Supongamos que estamos interesados en saber si existe alguna diferencia entre la edad de salida del agua `Age.FromEmergence` determinada por los predadores:

    -   Los niveles del factor predadores son:

        -   Predadores no letales `NL`

        -   Predadores letales `L`

        -   Control (sin predadores) `C`

-   La $H_0$ en todo ANOVA es simplemente que no existe diferencia entre $n$ tratamientos, y la $H_a$ es que al menos uno de los tratamientos tiene una media distinta.
:::

## ANOVA en R

::: incremental
-   Existen dos formas de llevar a cabo ANOVA en R:

    1.  Crear un modelo lineal con la funci√≥n `lm` y luego el ANOVA con la funci√≥n `anova` sobre el objeto producto de `lm`.

    2.  Aplicar directamente la funci√≥n `aov` sobre nuestros datos.

-   Ambas funciones (`lm` y `aov`) tienen la misma sintaxis. [Personalmente prefiero la primera opci√≥n.]{.fragment}

-   Adicionalmente, la librer√≠a `car` ofrece la funci√≥n `Anova`. El resultado de ambas es pr√°cticamente el mismo para la mayor√≠a de modelos. [Sin embargo, personalmente prefiero `Anova` ya que permite realizar correcciones cuando tenemos datos no balanceados.]{.fragment}
:::

## ANOVA de una v√≠a en R

::: columns
::: {.column .fragment width="50%"}
Opci√≥n 1

```{r echo=T, eval=F, error=T, fig.align = 'center'}
#| code-line-numbers: "1|2|3|4"
library(car)
lm1 <- lm(Age.FromEmergence ~ Pred, data = ranas)
Anova(lm1)
```
:::

::: {.column .fragment width="50%"}
Opci√≥n 2

```{r echo=T, eval=F, error=T, fig.align = 'center'}
#| code-line-numbers: "1|2|3"
anova1 <- aov(Age.FromEmergence ~ Pred, data = ranas)
summary(anova1)
```
:::
:::

::: columns
::: {.column .fragment width="50%"}
```{r echo=F, eval=T, error=T, fig.align = 'center'}
library(car)
lm1 <- lm(Age.FromEmergence ~ Pred, data = ranas)
Anova(lm1)
```
:::

::: {.column .fragment width="50%"}
```{r echo=F, eval=T, error=T, fig.align = 'center'}
anova1 <- aov(Age.FromEmergence ~ Pred, data = ranas)
summary(anova1)
```
:::
:::

## Diagn√≥sticos del ANOVA

::: incremental

-   Antes de conducir pruebas formales para los supuestos del ANOVA, es preciso darle un vistazo a diagn√≥sticos visuales que podemos obtener del mismo.

-   El ANOVA es un caso de regresi√≥n lineal (con predictores categ√≥ricos), por lo que en esta secci√≥n nos centraremos en la interpretaci√≥n de estos diagn√≥sticos desde la perspectiva del ANOVA.

-   En el apartado de regresi√≥n lineal volveremos a profundizar en las interpretaciones de los mismos para ese caso determinado.

-   Para acceder a estos diagn√≥sticos, basta usar la funci√≥n `plot` sobre el objeto donde guardamos los resultados del modelo `lm1`.

:::

## Diagn√≥sticos del ANOVA {visibility="uncounted"}

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=5}
lm1 <- lm(Age.FromEmergence ~ Pred, data = ranas)
par(mfrow = c(2, 2))
plot(lm1)
par(mfrow = c(1, 1))
```

## Diagn√≥sticos del ANOVA {visibility="uncounted"}

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.width=6}
par(mfrow = c(2, 2))
plot(lm1)
par(mfrow = c(1, 1))
```

## Diagn√≥sticos del ANOVA {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm1, 1)
```
:::

::: {.column .fragment width="60%"}

**Residuos vs. Valores ajustados**

En este plot podemos evidenciar departuras del supuesto de la homocedasticidad. Idealmente, la l√≠nea roja que se muestra deber√≠a ir a lo largo de la horizontal en la coordenada cero del eje y (sobre la l√≠nea entrecortada).
:::
:::

## Diagn√≥sticos del ANOVA {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm1, 2)
```
:::

::: {.column .fragment width="60%"}
**Gr√°fico Q-Q**

A diferencia del gr√°fico Q-Q que vimos para las pruebas t, en el eje y de este mismo gr√°fico para el ANOVA (y regresi√≥n lineal) se representan los residuos estandarizados. La interpretaci√≥n es la misma: idealmente los puntos deber√≠an ir a lo largo de la diagonal. Cuando no es as√≠, evidencia una violaci√≥n del supuesto de la normalidad.
:::
:::

## Diagn√≥sticos del ANOVA {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm1, 3)
```
:::

::: {.column .fragment width="60%"}
**Ra√≠z cuadrada de los residuos estandarizados vs. Valores ajustados**

Similar al primer diagn√≥stico, en el caso del ANOVA, nos da una idea de posibles departuras de la homogeneidad de las varianzas. La l√≠nea roja idealmente deber√≠a ser completamente recta.

:::
:::

## Diagn√≥sticos del ANOVA {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm1, 5)
```
:::

::: {.column .fragment width="60%"}
**Residuos vs. Apalancamiento**

Aquellos puntos que est√©n etiquetados con n√∫meros son mostrados como posibles outliers bajo dos criterios:

-   Est√°n por fuera de los l√≠mites de la regla del rango intercuart√≠lico (IQR), y

-   Marcados como outliers con influencia de apalancamiento mediante la prueba de Cook (distancia de Cook).

El segundo criterio es un argumento s√≥lido para remover outliers.

:::
:::


## Transformaciones

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=6}
lm2 <- lm(log(Age.FromEmergence) ~ Pred, data = ranas)
par(mfrow = c(2, 2))
plot(lm2)
par(mfrow = c(1, 1))
```

## Transformaciones {visibility="uncounted"}

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.width=6}
lm2 <- lm(log(Age.FromEmergence) ~ Pred, data = ranas)
par(mfrow = c(2, 2))
plot(lm2)
par(mfrow = c(1, 1))
```


## Prueba formal de normalidad

::: incremental
-   Como vimos, despu√©s de aplicar la transformaci√≥n logar√≠tmica el gr√°fico Q-Q mejor√≥ considerablemente.

-   Para estar seguros, podemos correr un test formal sobre los residuos del modelo con la ayuda de la librer√≠a `olsrr` mediante su funci√≥n `ols_test_normality`.
:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
library(olsrr)
ols_test_normality(lm2)
```

## Prueba formal de normalidad {visibility="uncounted"}

::: incremental
-   O tambi√©n podemos calcular la prueba de Shapiro-Wilk con funciones base de R
:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
residuos <- resid(lm2)
shapiro.test(residuos)
```

## Homogeneidad de las varianzas en ANOVA

::: incremental
-   La prueba m√°s usada para chequear la homogeneidad de varianzas de un ANOVA es la de Levene.

-   Para ello utilizaremos la funci√≥n `leveneTest` de la librer√≠a `car`. Podemos usar esta funci√≥n directamente sobre los datos con la misma sintaxis de `lm`, o sobre el objeto `lm2` en el que anteriormente almacenamos el resultado del modelo lineal con la transformaci√≥n.
:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
leveneTest(lm2, center = "mean")
```

## ANOVA de una v√≠a en R (continuaci√≥n)

::: incremental
-   As√≠, una vez que hemos transformado para obtener normalidad en los residuos y chequeado la homogeneidad de varianzas, es tiempo de hecharle un vistazo al resultado del ANOVA:
:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
Anova(lm2)
```

. . .

-   Por tanto, podemos concluir que al menos uno de los tratamientos es distinto (aceptamos la $H_a$ y rechazamos la $H_0$)

## ¬øQu√© tan distintos? {.smaller}

::: incremental
-   Preguntas naturales seguidas de estos resultados son: ¬øqu√© tan distintos son los tratamientos entre s√≠?, ¬øpuedo acaso ordernarlos de mayor a menor?, ¬øexisten pares de tratamientos que son iguales?

-   Podemos comenzar con una ayuda visual (ligeramente distinto a nuestro AED, usando la transformaci√≥n logar√≠tmica)
:::

. . .

::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
# usamos ggpubr nuevamente
ranas$log.Age.FromEmergence <- log(ranas$Age.FromEmergence)
ggboxplot(ranas,
          x = "Pred",
          y = "log.Age.FromEmergence",
          add = "jitter",
          color = "Pred")
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=4}
ranas$log.Age.FromEmergence <- log(ranas$Age.FromEmergence)
ggboxplot(ranas,
          x = "Pred",
          y = "log.Age.FromEmergence",
          add = "jitter",
          color = "Pred")
```
:::

## Comparaciones m√∫ltiples {.smaller}

::: incremental
-   Los m√©todos de comparaciones m√∫ltiples y gr√°ficos de interacci√≥n nos ayudan a responder estas preguntas.

-   En el caso de los gr√°ficos de interacci√≥n para ANOVA de una v√≠a, no tiene mucho sentido llevarlos a cabo ya que son m√°s √∫tiles para ANOVA de m√∫ltiples v√≠as, as√≠ que los dejaremos para despu√©s.

-   Las comparaciones m√∫ltiples m√°s usadas son:

    -   HSD Tukey (*Honestly significant difference*): lleva a cabo todos los pares de comparaciones posibles entre los niveles de un factor.

    -   Prueba de Dunnett: Compara los niveles √∫nicamente con respecto al nivel control dentro del factor.

-   Son conocidas tambi√©n como pruebas *post-hoc*.

-   En R, una manera de realizar comparaciones m√∫ltiples es mediante las librer√≠as `emmeans` y `multcomp` (esta √∫ltima depende de `multcompView`, as√≠ que no olvides instalarla tambi√©n).
:::

## HSD Tukey {.smaller}

. . .

Calculamos las medias marginales a partir del modelo

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=6}
#| code-line-numbers: "1|2|3"
library(emmeans)
ph1 <- emmeans(lm2, specs = "Pred", type = "response")
summary(ph1)
```



## HSD Tukey {.smaller autoanimate="true"}


Calculamos las medias marginales a partir del modelo

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
library(emmeans)
ph1 <- emmeans(lm2, specs = "Pred", type = "response")
summary(ph1)
```

. . .

-   Ahora podemos calcular las comparaciones por pares de HSD Tukey

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
tukey_comp <- contrast(ph1, specs = "Pred", method = "tukey")
tukey_comp
```

## Prueba de Dunnett {.smaller .scrollable}

. . .

-   Para Dunnett, es importante el establecer el grupo control

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
dunnett_comp <- contrast(ph1, specs = "Pred", method = "dunnett", ref = "C")
dunnett_comp
```

. . .

-   Finalmente, otra tabla de resumen de las comparaciones m√∫ltiples es la de agrupar las medias aritm√©ticas marginales con n√∫meros (o letras) de acuerdo a si estas son estad√≠sticamente distintas o no entre si. Para ello podemos usar la librer√≠a `multcomp`:

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
# multcomp necesita una librer√≠a extra llamada multcompView
# No olvides instalar multcompView antes de correr este c√≥digo
library(multcomp)
medias_marginales <- cld(ph1)
medias_marginales
```

## Antes de continuar {.smaller}

::: incremental

-   En este punto, antes de continuar hagamos uso nuevamente de la librer√≠a `flextable` para exportar nuestras tablas a Word.

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
library(flextable)
tabla_tukey <- colformat_double(flextable(as.data.frame(tukey_comp)), digits = 3, j = c(2, 3, 6, 7))
tabla_dunnett <- colformat_double(flextable(as.data.frame(dunnett_comp)), digits = 3, j = c(2, 3, 6, 7))
tabla_marginal <- colformat_double(flextable(medias_marginales), digits = 3, j = c(2, 3, 5, 6))
```

. . .

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.width=6}
tabla_tukey 
tabla_dunnett
tabla_marginal
```

## Antes de continuar {visibility="uncounted" .smaller}

. . .

-   La tabla del ANOVA requiere un poquito m√°s de preparaci√≥n y para ello nos ayudaremos de la librer√≠a `rstatix` para agregar los asteriscos de significancia.

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=6}
#| code-line-numbers: "1|2|3|4-8|9-10"
library(rstatix)
tabla_anova <- as.data.frame(Anova(lm2))
tabla_anova <- cbind(parametro = row.names(tabla_anova), tabla_anova)
tabla_anova <- add_significance(tabla_anova, 
                 p.col = "Pr(>F)", 
                 output.col = " ",
                 cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                 symbols = c("***", "**", "*", ".", "ns"))
tabla_anova <- colformat_double(flextable(tabla_anova), digits = 3, j = c(2, 4, 5))
tabla_anova <- add_footer_lines(tabla_anova, "C√≥digos Signif. 0 '***', 0.001 '**', 0.1 '*', 0.05 '.', 0.1 'ns'")
```

## Antes de continuar {visibility="uncounted" .smaller}

-   La tabla del ANOVA requiere un poquito m√°s de preparaci√≥n y para ello nos ayudaremos de la librer√≠a `rstatix` para agregar los c√≥digos de significancia.

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
library(rstatix)
tabla_anova <- as.data.frame(Anova(lm2))
tabla_anova <- cbind(parametro = row.names(tabla_anova), tabla_anova)
tabla_anova <- add_significance(tabla_anova, 
                 p.col = "Pr(>F)", 
                 output.col = " ",
                 cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                 symbols = c("***", "**", "*", ".", "ns"))
tabla_anova <- colformat_double(flextable(tabla_anova), digits = 3, j = c(2, 4, 5))
tabla_anova <- add_footer_lines(tabla_anova, "C√≥digos Signif. 0 '***', 0.001 '**', 0.1 '*', 0.05 '.', 0.1 'ns'")
tabla_anova
```


## Antes de continuar {visibility="uncounted"}

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=6}
save_as_docx("Tabla Anova" = tabla_anova, "Tabla Tukey" = tabla_tukey, "Tabla Dunnett" = tabla_dunnett,
             "Tabla Medias Marginales Esperadas" = tabla_marginal,
             path = "C:/Users/mmore/Documents/cursos_uce_2023/modulos/uce2023-modulo4/anova.docx")
```

![](images/anova_tabla.png){fig-align="center"}


## Gr√°ficos de comparaciones m√∫ltiples {.smaller}

::: incremental

-   Hay personas que prefieren tener representaciones visuales de las comparaciones m√∫ltiples.

-   Realizar este tipo de gr√°ficos sin embargo sol√≠a demandar buena experiencia ya sea en gr√°ficos base o `ggplot2`.

-   Afortunadamente, `rstatix` nos brinda la posibilidad de llevarlos a cabo de una manera relativamente sencilla.

-   La idea es generar un gr√°fico con las medias marginales observadas de la variable de inter√©s y posicionar sobre este los resultados de las comparaciones m√∫ltiples con sus c√≥digos de significancia (o valores p).

-   Las desventajas de esta visualizaci√≥n son:

    -   Tienen mayor sentido realizarlas con HSD Tukey
    
    -   Cuando el n√∫mero de pares de comparaciones es muy grande, el gr√°fico se vuelve m√°s dif√≠cil de interpretar que las tablas.
    
    -   `rstatix` no tiene manera de directamente volver a retransformar variables a sus unidades originales.

-   Otro gr√°fico de cierta popularidad es el de los grupos de Tukey de las medias marginales (gr√°ficos de barras con los n√∫meros/letras sobre cada categor√≠a). Para esto utilizaremos adem√°s la librer√≠a `stringr`
:::

## Gr√°ficos de comparaciones m√∫ltiples {.smaller visibility="uncounted"}


::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
#| code-line-numbers: "1|2-4|5-7|8-12|13|14"
ranas$Pred <- factor(ranas$Pred, levels = c("C", "NL", "L"))
bxplot <- ggboxplot(ranas, x = "Pred", 
                    y = "Age.FromEmergence", 
                    color = "Pred")
hsdvals <- emmeans_test(log.Age.FromEmergence ~ Pred, 
                        data = ranas, 
                        p.adjust.method = "mvt")
hsdvals <- add_significance(hsdvals, 
                            p.col = "p.adj", 
                            output.col = "p.adj.signif",
                            cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                            symbols = c("***", "**", "*", ".", "ns"))
hsdvals <- hsdvals %>% add_xy_position(x = "Pred")
bxplot + stat_pvalue_manual(hsdvals, y.position = c(120, 130, 140))
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=5}
ranas$Pred <- factor(ranas$Pred, levels = c("C", "NL", "L"))
bxplot <- ggboxplot(ranas, x = "Pred", y = "Age.FromEmergence", color = "Pred")
hsdvals <- emmeans_test(log.Age.FromEmergence ~ Pred, data = ranas, p.adjust.method = "mvt")
hsdvals <- add_significance(hsdvals, 
                                p.col = "p.adj", 
                                output.col = "p.adj.signif",
                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                                symbols = c("***", "**", "*", ".", "ns"))
hsdvals <- hsdvals %>% add_xy_position(x = "Pred")

bxplot + stat_pvalue_manual(hsdvals, y.position = c(120, 130, 140))
```
:::


## Gr√°ficos de comparaciones m√∫ltiples {.smaller visibility="uncounted"}


::: panel-tabset
### C√≥digo

```{r echo=T, eval=F, error=T, fig.align = 'center'}
#| code-line-numbers: "1|2|3|4-7|8-10|11-13|14-15"
library(stringr)
gruposvals <- as.data.frame(cld(ph1))
gruposvals$Pred <- factor(gruposvals$Pred, levels = c("C", "NL", "L"))
ggplot(gruposvals,
       aes(x = Pred, 
           y = response, 
           fill = Pred)) +
  geom_bar(stat = "identity", 
           show.legend = F, 
           color = "black")+
  geom_errorbar(aes(ymin = response - SE, 
                    ymax = response + SE), 
                width=0.2)+
  geom_text(aes(label=str_trim(.group), 
                y = response+SE, vjust=-0.5))
```

### Gr√°fico

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.height=5}
library(stringr)
gruposvals <- as.data.frame(cld(ph1))
gruposvals$Pred <- factor(gruposvals$Pred, levels = c("C", "NL", "L"))
ggplot(gruposvals,
       aes(x = Pred, y = response, fill = Pred))+
  geom_bar(stat = "identity", show.legend = F, color = "black")+
  geom_errorbar(aes(ymin = response - SE, ymax = response + SE), width=0.2)+
  geom_text(aes(label=str_trim(.group), y = response+SE, vjust=-0.5))
```
:::

## ANOVA de un dise√±o desbalanceado {.smaller}

::: incremental
-   Recordemos que 18 tanques con predadores no letales fueron descartados debido al brote de una enfermedad.

-   El dise√±o original de Touchon era balanceado. Al perderse unidades experimentales, el dise√±o se le puede denominar como desbalanceado. En otras palabras, el desbalance es la p√©rdida de observaciones.

-   La mayor√≠a de m√©todos estad√≠sticos requieren ser corregidos ante observaciones perdidas para poder tener la certeza de que los estimados que obtenemos no sean sesgados.

-   Sin adentrarnos en mayor detalle, uno de los componentes de la tabla de ANOVA es la suma de cuadrados. Existen tres tipos de suma de cuadrados: I, II y III.

-   En breve, las sumas II y III se aconseja sean usadas cuando existen interacciones en el ANOVA.

-   En R, la funci√≥n `aov` calcula la suma de cuadrados tipo I. Este tipo de suma no es conveniente ante la presencia de desbalance de los datos.

-   En cambio, la funci√≥n `Anova` de la librer√≠a `car`, usa por default el tipo II que es precisamente el recomendado usar ante la presencia de desbalance.

-   En resumen, s√≠. Hemos utilizado hasta el momento la correcci√≥n adecuada para estos datos.
:::

## Ejercicio 4.9

-   Lleva a cabo un ANOVA con todos sus pasos para la variable `Resorb.days` de los datos de Touchon

## Prueba de Kruskal-Wallis {.smaller}

::: incremental

-   La prueba de Kruskal-Wallis es la alternativa no param√©trica al ANOVA de una v√≠a.

-   Puede extenderse al ANOVA de m√∫ltiples v√≠as reorganizando el dise√±o experimental.

-   Similar a las pruebas de Wilcoxon, se basa en encontrar diferencias de las medianas en lugar de las medias y su poder ese menor.

-   Para ilustrar este ejemplo, tomemos la variable `Age.DPO` del estudio de Touchon y veamos si existen diferencias con respecto al tratamiento de predador `Pred`. `Age.DPO` sin transformaciones no cumple con los supuestos del ANOVA.

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
kruskal.test(Age.DPO ~ Pred, data = ranas)
```

## Comparaciones m√∫ltiples con Kruskal-Wallis {.smaller}

::: incremental

-   Con KW tambi√©n podemos hacer comparaciones m√∫ltiples.

-   En R base contamos con la funci√≥n `pairwise.wilcox.test` que lleva a cabo comparaciones por pares mediante el m√©todo de Wilcoxon.

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
pairwise.wilcox.test(ranas$Age.DPO, ranas$Pred, p.adjust.method = "BH")
```

## Ejercicio 4.10

-   Encuentra si existen diferencias en la longitud nariz-cloaca al emerger (`SVL.initial`) con respecto a los predadores `Pred` en los datos de Touchon. ¬øQu√© m√©todo es factible usar?, ¬øANOVA de una v√≠a o Kruskal-Wallis?

## Antes de continuar {.smaller}

::: incremental

-   Con respecto a los DDE que vimos en el m√≥dulo 2, el ANOVA de una v√≠a corresponde directamente al an√°lisis que llevar√≠amos a cabo para un DCA.

-   Para extender el modelo a un DBCA de una v√≠a basta el incorporar otro efecto principal en el modelo:

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
lm3 <- lm(log(Age.FromEmergence) ~ Pred + as.factor(Block), data = ranas)
Anova(lm3)
```

::: incremental

-   La interpretaci√≥n de este tipo de ANOVA se enfoca en el valor p de los tratamientos.

-   No tiene mucho sentido el interpretar el valor p del factor de bloque ya que est√° ah√≠ para controlar fuentes de variaci√≥n.

-   De manera similar, cuando extendamos el ANOVA a m√°s factores, el an√°lisis del DBCA factorial se consigue a√±adiendo un efecto principal para el bloque.

:::

## Antes de continuar {visibility="uncounted" .smaller}

::: incremental

-   Para las pruebas de comparaciones m√∫ltiples, seguimos el mismo procedimiento que describimos anteriormente ignorando el efecto del bloque.

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
ph_dbca <- emmeans(lm3, specs = "Pred", type = "response")
contrast(ph_dbca, specs = "Pred", method = "tukey")
```

## ANOVA de m√∫ltiples v√≠as {.smaller}

::: incremental

-   El ANOVA puede extenderse para analizar dos o m√°s factores a la vez. Su nombre entonces var√≠a dependiendo de cu√°ntos factores analicemos, as√≠: ANOVA de dos v√≠as (2 factores), ANOVA de tres v√≠as (3 factores) ...

-   En la pr√°ctica es recomendable dise√±ar experimentos hasta m√°ximo 3 factores:

    -   A m√°s factores, m√°s costosa la investigaci√≥n
    
    -   A m√°s factores, sus interacciones son m√°s dif√≠ciles de interpretar
    
    -   Es posible inclusive que tengamos resultados sin sentido (interacciones innecesarias)
    
-   ¬øQu√© son las interacciones?

    -   Una interacci√≥n se refiere cuando los niveles de un factor podr√≠an depender de los niveles de otro.
    
    -   Por ejemplo, con los datos de las ranas, podr√≠amos imaginar que en la ausencia de predadores, tener recursos altos o bajos podr√≠a influenciar el tiempo que tomaron los renacuajos en culminar la metamorfosis. Es decir, si hay predadores presentes, podr√≠a darse el caso de que las presas se escondan y coman menos influenciando as√≠ ese tiempo.
    
    -   As√≠, podr√≠amos saber si el effecto de los recursos son influenciados ante la presencia de predadores

:::

## ANOVA de m√∫ltiples v√≠as en R {.smaller .scrollable}

::: incremental

-   Vamos a usar nuevamente los datos de Touchon, la variable de respuesta es la edad de metamorfosis `Age.DPO` y los factores la presencia de predadores `Pred` y los recursos `Res`.

-   Para un ANOVA de m√∫ltiples v√≠as en R podemos usar la siguiente sintaxis: `Factor1*Factor2`

-   Para ahorrarnos tiempo, sup√≥ngamos que ya corrimos un primer ANOVA, y encontramos que usando el logaritmo de `Age.DPO` podemos normalizar los residuos. [Pero nos encontramos con esto:]{.fragment}
:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
lm4 <- lm(log(Age.DPO) ~ Pred*Res, data = ranas)
leveneTest(lm4, center = "mean")
```

::: incremental

-   **¬°La homogeneidad de las varianzas no se cumple!** üò±

-   ¬°Ninguna otra transformaci√≥n funciona!


:::

## ANOVA de m√∫ltiples v√≠as en R {visibility="uncounted"}

![](images/reir.jpg){fig-align="center"}

## ANOVA de m√∫ltiples v√≠as en R {visibility="uncounted" .smaller .scrollable}

::: incremental

-   A parte de reir, en este tipo de situaciones (que son bastante comunes), tenemos dos alternativas:

    1.   Realizar pruebas no param√©tricas, o
    
    2.   Calcular ANOVAs con correcciones para heterodasticidad.
    
-   Pero como acu√±√≥ el Ec. y estad√≠stico Milton Friedman: [*"No existe tal cosa como un almuerzo gratis"*](https://en.wikipedia.org/wiki/There_ain%27t_no_such_thing_as_a_free_lunch){target="_blank"}, usar la segunda opci√≥n no es tan f√°cil como hemos venido viendo.

-   En R, tenemos estos caminos (de peor a mejor opci√≥n):

    1.    Realizar el ANOVA usando la correcci√≥n de White-Huber disponible en la librer√≠a `car`, pero al costo de conducir comparaciones m√∫ltiples posiblemente sesgadas (siguiendo la l√≥gica de realizarlas con `emmeans`).
    
    2.    Utilizar `rstatix` para un ANOVA con la correcci√≥n de Welch, seguido de comparaciones m√∫ltiples con la correcci√≥n de Games-Howell y poder todav√≠a realizar sus gr√°ficos al costo de romper la secuencia de aprendizaje que hemos venido llevando para el ANOVA.
    
    3.    Utilizar las librer√≠as `nlme` para reparametrizar el modelo en forma de un modelo lineal generalizado, y posteriormente usar `car` y `emmeans` para el ANOVA y las comparaciones m√∫ltiples, respectivamente. Pero al costo de no poder graficarlas con `rstatix` sino desde 0.
    
-   A continuaci√≥n entonces iremos en este orden de las opciones: 2, 3 y 1 (la √∫ltima para ejemplificar cu√°l ser√≠a el camino suponiendo que la homocedasticidad se hubiese cumplido).

:::

## ANOVA de m√∫ltiples v√≠as en R. Opc. 2 {.smaller .scrollable}

::: incremental

-   El inconveniente de usar la correcci√≥n de Welch es que esta se puede aplicar solo a ANOVAs de una v√≠a.

-   Entonces, de manera similar a lo hicimos para poder analizar por Kruskall-Wallis un dise√±o factorial, tenemos que crear una variable dummy combinando los dos factores para correr un ANOVA de una v√≠a.

-   **Debemos tener en cuenta que** al realizar esto, reducimos poder de la prueba estad√≠stica.

:::

. . .

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=6}
ranas$log.Age.DPO <- log(ranas$Age.DPO)
ranas$tratamiento <- paste(ranas$Pred, ranas$Res, sep = "-")
anova_op2 <- ranas %>%
  welch_anova_test(log.Age.DPO ~ tratamiento)
```

## ANOVA de m√∫ltiples v√≠as en R. Opc. 2 {.smaller .scrollable visibility="uncounted"}

-   El inconveniente de usar la correcci√≥n de Welch es que esta se puede aplicar solo a ANOVAs de una v√≠a.

-   Entonces, de manera similar a lo hicimos para poder analizar por Kruskall-Wallis un dise√±o factorial, tenemos que crear una variable dummy combinando los dos factores para correr un ANOVA de una v√≠a.

-   **Debemos tener en cuenta que** al realizar esto, reducimos poder de la prueba estad√≠stica.


```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
ranas$log.Age.DPO <- log(ranas$Age.DPO)
ranas$tratamiento <- paste(ranas$Pred, ranas$Res, sep = "-")
ranas$tratamiento <- factor(ranas$tratamiento, levels = c("C-Lo", "NL-Lo", "C-Hi", "L-Lo", "NL-Hi", "L-Hi"))
anova_op2 <- ranas %>%
  welch_anova_test(log.Age.DPO ~ tratamiento)
anova_op2
```

. . .

-   Ahora podemos realizar las comparaciones de HSD Tukey (con correcci√≥n de Games-Howell)

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
games_comp <- ranas %>% games_howell_test(log.Age.DPO ~ tratamiento)
games_comp <- add_significance(games_comp, 
                                p.col = "p.adj", 
                                output.col = "p.adj.signif",
                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                                symbols = c("***", "**", "*", ".", "ns"))
games_comp
```

. . . 

-   Finalizamos con el gr√°fico de estas

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}

games_comp <- games_comp %>% 
  add_xy_position(x = "tratamiento", step.increase = 1)
ggboxplot(ranas,
          x = "tratamiento",
          y = "log.Age.DPO") + 
  stat_pvalue_manual(games_comp, 
                     hide.ns = T,
                     y.position = c(5.1,5.5,5.9,6.3,6.7,7.1))
```

## ANOVA de m√∫ltiples v√≠as en R. Opc. 3 {.smaller .scrollable}

::: incremental

-   La tercera opci√≥n involucra el reparametrizar el modelo para poder analizarlo como un modelo lineal generalizado.

-   En breve, una de las ventajas de los modelos lineales generalizados es que pueden asumir varianzas distintas a trav√©s de modelar directamente la heterodasticidad.

-   Para su implementaci√≥n usaremos la librer√≠a `nlme`

:::

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
library(nlme)
anova_op3 <- gls(log(Age.DPO) ~ Pred*Res,
                 data = ranas,
                 weights = varIdent(form = ~1|Pred*Res)) 
```

. . .

-   Mediante la librer√≠a `car` podemos obtener la tabla del ANOVA (o especificamente llamada Analisis de Desviaci√≥n)

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
Anova(anova_op3)
```

. . .

-   Ahora, usando `emmeans` podemos calcular el HSD de Tukey directamente sin necesidad de correcciones. Una consideraci√≥n importante es que, cuando tenemos dos factores debemos hacer las comparaciones de cada factor a la vez a lo largo de los niveles del otro.

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
tukey_comp_pred <- emmeans(anova_op3, specs = "Pred", by = "Res", method = "tukey") # medias marginales esperadas
contrast(tukey_comp_pred, specs = "Pred", by = "Res", method = "tukey")
```

. . .

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
tukey_comp_res <- emmeans(anova_op3, specs = "Res", by = "Pred", method = "tukey") # medias marginales esperadas
contrast(tukey_comp_res, specs = "Res", by = "Pred", method = "tukey")
```


-   Para graficar estas comparaciones mediante esta opci√≥n es necesario el empezar de cero con `ggplot2`. La raz√≥n es que `rstatix` no tiene las capacidades de lidiar con interacciones provenientes de `emmeans` (no es compatible con la sintaxis de los comandos `contrast` de arriba) por lo que dejaremos esta opci√≥n hasta aqu√≠.


## ANOVA de m√∫ltiples v√≠as en R. Opc. 1 {.smaller .scrollable}

::: incremental

-   Finalmente, asumamos que no tuvimos el problema de heterodasticidad y pudimos haber seguido el curso normal para realizar las comparaciones m√∫ltiples usando solamente `car`, `emmeans` y `multcomp`.

-   Este es el transcurso normal de t√≥picos en el aprendizaje del ANOVA de m√∫ltiples v√≠as:

:::

. . .

-   Tabla del ANOVA con `car` (mencionamos que `car` es capaz de llevar a cabo una correcci√≥n de heterodasticidad, esta se consigue agregando el argumento `white.adjust = T` dentro de la funci√≥n `Anova`)

```{r echo=T, eval=T, error=T, fig.align = 'center', fig.width=6}
Anova(lm4)
```

. . .

-   Al igual que en la opci√≥n 3, calculamos las comparaciones m√∫ltiples viendo a cada factor a la vez a lo largo de los niveles del otro.


```{r echo=T, eval=T, error=T}
tukey_comp_pred1 <- emmeans(lm4, specs = "Pred", by = "Res", type = "response")
contrast(tukey_comp_pred1, specs = "Pred", method = "tukey")
```

. . .

```{r echo=T, eval=T, error=T}
tukey_comp_res1 <- emmeans(lm4, specs = "Res", by = "Pred", type = "response")
contrast(tukey_comp_res1, specs = "Pred", method = "tukey", adjust = "holm")
```

## Antes de continuar {.smaller}

::: incremental

-   Muchas personas gustan de las tablas de grupos de Tukey para las medias marginales esperadas en dise√±os experimentales factoriales al estilo que usamos para poder conducir la opci√≥n 2 anteriormente descrita.

-   Esta pr√°ctica es innecesaria si el investigador es capaz de hacer buenas inferencias bas√°ndose en las comparaciones por factor a lo largo de los niveles del otro.

-   No tienen ning√∫n problema operacional ya que a la final es una reparametrizaci√≥n v√°lida del modelo.

-   Sin embargo, cuando el modelo sobre el cual son aplicadas es incorrecto, son m√°s susceptibles de reflejar valores p que concluyen con inferencias falaces.

-   En el largo ejemplo de las opciones a mano para lidiar con heterodasticidad, podemos con seguridad afirmar que del peor al mejor modelo su orden ser√≠a: Opci√≥n 1 < Opci√≥n 2 < Opci√≥n 3.

-   Para ilustrar esto, con la variable dummy que creamos en la opci√≥n 2, calculemos los grupos Tukey de las medias marginales esperadas en las opciones 1 y 3 para su comparaci√≥n.

:::

## Antes de continuar {.smaller visibility="uncounted" .scrollable}

. . .

-   Grupos Tukey de las medias marginales esperadas en la opci√≥n 1

```{r echo=T, eval=T, error=T}
lm_op1 <- lm(log(Age.DPO) ~ tratamiento, data = ranas)
emm_op1 <- emmeans(lm_op1, specs = "tratamiento", type = "response")
t_grupos_op1 <- contrast(emm_op1, specs = "tratamiento", method = "tukey")
t_grupos_op1 <- add_significance(as.data.frame(t_grupos_op1), 
                                p.col = "p.value", 
                                output.col = "p.adj.signif.op1",
                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                                symbols = c("***", "**", "*", ".", "ns"))
```

. . .

-   Grupos Tukey de las medias marginales esperadas en la opci√≥n 3

```{r echo=T, eval=T, error=T}
lm_op3 <- gls(log(Age.DPO) ~ tratamiento,
                 data = ranas,
                 weights = varIdent(form = ~1|tratamiento)) 
emm_op3 <- emmeans(lm_op3, specs = "tratamiento", type = "response")
t_grupos_op3 <- contrast(emm_op3, specs = "tratamiento", method = "tukey")
t_grupos_op3 <- add_significance(as.data.frame(t_grupos_op3), 
                                p.col = "p.value", 
                                output.col = "p.adj.signif.op3",
                                cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                                symbols = c("***", "**", "*", ".", "ns"))
```


. . .

-   Un poco de carpinter√≠a

```{r echo=T, eval=T, error=T}
colnames(games_comp)[c(7,8)] <- c("p.value.op2", "p.adj.signif.op2")
colnames(t_grupos_op3)[7] <- "p.value.op3"
colnames(t_grupos_op1)[7] <- "p.value.op1"

comp_table <- cbind(t_grupos_op3[,1],
                    t_grupos_op1[,c(7, 8)],
                    games_comp[,c(7, 8)],
                    t_grupos_op3[,c(7, 8)])

comp_table <- flextable(comp_table)
final_comp_table <- colformat_double(comp_table, j = c(2, 4, 6), digits = 3)
final_comp_table

```


## Gr√°ficos de interacci√≥n {.smaller}

::: incremental

-   Es una forma de representar las predicciones lineales de un modelo con respecto a los niveles de sus factores. 

-   Es recomendable usarlos con factores de hasta 3 niveles y en ANOVAS de dos factores as√≠ como tambi√©n con las medias marginales esperadas.

-   Existen diversas formas de realizarlos en R:

    -   Librer√≠a base de R (solo puede hacerlo con medias marginales observadas[... al menos hasta donde tengo conocimiento)]{.fragment}
    
    -   Construirlos desde cero con `ggplot2` (para las opciones 2 y 3).
    
    -   Usar librer√≠as accesorias de `ggplot2` como `interactions`. (Esta alternativa solo es v√°lida para la primera opci√≥n que presentamos)
:::



## Gr√°ficos de interacci√≥n en R {.scrollable}

::: columns
::: {.column .fragment width="50%"}
```{r echo=T, eval=F, error=T}
library(interactions)
graf_inter1 <- cat_plot(
  lm4,
  pred = Pred,
  modx = Res,
  geom = "line",
  data = ranas
)
graf_inter1
```
:::

::: {.column .fragment width="50%"}
```{r echo=F, eval=T, error=T}
library(interactions)
graf_inter1 <- cat_plot(
  lm4,
  pred = Pred,
  modx = Res,
  geom = "line",
  data = ranas
)
graf_inter1
```
:::
:::


::: columns
::: {.column .fragment width="50%"}
```{r echo=T, eval=F, error=T}
library(interactions)
graf_inter2 <- cat_plot(
  lm4,
  pred = Res,
  modx = Pred,
  geom = "line",
  data = ranas
)
graf_inter2
```
:::

::: {.column .fragment width="50%"}
```{r echo=F, eval=T, error=T}
library(interactions)
graf_inter2 <- cat_plot(
  lm4,
  pred = Res,
  modx = Pred,
  geom = "line",
  data = ranas
)
graf_inter2
```
:::
:::



## Ejercicios 4.11

-   Lleva a cabo un ANOVA de dos v√≠as para las variables `Resorb.days` y los factores `Pred` y `Res`. La pregunta a investigar es saber si existe una interacci√≥n entre la presencia de predadores a distintos niveles de recursos que afecte el tiempo de reabsorci√≥n de la cola en los renacuajos de ranas arb√≥reas de ojos rojos.

-   A pesar de que el modelo para `Resorb.day` que acabas de hacer cumple con los supuestos del ANOVA, solo por aprendizaje, conduce una prueba de Kruskal-Wallis usando los mismos factores.

-   ¬øC√≥mo implementar√≠as un DBCA factorial con estos datos?



# Regresi√≥n lineal

## Introducci√≥n {.smaller}

::: incremental

-   Otro modelo estad√≠stico ampliamente usado es la regresi√≥n lineal.

-   Se diferencia del ANOVA al considerar un predictor continuo (no un factor categ√≥rico).

-   Los supuestos de la regresi√≥n lineal son:

    -   Existencia de una relaci√≥n lineal entre las variables continuas objeto de la regresi√≥n
    
    -   Normalidad de los residuos
    
    -   Que no exista multicolinearidad (en el caso de regresi√≥n m√∫ltiple)
    
    -   Que no exista auto correlaci√≥n (que las observaciones no dependan una de otra dentro de una misma variable)
    
    -   Homogeneidad de la varianza de los residuos

-   Contrario al ANOVA, no existen correcciones o m√©todos alternativos cuando las transformaciones fallan.

-   Por esto, lo que se recomienda hacer es mencionar todos los detalles de la conducci√≥n del modelo. [Cosa que rara vez pasa.]{.fragment}

-   En regresi√≥n lineal es quiz√° en el m√©todo que m√°s se abusa del remover outliers. 

:::

## Regresi√≥n lineal en R {.smaller}

::: incremental

-   Usando los datos de Touchon, podr√≠amos preguntarnos si el tama√±o de las ranas al final de la metamorfosis `SVL.final` est√° influenciado por la edad en finalizar la metamorfosis `Age.DPO`.

-   Esta regresi√≥n lineal ser√≠a de la siguiente forma:

:::

. . .

```{r echo=T, eval=T, error=T}
lm6 <- lm(SVL.final ~ Age.DPO, data = ranas)
summary(lm6)
```

. . . 

- Pero antes de cualquier inferencia, vamos a darle un vistazo a los diagn√≥sticos de la regresi√≥n lineal

## Diagn√≥sticos de la regresi√≥n lineal

```{r echo=T, eval=F, error=T, fig.align = 'center', fig.width=5}
par(mfrow = c(2, 2))
plot(lm6)
par(mfrow = c(1, 1))
```

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted"}

```{r echo=F, eval=T, error=T, fig.align = 'center', fig.width=6}
par(mfrow = c(2, 2))
plot(lm6)
par(mfrow = c(1, 1))
```

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm6, 1)
```
:::

::: {.column .fragment width="60%"}

**Residuos vs. Valores ajustados**

En el ANOVA vimos como este plot suger√≠a departuras de la homocedasticidad. En el caso de la regresi√≥n lineal, los residuos al no estar agrupados en categor√≠as presentan mayor informaci√≥n sobre este supuesto. Adicionalmente, curvaturas en la l√≠nea roja evidencian tambi√©n departuras de la linearidad. Esto quiere decir que la relaci√≥n entre las variables no es completamente lineal. A veces esto puede corregirse con transformaciones.

:::
:::

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted" .smaller}

![](images/kutner.png){fig-align="center"}

(a) Es ideal. (b) Es indicativo de no linearidad. (c) Evidencia de heterodasticidad. (d) Evidencia de una tendencia temporal

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm6, 2)
```
:::

::: {.column .fragment width="60%"}
**Gr√°fico Q-Q**

Misma explicaci√≥n que antes
:::
:::

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm6, 3)
```
:::

::: {.column .fragment width="60%"}
**Ra√≠z cuadrada de los residuos estandarizados vs. Valores ajustados**

Misma explicaci√≥n que antes

:::
:::

## Diagn√≥sticos de la regresi√≥n lineal {visibility="uncounted" .smaller}

::: {.columns .v-center-container}
::: {.column .fragment width="40%"}
```{r echo=F, eval=T, error=T, fig.height=6, fig.width=6}
plot(lm6, 5)
```
:::

::: {.column .fragment width="60%"}
**Residuos vs. Apalancamiento**

Aquellos puntos que est√©n etiquetados con n√∫meros son mostrados como posibles outliers bajo dos criterios:

-   Est√°n por fuera de los l√≠mites de la regla del rango intercuart√≠lico (IQR), y

-   Marcados como outliers con influencia de apalancamiento mediante la prueba de Cook (distancia de Cook).

El segundo criterio es un argumento s√≥lido para remover outliers.

:::
:::

## Pruebas formales de los supuestos {.smaller}

::: incremental

-   Como vimos, los supuestos de la regresi√≥n lineal son m√°s que para el ANOVA.

-   Existen varias pruebas formales para chequear cada uno de sus supuestos, sin embargo rara vez son empleadas.

-   La raz√≥n yace en que si los aplic√°ramos todo el tiempo, no har√≠amos regresiones lineales ni el 10\% de las veces.

-   Si tienes curiosidad en estas pruebas puedes visitar [este enlace.](https://rpubs.com/aryn999/LinearRegressionAssumptionsAndDiagnosticsInR){target="_blank"}

-   De alguna manera podemos decir que de hecho, los estad√≠sticos somos m√°s laxos con la regresi√≥n lineal, sin embargo esto es bajo el supuesto no estad√≠stico de que estas departuras de los supuestos fueran debidamente documentadas y plasmadas en los trabajos cient√≠ficos, lo cual lamentablemente no pasa muy a menudo.

-   Existen por supuesto m√©todos que no dependen de todos estos supuestos (por ejemplo: regresiones lineales Bayesianas, modelos lineales generalizados correctamente parametrizados) pero no son parte de este curso.

:::

## Transformaci√≥n de datos {.scrollable .smaller}

::: incremental

-   Al igual que en el ANOVA, podemos recurrir a transformaciones de datos que nos permitan aliviar varios de los supuestos no cumplidos de la regresi√≥n lineal.

-   En el presente caso, esto lo logramos al utilizar el logaritmo natural de las dos variables del modelo

:::

. . .

```{r echo=T, eval=T, error=T, fig.height=6, fig.width=6}
lm6 <- lm(log(SVL.final) ~ log(Age.DPO), data = ranas)
par(mfrow = c(2, 2))
plot(lm6)
par(mfrow = c(1, 1))
summary(lm6)
```

## Interpretaci√≥n de la regresi√≥n lineal {.smaller .scrollable}

. . .

$$
y = mx + b
$$

. . .

```{r echo=F, eval=T, error=T}
summary(lm6)
```

. . .

-   Por cada incremento en una unidad del logaritmo de `Age.DPO`, tenemos una unidad en descenso del logaritmo de `SVL.final`

. . .

```{r echo=T, eval=T, error=T}
ggplot(ranas, aes(x = log(Age.DPO), y = log(SVL.final))) +
  geom_point()+
  geom_smooth(method = "lm")
```

## Interpretaci√≥n de la regresi√≥n lineal {.smaller .scrollable visibility="uncounted"}

::: incremental

-   Sin embargo una interpretaci√≥n en la escala logar√≠tmica no es completamente entendible, al menos para alguien ajeno al an√°lisis que realizamos.

-   Podr√≠amos hacer la retransformaci√≥n de las variables a sus unidades originales y generar un gr√°fico de las predicciones. A la final se reduce a matem√°tica b√°sica.

-   Afortunadamente la librer√≠a `ggeffects` nos salva de ese dilema!

:::

. . .

```{r echo=T, eval=T, error=T}
library(ggeffects)
predicciones <- ggpredict(lm6)
predicciones
```

. . .

-   Y finalmente el gr√°fico de predicciones

```{r echo=T, eval=T, error=T, fig.align='center', fig.height=4, fig.width=5}
plot(predicciones)
```

# ¬°Antes de terminar!

## El m√°gico $R^2$

![](images/vieja.jpg){fig-align="center"}

## El m√°gico $R^2$ {visibility="uncounted" .smaller}

::: incremental

-   Quiz√° muchos hayan escuchado que un $R^2$ cercano a 1 es "ideal" cuando realizamos una regresi√≥n lineal.

-   Recuerdo incluso haber sido indoctrinado acerca de m√°rgenes para un buen $R^2$ (algo as√≠ como que por encima del 80\% es "bueno", mayor al 90\% es excelente y 100\% es el Nirvana).

-   En breve, $R^2$ **NO ES NINGUNA DE LAS SIGUIENTES COSAS**:

    -   Una m√©trica de bondad de ajuste[: no nos dice si el modelo se ajusta bien a los datos.]{.fragment}
    
    -   Una m√©trica del error de predicci√≥n[: no mide para nada que tan bueno es el modelo para predecir futuras observaciones.]{.fragment}
    
    -   Una m√©trica que permita comparar modelos usando variables transformadas[: es com√∫n jugar a transformar los datos para ver de que manera se puede inflarlo hacia el santo grial.]{.fragment}
    
    -   Una m√©trica que permita que tan bien una variable explica otra[: en el ejemplo que vimos, y en toda regresi√≥n lineal, si cambiamos el predictor por respuesta y viceversa, tendremos exactamente el mismo $R^2$]{.fragment}
    
-   $R^2$ es simplemente una medida de la cantidad de variaci√≥n que un modelo espec√≠fico explica. [¬øTiene alguna utilidad pr√°ctica?]{.fragment} [ no lo s√©, en 10 a√±os como estad√≠stico no lo he usado nunca, al menos no, voluntariamente...]{.fragment}

:::

## El m√°gico $R^2$ {visibility="uncounted" .smaller}

. . .

-   Lo que visto es carnicer√≠as de datos por inflar $R^2$ debido a esta mala interpretaci√≥n que no se sabe su origen exacto ([pero quiz√° aqu√≠ uno de tantos culpables perdidos en la historia](https://psycnet.apa.org/record/1946-01733-001){target="_blank"}).

. . .

-   Ac√° les dejo unos cuantos recursos que pueden revisar en m√°s detalle si les interesa:

    -   [El paper "How not to lie with Statistics: Avoiding common mistakes in Quantitative Political Science"](https://www.jstor.org/stable/2111095?casa_token=F0Om3ZPkjE4AAAAA%3AvR0lcSXuNHICl21EYDAoXSerVhME0AO_ZvkzayO1vYT6R3cCM9Ooy6-P9Wa6AEZN1Gcm960rjGFM9JVA4AJc4lm-nswzYJxdtiKr03H4tbVMRW16e35TlA){target="_blank"} Un art√≠culo extenso pero que contiene una secci√≥n dedicada a desmitificar esta mala pr√°ctica.
    
    -   [Las notas de la clase del Prof. Cosma Shalizi de la Universidad Carnegie Mellon](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/10/lecture-10.pdf){target="_blank"} donde hermosamente destruye los mitos en torno al $R^2$ citando f√≥rmulas y principios estad√≠sticos.
    
    -   [Un blog de Clay Ford, consultor estad√≠stico de la Universidad de Virginia](https://data.library.virginia.edu/is-r-squared-useless/){target="_blank"} donde demuestra con R que valores de $R^2$ cercanos a 0 no necesariamente implican un mal modelo, ni valores cercanos 1 son indicativo de modelos destacados. 

# ¬°Gracias!
